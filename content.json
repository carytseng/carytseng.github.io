{"pages":[{"title":"about","date":"2021-02-13T14:22:07.000Z","path":"about/index-1.html","text":""},{"title":"Categories","date":"2021-12-04T12:21:46.494Z","path":"categories/index.html","text":""},{"title":"Tags","date":"2021-12-04T12:21:46.492Z","path":"tags/index.html","text":""}],"posts":[{"title":"","date":"2021-12-15T02:47:03.132Z","path":"2021/12/15/javacv抓取rtsp视频流/","text":"javacv抓取rtsp视频流​ javacv java平台的流媒体开发包，对opencv、ffmpeg等库做了二次封装 流媒体协议 rtmp、rtsp、hls 封装格式 flv、jpeg、png 图像像素格式 没有经过编码的原始像素排列的数据 图片封装格式 png（无损）、bmp（无损不压缩）、gif/jpg（有损压缩） 编码 对图像像素格式进行编码才是视频帧，即压缩 FrameGrabber(帧抓取器/采集器)介绍用于采集/抓取视频图像和音频采样。封装了检索流信息，自动猜测视频解码格式，音视频解码等具体API，并把解码完的像素数据（可配置像素格式）或音频数据保存到Frame中返回等功 FrameGrabber的子类/实现类包含以下几个： FFmpegFrameGrabber、OpenCVFrameGrabber、IPCameraFrameGrabber、VideoInputFrameGrabber、FlyCapture2FrameGrabber、DC1394FrameGrabber","tags":[],"categories":[]},{"title":"","date":"2021-12-06T14:13:53.733Z","path":"2021/12/06/算法/剑指 Offer 10- I. 斐波那契数列/","text":"class Solution { public int fib(int n) { if (n == 0 || n == 1) { return n; } int a = 1, b = 0; for (i = 1; i &lt; n; i++) { a = a + b; b = a - b; a %= 1000000007; } return a; }}","tags":[],"categories":[{"name":"算法","slug":"算法","permalink":"https://dogfun.top/categories/%E7%AE%97%E6%B3%95/"}]},{"title":"","date":"2021-12-06T14:00:18.469Z","path":"2021/12/06/算法/剑指 Offer 09. 用两个栈实现队列/","text":"class CQueue { Stack s1; Stack s2; public CQueue() { s1 = new Stack(); s2 = new Stack(); } public void appendTail(int value) { while (s2.size() &gt; 0) { s1.push(s2.pop()); } s1.push(value); } public int deleteHead() { while (s1.size() &gt; 0) { s2.push(s1.pop()); } return s2.size() == 0 ? -1 : s2.pop(); }}/** Your CQueue object will be instantiated and called as such: CQueue obj = new CQueue(); obj.appendTail(value); int param_2 = obj.deleteHead(); /","tags":[],"categories":[{"name":"算法","slug":"算法","permalink":"https://dogfun.top/categories/%E7%AE%97%E6%B3%95/"}]},{"title":"跨域CORS后端处理","date":"2021-11-29T07:15:50.000Z","path":"2021/11/29/web/CORS/","text":"跨域 浏览器自身存在保护机制，当从一个域名访问另一个域名的资源时，域名、端口、协议任一不同，都会产生跨域问题 跨域限制 无法读取非同源网页的 Cookie、LocalStorage 和 IndexedDB 无法接触非同源网页的 DOM 无法向非同源地址发送 AJAX 请求（可以发送，但浏览器会拒绝接受响应） 解决方案跨域资源分享CORS后端添加Access-Control-Allow-Origin返回头，允许通过的域","tags":[],"categories":[{"name":"web","slug":"web","permalink":"https://dogfun.top/categories/web/"}]},{"title":"思考仓库","date":"2021-11-28T03:34:18.005Z","path":"2021/11/28/index/","text":"Hi there 👋 I’m carytseng, a goosy coder.this is a repository for record my thinking and study. 💬 Ask me about … email -&gt; &#x63;&#97;&#114;&#x79;&#116;&#x73;&#101;&#x6e;&#x67;&#46;&#107;&#105;&#114;&#97;&#x40;&#103;&#x6d;&#97;&#x69;&#x6c;&#46;&#x63;&#x6f;&#109;","tags":[],"categories":[]},{"title":"Vim","date":"2021-11-28T03:15:15.000Z","path":"2021/11/28/linux/vim/","text":"基础命令命令模式移动光标 按键 操作 h 左移动 j 下移动 k 上移动 l 右移动 ctrl+d 下移动半页 ctrl+u 上移动半页 gg 移动到第一行 G 移动到最后一行 nG 移动到第n行 n+ 右移n个字符 n+ 下移动n行 搜索 按键 操作 /word 向光标下搜索,n搜索下一个,shirt+n搜索上一个 ?word 向光标上搜索 删除、复制与粘贴删除 按键 操作 x 向后删除一个字符 nx 向后删除n个字符 dd 删除游标那正行 ndd 删除光标下n行 dG 全部删除 shift+6 到行尾 shift+4 到行头 复制 按键 操作 yy 复制那一行 nyy 复制光标下n行 按键 操作 p 将已复制的数据贴到光标下一行 P 将已复制的数据贴到光标上一行 按键 操作 u 复原前一个动作（撤回） ctrl+r 重做上一个动作 切换到输入模式 按键 操作 i 目前光标所在处输入 I 从光标所在行的非空格字符输入 a 从目前光标所在的下一个字符开始输入 A 从目前光标所在的最后一个字符开始输入 o 从目前光标所在的行的下一行开始输入 O 从目前光标所在的行的上一行开始输入 命令模式切换到底线命令模式 按键 操作 :w 编辑的数据写入硬盘 :w! 强制写入硬盘，无权限还是写不进 :q 离开vi :q! 修改过不想保存，强制离开vi :wq 保存后离开 :w [filename] 另存为 vim环境的变更 按键 操作 :set nu 显示行号 :set nonu 取消显示行号 组合实用yy:复制当前行p: 复制的内容粘贴f+[?]:偏移到某个字符ciw:删除当前所处的词，并进入插入模式 块删除vjd 删除某个块里的内容并进入插入模式 123456789ci&#123;&#123; example&#125;&quot;example&quot;;(example); 注释多行注释： 进入命令行模式–&gt; 将光标移动到要注释的第一行位置–&gt; 按ctrl + v进入 visual block模式–&gt; 按字母j,或k（或者上下移动键）纵向选中需要注释的行–&gt; 按大写字母I，进入插入模式–&gt; 输入注释符号，例如##（需要添加几列就输入几个）–&gt; 按esc键就注释多行了。 取消多行注释（删除注释）： 进入命令行模式–&gt; 将光标移动到要取消注释的第一行第一列位置–&gt; 按ctrl + v进入 visual block模式–&gt; 按小写字母h或l横向选中列的个数，按小写字母j或k纵向选中行的个数（同样可以使用上下左右移动键）–&gt; 按d键或者delete键就可多行取消注释。","tags":[],"categories":[{"name":"linux","slug":"linux","permalink":"https://dogfun.top/categories/linux/"}]},{"title":"Minio","date":"2021-11-27T01:49:06.000Z","path":"2021/11/27/中间件/minio/","text":"docker安装123456docker run -p 9000:9000 -p 9001:9001 -d --name minio1 \\ -v /Users/carytseng/envir/minio/data:/data \\ -v /Users/carytseng/envir/minio/config:/root/.minio \\ -e &#x27;MINIO_ROOT_USER=admin&#x27; \\ -e &#x27;MINIO_ROOT_PASSWORD=admin123&#x27; \\ minio/minio server /data --console-address &quot;:9001&quot;","tags":[],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://dogfun.top/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"随想11-27","date":"2021-11-27T01:49:06.000Z","path":"2021/11/27/随想/随想11-27/","text":"泛娱乐时代倘若不能保持独立思考的能力，建立自己的观念防线，极其容易被喂养垃圾价值观而不自知，在碎片化的无意识信息汲取中得不到任何有养分的熏陶，谈何成长，不变成shit就不错了。走向平庸只需几步，失去专注力、固步自封害怕触及新领域、沉浸在自我建立的舒适区中。只需要两三年，基本的格局即会定调，再想改变是难上加难，毕竟人的天性对于大多数人来讲是不可抗力因素。","tags":[],"categories":[{"name":"随想","slug":"随想","permalink":"https://dogfun.top/categories/%E9%9A%8F%E6%83%B3/"}]},{"title":"NVM","date":"2021-10-25T01:49:06.000Z","path":"2021/10/25/web/NVM/","text":"1、nvm安装。nvm是node版本管理工具，为解决node各版本不兼容问题，nvm是让你在同一台机器上安装和切换不同版本的node brew install nvm 编辑配置文件，vim ~/.bash_profile，文件中写入如下内容 12export NVM_DIR=~/.nvmsource $(brew --prefix nvm)/nvm.sh 保存，source ~/.bash_profile 2、nvm切换镜像源，解决node下载卡/失败的问题 1234567vim ~/.bash_profile// 加入以下两条配置文件export NVM_NODEJS_ORG_MIRROR=http://npm.taobao.org/mirrors/nodeexport NVM_IOJS_ORG_MIRROR=http://npm.taobao.org/mirrors/iojs// 重启配置文件source ~/.bashrc 3、安装node指定版本 12345nvm ls-remote // 查看所有的node可用版本nvm list // 查看已安装node版本nvm install 版本号 // 下载指定node版本，如nvm install v11.14.0nvm use 版本号 // 使用指定版本nvm alias default // 设置默认版本，每次启动终端都使用该版本","tags":[],"categories":[{"name":"web","slug":"web","permalink":"https://dogfun.top/categories/web/"}]},{"title":"Mac平台下工具总结","date":"2021-09-25T01:49:06.000Z","path":"2021/09/25/效率/mac/","text":"收藏软件网站macwk 必备工具 解压：Bandizip 影音：IINA 终端替代：iTerm2 文档阅览：PDF Expert 浏览器下载：NeatDownloadManager 磁力链接必备：迅雷 系统清理：Disk diet 本地索引搜索：HapiGo 外网工具：Clash 文档编辑：wps 邮件收发（主要可设代理，方便gmail）：Formail 文件管理器替代：TotalFinder 工作必备 MarkDown编辑：Typora 文本编辑：Sublime Text Java开发：IDEA 数据库图形化：Navicat git图形化工具：SourceTree svn工具：Cornerstone 接口调试：PostMan UML工具：draw.io 容器：docker 性能监控：JProfiler 文本对比：Beyond Compare redis图形化工具：RDM 前端编辑：Visual Studio Code ssh工具：Royal Tsx 文本编辑统一将所有文本编辑类统一用visual studio code解决 添加pretty json插件 markdown all in one插件 系统性能设置提升设置性能模式12345678开启性能模式sudo nvram boot-args=&quot;serverperfmode=1 $(nvram boot-args 2&gt;/dev/null | cut -f 2-)&quot;关闭性能模式sudo nvram boot-args=&quot;$(nvram boot-args 2&gt;/dev/null | sed -e $&#x27;s/boot-args\\t//;s/serverperfmode=1//&#x27;)&quot;查看当前模式nvram boot-args 设置显卡模式12345sudo pmset -a GPUSwitch 0 // 强制使用集显sudo pmset -a GPUSwitch 1 // 强制使用独显sudo pmset -a GPUSwitch 2 // 自动切换模式 mac 上的 spotlight开关1234关闭：sudo launchctl unload -w /System/Library/LaunchDaemons/com.apple.metadata.mds.plist打开（注意要使用HapiGo必须要打开，依赖此引擎）：sudo launchctl load -w /System/Library/LaunchDaemons/com.apple.metadata.mds.plist","tags":[],"categories":[{"name":"效率","slug":"效率","permalink":"https://dogfun.top/categories/%E6%95%88%E7%8E%87/"}]},{"title":"Java基础补全","date":"2021-08-05T11:59:19.000Z","path":"2021/08/05/java/java/","text":"基本数据类型 boolean (8bit),byte(8bit),char(16bit),short(16bit),int(32bit),long(64bit),float(32bit),double(64bit),void Boolean,Byte,Character,Integer,Long,Float,Double,Void Java源文件名与类public修饰符 一个java源文件作为编译器的一个编译单元，可以有多个类，若有public类，则该类名与源文件名必须相同且只有一个，但源文件中不是必须含有public类，public类知识用来表示编译单元中存在公开接口。编译的时候java编译器判断如果存在public类，就将该类当做编译单元的对外接口，类加载器需要把该类加载。对于一个public类可以被项目中任何一个类引用。若源文件中含有public类，且含有main方法，则main方法必须在public类中定义。因为public类是对外的公开接口。 &amp;和&amp;&amp;的区别&amp;&amp;是短路操作符:若操作符左边的布尔表达式能推算出整个表达式的布尔值，则不计算右边的表达式。 &amp;是非短路操作符:始终会计算两边的布尔表达式。 ==与equals==比较两个变量的值是否相等，也就是变量所存储的数值是否相等 若是基本类型，比较数值大小 若是对象类型，比较引用变量所指向的对象是否是同一个。 equals用于比较两个独立的对象是否相同，equals方法可覆盖，定义相同的条件 创建对象的几种方式 用new语句创建对象，这是最常用的创建对象的方式。 运用反射手段，调用Java.lang.Class或者java.lang.reflect.Constructor类的newInstance()实例方法。 调用对象的clone()方法。 运用反序列化手段，调用java.io.ObjectInputStream对象的readObject()方法. equal和hashcode​ 哈希码位于对象头中，每个对象都有。主要用于查找，如HashSet在存放对象时会使用对象的哈希码来计算存储位置，HashSet是不能存放相同的两个对象的，这个相同由我们自己定义，也即是equals方法。 为什么要保证equals方法相同的两个对象 hashcode相同？ 假设equals定义了两个相同的对象，而未覆写hashcode，则hashset容器根据不同的hashcode将两个对象都放进去。重写了，就会判断同一位置上已有相同的对象。 假设有相同hashcode，则会算出相同的存储位置，若不覆写equals方法，默认调用object的equals方法，比较两个引用地址，不同就都放进去，在同一位置上使用链表存储。所以必须覆写equals方法保证对象的合法性。 值传递和引用传递 java基本数据类型是值传递，修改值不会对原来的值造成影响，对象类型都是引用传递，将对象引用的地址传递给方法参数，方法中修改对象属性即修改指向的内存空间上的对象的属性，java的方法只支持值传递。 方法重载与方法覆写方法重载发生在一个类中，多个同名函数同时存在，具有不同的参数个数、类型,调用方法时通过传递给它们的不同参数个数和参数类型决定具体使用哪个方法，这就是多态（编译时绑定），无法以返回类型作为重载标准。 方法覆写主要是子类对父类方法的重写，相同的名称和参数。子类函数的访问权限不能少于父类的。 动态绑定： 编译器检查对象声明的类型和方法名，从而获取所有候选方法。 当程序运行并且使用动态绑定来调用一个方法时，那么虚拟机必须调用对象的实际类型相匹配的方法版本。 一个是编译时绑定，根据代码传入的参数类型或者个数来确定调用的方法 一个是运行时绑定，根据传入的对象类型，确定调用子类抑或父类的方法 静态变量与实例变量语法定义：静态变量加static关键字，实例变量不需要 程序运行区别： 实例变量与实例对象关联，必须创建实例对象，才能使用对象的实例变量。 而静态变量与类关联，随着类的加载而被分配空间，无须创建对象，并且静态变量只分配了一次。 static 被static修饰的成员变量和成员方法独立于该类的任何对象。也就是说，它不依赖类特定的实例，被类的所有实例共享。只要这个类被加载，Java虚拟机就能根据类名在运行时数据区的方法区内定找到他们。因此，static对象可以在它的任何对象创建之前访问，无需引用任何对象。 static变量 按照是否静态的对类成员变量进行分类可分两种：一种是被static修饰的变量，叫静态变量或类变量；另一种是没有被static修饰的变量，叫实例变量。两者的区别是： 对于静态变量在内存中只有一个拷贝（节省内存），JVM只为静态分配一次内存，在加载类的过程中完成静态变量的内存分配，可用类名直接访问（方便），当然也可以通过对象来访问（但是这是不推荐的）。 对于实例变量，没创建一个实例，就会为实例变量分配一次内存，实例变量可以在内存中有多个拷贝，互不影响（灵活）。 静态方法 静态方法可以直接通过类名调用，任何的实例也都可以调用，因此静态方法中不能用this和super关键字，不能直接访问所属类的实例变量和实例方法(就是不带static的成员变量和成员成员方法)，只能访问所属类的静态成员变量和成员方法。因为实例成员与特定的对象关联！这个需要去理解，想明白其中的道理，不是记忆！！！ 因为static方法独立于任何实例，因此static方法必须被实现，而不能是抽象的abstract。 static代码块 static代码块也叫静态代码块，是在类中独立于类成员的static语句块，可以有多个，位置可以随便放，它不在任何的方法体内，JVM加载类时会执行这些静态的代码块，如果static代码块有多个，JVM将按照它们在类中出现的先后顺序依次执行它们，每个代码块只会被执行一次。例如： finalfinal用于声明类，方法和变量，表示属性不可变，类不可继承，方法不可覆写。 final 数据：编译期常量，这类常量必须是基本数据类型，使用static、final修饰。 对于对象引用使用final时，使引用恒定不变，但对于对象本身是可以被改变的，即指向恒定不变。定义时需要赋值 final方法：继承类不能覆盖基类的方法 final类：不能被继承 String 、StringBuilder、StringBuffer区别 执行速度方面：StringBuilder&gt;StringBuffer&gt;String String创建的是字符串常量，是不可变的，操作时会不断创建新的对象，原来的对象会被GC回收掉。而StringBuilder和StringBuffer是字符串变量，操作时是对同一个对象进行。 StringBuilder：线程非安全 StringBuffer：线程安全 String若用==比较，则比较的是对象的地址。String方法重写了equals方法，所以比较时，比较的是字符串的内容是否相同。 String创建字符串的方式: 使用new关键字创建字符串,比如String s1 = new String(“abc”); 直接指定.比如String s2 = “abc”; 使用串联生成新的字符串.比如String s3 = “ab” + “c”; Java运行时会维护一个String Pool(String池),JavaDoc翻译很模糊”字符串缓冲区”.String池用来存放运行时中产生的各种字符串,并且池中的字符串的内容不重复.而一般对象不存在这个缓冲池,并且创建的对象仅仅存在于方法的堆栈区。 原理 原理1:当使用任何方式来创建一个字符串对象s时,Java运行时(运行中JVM)会拿着这个X在String池中找是否存在内容相同的字符串对象,如果不存在,则在池中创建一个字符串s,否则,不在池中添加. 原理2:Java中,只要使用new关键字来创建对象,则一定会(在堆区或栈区)创建一个新的对象. 原理3:使用直接指定或者使用纯字符串串联来创建String对象,则仅仅会检查维护String池中的字符串,池中没有就在池中创建一个,有则罢了!但绝不会在堆栈区再去创建该String对象. 原理4:使用包含变量的表达式来创建String对象,则不仅会检查维护String池,而且还会在堆栈区创建一个String对象. javac编译可以对字符串常量直接相加的表达式进行优化，不必要等到运行期去进行加法运算处理，而是在编译时去掉取中的加号 常见问题：123456789101112131415161718192021String s1 = &quot;a&quot;;String s2 = s1 + &quot;b&quot;;//含有变量，因此会先检查维护String池，并在堆中创建一个新对象String s3 = &quot;a&quot; + &quot;b&quot;;System.out.println(s2 == &quot;ab&quot;);//false,&quot;ab&quot;的地址在常量池中，而s2指向的是堆中所copy的对象System.out.println(s3 == &quot;ab&quot;);//trueSystem.out.println(s3 == s2);//falseString s1 = &quot;a&quot;;String s2 = &quot;a&quot; + &quot;b&quot;;//直接在常量池中创建一个新的String s3 = &quot;a&quot; + &quot;b&quot;;//使用常量池中存在的System.out.println(s2 == &quot;ab&quot;);//trueSystem.out.println(s3 == s2);//true ThreadLocal 线程本地变量，对于一个变量，ThreadLocal为该变量在每个线程中创建一个副本，线程间的变量互不影响。适用场景，多个线程不依赖于共享变量的状态来进行逻辑驱动，适用于在每个线程中，保存一份变量副本，对于该副本的任何修改也仅限于该线程的操作，其他线程无法影响。 设计理念 概括起来说，对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，做到多线程的数据隔离。 设计原理 ​ 每个线程Thread类会维护一个变量ThreadLocalMap，该map是以ThreadLocal作为key，保存的变量值作为value保存在当前线程的ThreadLocalMap中，所以每个线程可以存储多个ThreadLocal的变量值。set的时候，拿到当前线程的ThreadLocalMap，若map为空则初始化，否则set进变量值。get的时候，是获取当前线程的ThreadLocalMap，以该ThreadLocal作为key来获取变量值。 12345678910111213141516171819202122public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); 类加载及双亲委派模型类加载加载：​ 查找并加载二进制数据。把类的.class文件中的二进制数据读入内存，把它存放到方法区，然后在堆创建一个Class对象，用来封装类在方法区内的数据结构，提供了访问类在方法区内的数据结构的接口。 连接： 验证：确保被加载类的正确性。 准备：为类的静态变量分配内存，并将其初始化为默认值。 解析：把类中的符号引用转换为直接引用。 初始化：给类的静态变量赋予正确的初始值。 假如这个类还没有被加载和连接，就先进行加载和连接。 假如这个类存在父类，并且这个父类还没有初始化，就先初始化。 假如这个类存在初始化语句，就依次执行。 初始化的时机： 创建类的实例：new、反射、克隆及序列化。 调用类的静态方法。 访问某个类或接口的静态变量。 调用java api的某些反射方法。 初始一个类的子类 类及对象创建的初始化顺序 父类–静态变量 父类–静态初始化块 子类–静态变量 子类–静态初始化块 父类–变量 父类–初始化块 父类–构造器 子类–变量 子类–初始化块 子类–构造器 双亲委派模型：Bootstrap ClassLoader、Extension ClassLoader、ApplicationClassLoader。 如果一个类加载器收到类加载的请求，首先不会自己尝试加载，先委派给父类加载器去完成，只有当父加载器无法加载时，子加载器才会尝试加载。这种机制下用户自定义的类加载器不可能加载由父加载器加载的可靠类，从而防止不可靠的恶意代码。 ExceptionError与Exception Error是程序无法处理的错误，比如OutOfMemoryError、ThreadDeath等。这些异常发生时， Java虚拟机（JVM）一般会选择线程终止。 Exception是程序本身可以处理的异常，这种异常分两大类运行时异常和非运行时异常。 程序中应当尽可能去处理这些异常。 运行时异常： 运行时异常都是RuntimeException类及其子类异常，如NullPointerException、IndexOutOfBoundsException、ArithmeticException、 IllegalArgumentException 等， 这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。 非运行时异常 非运行时异常是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。 try语句块 表示要尝试运行代码，try语句块中代码受异常监控，其中代码发生异常时，会抛出异常对象。 catch语句块 捕获try代码块中发生的异常并在其代码块中做异常处理，catch语句带一个Throwable类型的参数，表示可捕获异常类型。当try中出现异常时，catch会捕获到发生的异常，并和自己的异常类型匹配， 若匹配，则执行catch块中代码，并将catch块参数指向所抛的异常对象。catch语句可以有多个，用来匹配多个中的一个异常，一旦匹配上后，就不再尝试匹配别的catch块了。通过异常对象可以获取异常发生时完整的JVM堆栈信息，以及异常信息和异常发生的原因等。 finally语句块 是紧跟catch语句后的语句块，这个语句块总是会在方法返回前执行，而不管是否try语句块是否发生异常。并且这个语句块总是在方法返回前执行。目的是给程序一个补救的机会。这样做也体现了Java语言的健壮性。 try、catch、finally三个语句块应注意的问题 try、catch、finally三个语句块均不能单独使用，三者可以组成 try…catch…finally、try…catch、 try…finally三种结构，catch语句可以有一个或多个，finally语句最多一个。 try、catch、finally三个代码块中变量的作用域为代码块内部，分别独立而不能相互访问。 如果要在三个块中都可以访问，则需要将变量定义到这些块的外面。 多个catch块时候，只会匹配其中一个异常类并执行catch块代码，而不会再执行别的catch块， 并且匹配catch语句的顺序是由上到下。 throw、throws关键字 throw关键字是用于方法体内部，用来抛出一个Throwable类型的异常。如果抛出了检查异常，则还应该在方法头部声明方法可能抛出的异常类型。该方法的调用者也必须检查处理抛出的异常。如果所有方法都层层上抛获取的异常，最终JVM会进行处理，处理也很简单，就是打印异常消息和堆栈信息。如果抛出的是Error或RuntimeException，则该方法的调用者可选择处理该异常。有关异常的转译会在下面说明。 throws关键字用于方法体外部的方法声明部分，用来声明方法可能会抛出某些异常。仅当抛出了检查异常，该方法的调用者才必须处理或者重新抛出该异常。当方法的调用者无力处理该异常的时候，应该继续抛出，而不是囫囵吞枣一般在catch块中打印一下堆栈信息做个勉强处理。 try中return，则finally语句是否执行，什么时候执行？123456789101112131415public class smallT &#123; public static void main(String[] args) &#123; smallT t = new smallT(); int b = t.get(); System.out.println(b); &#125; public int get() &#123; try &#123; return 1; &#125; finally &#123; return 2; &#125; &#125;&#125; 先返回1，最终返回的是2。 try中的return 语句调用的函数先于 finally中调用的函数执行，也就是说 return语句先执行，finally语句后执行，所以，返回的结果是 2。Return 并不是让函数马上返回，而是 return语句执行后，将把返回结果放置进函数栈中，此时函数并不是马上返回，它要执行 finally语句后才真正开始返回。 高级应用流式处理 将待处理的集合当成流经过管道的处理，比如筛选、排序、聚合等，得到最终想要的结果。 forEach 1234567891011Random random = new Random(); random.ints().limit(10).forEach(System.out::println);//打印对象students.stream().forEach(s-&gt;&#123; System.out.println(s.getName())&#125;); map 12345List&lt;Integer&gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5); // 获取对应的平方数 List&lt;Integer&gt; squaresList = numbers.stream().map( i -&gt; i*i).distinct().collect(Collectors.toList()); filter 12345List&lt;String&gt;strings = Arrays.asList(&quot;abc&quot;, &quot;&quot;, &quot;bc&quot;, &quot;efg&quot;, &quot;abcd&quot;,&quot;&quot;, &quot;jkl&quot;); // 获取空字符串的数量 long count = strings.stream().filter(string -&gt; string.isEmpty()).count(); limit 123Random random = new Random(); random.ints().limit(10).sorted().forEach(System.out::println); order 1234567//按照对象的某个属性排序students.stream().sorted(Comparator.comparing(Student::getBirthday)).collect(Collectors.toList());//倒序students.stream().sorted(Comparator.comparing(Student::getBirthday).reversed()).collect(Collectors.toList()); match allMatch：Stream 中全部元素符合则返回 true ; anyMatch：Stream 中只要有一个元素符合则返回 true; noneMatch：Stream 中没有一个元素符合则返回 true。 1234567891011121314151617boolean all = lists.stream().allMatch(u -&gt; u.getId() &gt; 3);System.out.println(&quot;是否都大于3:&quot; + all);boolean any = lists.stream().anyMatch(u -&gt; u.getId() &gt; 3);System.out.println(&quot;是否有一个大于3:&quot; + any);boolean none = lists.stream().noneMatch(u -&gt; u.getId() &gt; 3);System.out.println(&quot;是否没有一个大于3的:&quot; + none); // 是否都大于3:false// 是否有一个大于3:true// 是否没有一个大于3的:false","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://dogfun.top/categories/java/"}]},{"title":"","date":"2020-11-29T13:00:15.569Z","path":"2020/11/29/效率/效率/","text":"IDEA快速代码生成12psvm 生成main方法sout 生成System.out.println 查找1234567891011121314151617181920cmd+o 定位类查找cmd+shift+f 查找文件shift+shift 所有文件查找option+f7. 定位使用到的地方cmd+b 声明或使用到的地方option+cmd+b 定位接口实现类cmd+u 定位实现的接口或者继承类cmd+b 定位调用方cmd+\\ 插件定位controller方法alt+cmd+b 定位实现类 类生成123ctrl+enter 类生成方法cmd+n 生成构造、test、equal、overwrite等 其他123456789cmd+shift+u 大小写切换cmd+l 定位文件行&amp;列cmd+b 回到调用位置cmd+[+]/[-]展开代码/折叠代码cmd+shift+[+]/[-]展开所有代码/折叠所有代码 GitLinux系统监测1234ps -ef 显示运行进程top 实时显示系统进程及参数 bash1234echo -n -e type Mac 根据路径打开文件 shirt+cmd+g 打开访达 cmd+n 搜词 option+/ 全局搜索 option+space 我的电脑 cmd+shirt+h 新建文件夹 cmd+shirt+n 同一个应用多开切换 cmd+` 桌面 f11 Markdown 添加目录 [toc] h1 # 块引用 &gt; 列表 * || 1. 代码块 ``` 加粗 ? 图片引入 下划线 *** 表格 |||| Hexo 新建文章 hexo n “hello world” 新建页面 hexo new page “pageName” 生成静态页面至public目录 hexo g 开启预览访问端口 hexo s 上传部署 hexo d 帮助 hexo help 生成并本地预览 hexo s -g 生成并上传 hexo d -g Alfred文件目录搜索12find [file]open [file] 文本内容搜索1in [file] 快捷网页搜索123google somethingwiki somethingbing something 翻译1yd []","tags":[],"categories":[{"name":"效率","slug":"效率","permalink":"https://dogfun.top/categories/%E6%95%88%E7%8E%87/"}]},{"title":"ignite迁移","date":"2020-11-28T11:59:19.000Z","path":"2020/11/28/vps/ignite迁移/","text":"12#新主机docker脚本安装curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun docker-compose.yml&amp;ignite.db文件cp 容器服务导出导入 生成容器快照，打出镜像 docker commit -p [containerId] [alias] 生成tar文件 docker save -o ~/[filename].tar [imageName] 导入tar文件 cat [tarfile] |docker import - [name] 原主机获取容器启动命令相关参数 安装runlike 12345yum install -y python-pippip install runlike#查看启动参数runlike -p [containerid]cp 启动ssr子容器所有服务，获得所有containerid，修改ignite.db中表user的service_id docker-compose run –rm ignite-admin /bin/sh -c ‘./ignite-admin recover’ docker-compose up -d","tags":[],"categories":[{"name":"vps","slug":"vps","permalink":"https://dogfun.top/categories/vps/"}]},{"title":"CAP定理","date":"2020-11-04T13:41:57.000Z","path":"2020/11/04/web/CAP定理/","text":"面试被问到CAP定理，之前看过，真正问起来讲得不清楚，估计没有真正的理解这个定理，故作此文进行记录 分布式系统有三个指标，也即一致性、可用性、分区容错 （C）一致性：多个节点的数据保持一致，当某个节点的数据修改后，需要同步修改所有节点的数据，保持一致 （A）可用性：即当某个节点宕机后，整个集群还能正常对外服务，保证服务健康 （P）分区容错：两个节点间可能会无法通信，P定理总是成立的。 一致性和可用性不可能同时成立，因为P即分区容错总是可能出现，如果要保证一致性，则必须保证所有节点都收到该数据的同步，才能对外服务，这就不满足可用性。如果满足可用性，即某个节点崩坏了也要提供服务，那么就不能保证一致性。 所以一般需要根据业务需要，保证C或A其中一个特性，例如网页更新可以采取可用性，因为最终用户都会看到最新的版本；如果是银行等金融数据，需要保证强一致性，则需要抛弃可用性。","tags":[],"categories":[{"name":"web","slug":"web","permalink":"https://dogfun.top/categories/web/"}]},{"title":"redis","date":"2020-10-28T07:13:07.000Z","path":"2020/10/28/中间件/redis/","text":"工作中接触Redis大多仅用来作为缓存，也用过来做分布式锁，对于内部的实现机制及高级用法几乎是走马观花，故作此文用来记录相关的知识点，从原理出发慢慢拓展此文，全部用自己的理解话术来进行记录，个人理解，有误请指出。 RedisRedis诞生之初是为了解决关系型数据库的性能问题，由于IO需要对磁盘的读写速度满足不了实际场景，因此创造者利用内存造了一个内存数据库，没有关系型数据库的约束，Redis提供的数据结构简单且能满足高性能的读写场景，其基于对内存的读写，能够在短时间内处理数据，由于读写速度快，免去IO的局限，IO涉及操作系统用户空间与内核空间的数据复制及事件等待，所以redis采用单线程的处理模型，免去线程切换的开销，因为也没必要进行多线程处理 对比memcached支持多种数据结构，memcached仅支持字符串且不支持持久化 请求处理Redis采用基于Reactor模式开发网络事件处理器，采用IO多路复用技术，简单来说就是一条线程监听多个客户端socket，当有事件到时，将事件作为一个task放到队列中，接下来文件处理器会对队列中的task进行处理，文件处理器是单线程的，没有线程的切换问题，文件处理器包含连接应答器、命令请求处理器、命令回复处理器，执行相应的命令后，返回相应。这也是Redis速度快的原因：IO多路复用、单线程处理task、基于内存的数据操作 Redis数据结构基于键值的存储，值支持以下几种类型 string：字符串 字节串：非字符自增会报错 整数：可自增减 浮点数 list：有序队列 可用作队列 set：集合 hash：散列 zset：有序集合 相比散列，提供基于分值的相关功能，每个key有对应的score，应对一些场景应用 持久化Redis提供持久化的功能，能够将内存的数据定时写入硬盘，保证数据在系统重启后能够恢复，继续进行服务 两种持久化的方式： 快照 AOF 快照 快照：会开启一个子进程定时对内存的数据进行打快照，使用BGSAVE命令，缺点是快照是按周期打，性能有限，一旦系统崩溃，会丢失从上次快照之后的数据，也有可能在刚打完快照就崩溃。而且打快照可能会造成Redis停顿 AOF AOF：将Redis的执行命令记录下来，记录到AOF文件中，可根据需要设置频率，恢复时只需要执行相应的写命令即可。缺点是AOF的文件会随着内存数据的增大而增大，造成磁盘爆满，可以使用命令对AOF文件重写，压缩冗余的部分 同步频率 always：每个命令都写入磁盘 everysec：每秒同步一次，多个命令到磁盘 no：由系统决定写入时间 复制水平添加多个Redis实例，通过主从服务器来满足高性能的读写请求。主服务器将快照文件发送到从服务器，从服务器获得快照并初始化数据 过期时间设置Redis提供过期时间设置保证内存空间，也能保证热数据 Redis后台有两种方式对过期数据进行删除 定期删除：每隔一段时间抽取过期的key然后删除 惰性删除：当系统查询到这个过期key时会删除 热key问题针对某个key的大流量请求，造成物理机的网卡超载，导致Redis宕机引发雪崩 解决思路： 提前把key打到不同的服务器 加入二级缓存，提前加载热key到内存 缓存击穿|缓存穿透|缓存雪崩缓存击穿类似热key问题，区别点在于key的过期导致请求打在DB上 解决思路： 加锁更新，对key进行加锁，在数据库查询前就进行了拦截 过期时间写在value中，用异步方式刷新过期时间 缓存穿透查询缓存中不存在的key，恶意请求大量制造不存在的key直接请求DB 解决思路： 加一层布隆过滤器 缓存雪崩某一时刻可能发生大规模的缓存失效，例如缓存服务宕机，大量的key同时失效，请求打到DB，导致整个系统雪崩 不同的key设置不同的过期时间，避免同时过期 限流，降低db压力 二级缓存 redis分布式锁实现秒杀业务 曾经做过一个类似秒杀系统的模块，系统采用分布式架构，场景是这样子的，用户提了故障单后，有跟踪故障单的需求，衍生了催单，用户会通过多个客户端去提交催单，用户催单有专人去跟踪，有一定的时效性，需要及时处理反馈。 业务规则 同一个工单号一个用户15分钟内只能提一次催单 同一个工单号不同用户15分钟内只产生一条催单，新增的用户则追加子记录 问题 需要考虑并发操作 保证分布式环境下业务的正确处理 考虑大流量请求下服务处理压力 虽然系统是运营商的内部系统，tob的用户量并不会很大，但站在技术角度，需要考虑如果toc要怎么满足的问题。首先处理并发问题，因为多个用户对于同一个工单的业务操作是竞争的，因此需要对同一个工单号上锁，其次要满足高可用，因此在多服务运行环境下，需要引入分布式锁，查了下分布式锁的解决方案可以使用redis或者数据库锁（通过数据库插入记录的唯一性保证），这里使用redis分布式锁来解决，且针对用户的重复查询，使用redis缓存来降低DB的压力，这样15分钟内用户的多次查询都能命中缓存，以此解决问题3。 分布式锁的方案及原理 数据库加锁 数据库锁主要是利用行记录的唯一性来保护资源，插入失败即继续重试，直至获取到锁。需要自己考虑锁超时，事务等。 Redis锁 利用sexNx方法的原子特性实现，多个进程竞争set值，只有一个进程set成功则为获取锁成功，需要设置锁的过期时间防止宕机，redis2.8以前需要使用lua脚本来保证setNx与过期时间设置保证原子操作，2.8以后能支持nx和ex是同一操作。可以使用redission客户端，封装了锁的实现。 zookeeper锁 使用Curator框架，其封装了zookeeper的API，提供分布式锁的实现。原理是zookeeper有一个临时有序节点的概念，在某个目录加锁会生成一个节点，后来的客户端会有序生成排列，然后先到的客户端会检测自己是不是第一个节点，是的话就加锁成功，否则寻找当前节点的上一个节点，并且添加监听器。当上一个节点操作完毕释放锁会删除自己的节点，此时监听到删除的下一个节点会尝试获取。这里不用保证超时，因为zookeeper能够检测客户端的健康状态，当失活后能够删除当前节点，这也就是zookeeper锁的原理 伪代码 1234567891011121314151617181920212223242526272829303132333435363738void submitCallOrder(String orderNum, String userName)&#123; String cacheUserOrderNum; //缓存取是否催单，key以用户+工单号 cacheUserOrderNum=template.opsForValue().get(userName+&quot;:&quot;+orderNum); if(Strings.isNotBlank(cacheUserOrderNum))&#123; //用户已催单 &#125; //加锁，获取不到一直阻塞 while(!redisLockHelper.lock(orderNum,String.valueOf(time)))&#123;&#125;; //查询是否有15分钟内的催单 Order dbOrder=orderMapper.existLatestCallOrder(orderNum); if(dbOrder==null)&#123; //没有则新增催单 orderMapper.insert(order); //新增催单用户子记录 subOrderMapper.insert(subOrder); //缓存数据 template.opsForValue().set(userName+&quot;:&quot;+orderNum,&quot;1&quot;, TimeUnit.MINUTES.toMinutes(15)); &#125;else&#123; //用户15分钟内是否催过单 if(subOrderMapper.existLatestSubCallOrder(orderNum,userName))&#123; //缓存数据 template.opsForValue().set(userName+&quot;:&quot;+orderNum,&quot;1&quot;, TimeUnit.MINUTES.toMinutes(15)); &#125;else&#123; //新增催单用户子记录 subOrderMapper.insert(subOrder); //更新催单主记录最近催单时间 orderMapper.updateByPrimaryKeySelective(order); //缓存数据 template.opsForValue().set(userName+&quot;:&quot;+orderNum,&quot;1&quot;, TimeUnit.MINUTES.toMinutes(15)); &#125; &#125; //释放锁 redisLockHelper.unlock(orderNum,String.valueOf(time));&#125; Redis分布式锁工具类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class RedisLockHelper &#123; @Autowired private StringRedisTemplate stringRedisTemplate; /** * 加锁 * @param targetId targetId - 唯一标志 * @param timeStamp 当前时间+超时时间 也就是时间戳 * @return */ public boolean lock(String targetId,String timeStamp)&#123; if(stringRedisTemplate.opsForValue().setIfAbsent(targetId,timeStamp))&#123; // 对应setnx命令，可以成功设置,也就是key不存在 return true; &#125; // 判断锁超时 - 防止原来的操作异常，没有运行解锁操作 防止死锁 String currentLock = stringRedisTemplate.opsForValue().get(targetId); // 如果锁过期 currentLock不为空且小于当前时间 if(!Strings.isNullOrEmpty(currentLock) &amp;&amp; Long.parseLong(currentLock) &lt; System.currentTimeMillis())&#123; // 获取上一个锁的时间value 对应getset，如果lock存在 String preLock =stringRedisTemplate.opsForValue().getAndSet(targetId,timeStamp); // 假设两个线程同时进来这里，因为key被占用了，而且锁过期了。获取的值currentLock=A(get取的旧的值肯定是一样的),两个线程的timeStamp都是B,key都是K.锁时间已经过期了。 // 而这里面的getAndSet一次只会一个执行，也就是一个执行之后，上一个的timeStamp已经变成了B。只有一个线程获取的上一个值会是A，另一个线程拿到的值是B。 if(!Strings.isNullOrEmpty(preLock) &amp;&amp; preLock.equals(currentLock) )&#123; // preLock不为空且preLock等于currentLock，也就是校验是不是上个对应的商品时间戳，也是防止并发 return true; &#125; &#125; return false; &#125; /** * 解锁 * @param target * @param timeStamp */ public void unlock(String target,String timeStamp)&#123; try &#123; String currentValue = stringRedisTemplate.opsForValue().get(target); if(!Strings.isNullOrEmpty(currentValue) &amp;&amp; currentValue.equals(timeStamp) )&#123; // 删除锁状态 stringRedisTemplate.opsForValue().getOperations().delete(target); &#125; &#125; catch (Exception e) &#123; log.error(&quot;警报！警报！警报！解锁异常&#123;&#125;&quot;,e); &#125; &#125;&#125; github源码地址 redis批量删除 redis没有提供针对key的模糊删除支持，提供的keys命令会一次性扫描库中符合条件的记录，没有分页设置，可能由于数据量过大造成redis卡顿，影响正常业务进行，在生产中应该摒弃用keys命令来扫描。 Scan命令该命令是redis2.8提供的，相比keys命令，它是通过游标分步进行，不会对线程造成阻塞，提供匹配功能。游标的意思，redis的数据结构是基于hash的，类似java的hashmap，底层也是数组+链表，这里通过游标遍历。 SCAN CURSOR [MATCH pattern] [COUNT count] CURSOR代表游标，每次扫描都会返回上次的游标以此来开始增量的扫描，count指扫描槽位的数量，可以理解为扫描hashmap中一维数组中多少个元素并返回这些槽组的数据，判断是否有符合的元素。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public void scanAndDel(String key) &#123; try &#123; redisTemplate.execute((RedisCallback&lt;Boolean&gt;) redisConnection -&gt; &#123; Object nativeConnection = redisConnection.getNativeConnection(); // lettuce 单机 if (nativeConnection instanceof RedisAsyncCommands) &#123; RedisAsyncCommands connection = (RedisAsyncCommands) nativeConnection; RedisCommands&lt;byte[], String&gt; commands = connection.getStatefulConnection().sync(); KeyScanCursor&lt;byte[]&gt; scanCursor = null; do &#123; if (scanCursor == null) &#123; scanCursor = commands.scan(ScanArgs.Builder.matches(key)); &#125; else &#123; scanCursor = commands.scan(scanCursor, ScanArgs.Builder.matches(key)); &#125; List&lt;byte[]&gt; byteKeys = scanCursor.getKeys(); if (byteKeys.size() &gt; 0) &#123; byte[][] keys = new byte[byteKeys.size()][]; for (int i = 0; i &lt; byteKeys.size(); i++) &#123; keys[i] = byteKeys.get(i); &#125; commands.del(keys); try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; while (!scanCursor.isFinished()); &#125; // lettuce 集群 if (nativeConnection instanceof RedisAdvancedClusterAsyncCommands) &#123; RedisAdvancedClusterAsyncCommands connection = (RedisAdvancedClusterAsyncCommands) nativeConnection; RedisAdvancedClusterCommands&lt;byte[], String&gt; commands = connection.getStatefulConnection().sync(); KeyScanCursor&lt;byte[]&gt; scanCursor = null; do &#123; if (scanCursor == null) &#123; scanCursor = commands.scan(ScanArgs.Builder.matches(key)); &#125; else &#123; scanCursor = commands.scan(scanCursor, ScanArgs.Builder.matches(key)); &#125; List&lt;byte[]&gt; byteKeys = scanCursor.getKeys(); if (byteKeys.size() &gt; 0) &#123; byte[][] keys = new byte[byteKeys.size()][]; for (int i = 0; i &lt; byteKeys.size(); i++) &#123; keys[i] = byteKeys.get(i); &#125; commands.del(keys); try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; while (!scanCursor.isFinished()); &#125; return true; &#125;); &#125; catch (Exception e) &#123; &#125; &#125;","tags":[],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://dogfun.top/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"Spring多数据源加载","date":"2020-10-07T02:21:14.000Z","path":"2020/10/07/web/Spring多数据源加载/","text":"前言 Spring引入多数据源的方式，系统扩展的过程中可能会引入多个数据源，查阅了一些博客，发现引入方式或多或少都需要引入新的配置类，这里记录下在不需要修改任何代码的情况下，扩展数据源的方式，以后只需要在配置文件添加配置就能直接引入。 引入方式 分包方式 参数化方式 注解+AOP 分包方式比较简单，哪个数据源的操作就走哪个mapper目录下的文件，一般就是两个库无任何关联的场景。 参数化方式根据传入的参数选择数据源，进行数据查询，个人比较推崇这一种方式。 注解+AOP在特定的方式上添加自定义的注解，配置上需要选择的数据源值，AOP执行的时候通过获取注解上的值来切换，这种方式需要在方法上写死需要的数据源，不太灵活。 引入数据源的思路 配置文件添加多个数据源 自定义数据源配置 注入Spring容器 利用ThreadLocal的上下文，实现线程与数据源的绑定关系 使用上用参数化还是AOP等都可以 步骤application.yml 1234567891011121314151617spring: datasource: master: password: 12345678 jdbcUrl: jdbc:mysql://127.0.0.1:3306/master?useUnicode=true&amp;characterEncoding=UTF-8 driverClassName: com.mysql.jdbc.Driver username: root slave1: password: 12345678 jdbcUrl: jdbc:mysql://127.0.0.1:3306/slave1?useUnicode=true&amp;characterEncoding=UTF-8 driverClassName: com.mysql.jdbc.Driver username: root slave2: password: 12345678 jdbcUrl: jdbc:mysql://127.0.0.1:3306/slave2?useUnicode=true&amp;characterEncoding=UTF-8 driverClassName: com.mysql.jdbc.Driver username: root 建立一个property类来映射配置，这样我们就能拿到多个数据源的配置了。 1234567@Data@Component@ConfigurationProperties(prefix = &quot;spring&quot;)public class DynamicDataSourceProperty &#123; //只映射datasource private Map&lt;String, Object&gt; datasource;&#125; 接下来我们就是将所有的配置转换成bean并且注入到Spring中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configuration@MapperScan(basePackages = &quot;com.demo.sv.mapper&quot;)public class DynamicDataSourceConfig &#123; @Autowired private BeanFactory beanFactory; @Autowired private DynamicDataSourceProperty dynamicDataSourceProperty; /** * 功能描述: &lt;br&gt; * 〈动态数据源bean 自动配置注册所有数据源〉 * */ @Bean @Primary public DataSource dynamicDataSource() &#123; //拿到Spring容器 DefaultListableBeanFactory listableBeanFactory = (DefaultListableBeanFactory) beanFactory; /*获取yml所有数据源配置*/ Map&lt;String, Object&gt; datasource = dynamicDataSourceProperty.getDatasource(); Map&lt;Object, Object&gt; dataSourceMap = new HashMap&lt;&gt;(5); Optional.ofNullable(datasource).ifPresent(map -&gt; &#123; for (Map.Entry&lt;String, Object&gt; entry : map.entrySet()) &#123; //创建数据源对象 HikariDataSource dataSource = (HikariDataSource) DataSourceBuilder.create().build(); String dataSourceId = entry.getKey(); configeDataSource(entry, dataSource); /*bean工厂注册每个数据源bean*/ listableBeanFactory.registerSingleton(dataSourceId, dataSource); dataSourceMap.put(dataSourceId, dataSource); &#125; &#125;); //AbstractRoutingDataSource设置主从数据源 return new DynamicDataSource(beanFactory.getBean(&quot;master&quot;, DataSource.class), dataSourceMap); &#125; //从配置转换成bean private void configeDataSource(Map.Entry&lt;String, Object&gt; entry, HikariDataSource dataSource) &#123; Map&lt;String, Object&gt; dataSourceConfig = (Map&lt;String, Object&gt;) entry.getValue(); dataSource.setJdbcUrl(MapUtils.getString(dataSourceConfig, &quot;jdbcUrl&quot;)); dataSource.setDriverClassName(MapUtils.getString(dataSourceConfig, &quot;driverClassName&quot;)); dataSource.setUsername(MapUtils.getString(dataSourceConfig, &quot;username&quot;)); dataSource.setPassword(MapUtils.getString(dataSourceConfig, &quot;password&quot;)); &#125;&#125; 切换数据源我们需要用到Spring提供的一个抽象类AbstractRoutingDataSource，这个类有个抽象方法determineTargetDataSource，我们通过继承这个类，并且实现determineTargetDataSource方法，这个determineTargetDataSource就是决定调用数据源的逻辑，简单来说这个方法算出key值，然后去数据源池取出我们需要的数据源。 12345678910111213141516public class DynamicDataSource extends AbstractRoutingDataSource &#123; public DynamicDataSource(DataSource defaultDataSource, Map&lt;Object, Object&gt; targetDataSource) &#123; backupTargetDataSources = targetDataSource; super.setDefaultTargetDataSource(defaultDataSource); super.setTargetDataSources(backupTargetDataSources); super.afterPropertiesSet(); &#125; @Override protected Object determineCurrentLookupKey() &#123; log.info(&quot;当前的数据源：&#123;&#125;&quot;,DynamicDataSourceContextHolder.getContextKey()); //我们自己定义了一个DynamicDataSourceContextHolder来维护key，只要我们在方法调用前设置key，Spring会根据这个方法来决定数据源 return DynamicDataSourceContextHolder.getContextKey(); &#125;&#125; 测试类，Springboot项目要加入排除自动配置数据源注解@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class}) 123456789101112131415161718192021@SpringBootTest@RunWith(SpringJUnit4ClassRunner.class)class SvApplicationTests &#123; @Autowired private UserMapper userMapper; @Autowired private ApplicationContext context; @Test public void query() &#123; User user = new User(); //根据需要切换我们需要的数据源 DynamicDataSourceContextHolder.setContextKey(&quot;slave2&quot;); List&lt;User&gt; users= userMapper.query(); DynamicDataSourceContextHolder.remove(); System.out.println(users); &#125;&#125; 关于多数据源的事务处理当引入多数据源后，如果要加入事务处理，同一个事务中处理处理两个数据源的数据会失败，主要是因为第一个数据源打开数据库连接后，会加入ThreadLocal中与线程进行绑定，而此时第二个数据源再获取sqlSession，发现不为空，取的是第一个数据源的连接，所以会有问题。如果要支持，思路就是保证sqlSession的独立，但不能保证分布式事务的正确处理。查阅相关资料，可以使用XA协议，具体此文没有详细探讨。","tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"},{"name":"数据源","slug":"数据源","permalink":"https://dogfun.top/tags/%E6%95%B0%E6%8D%AE%E6%BA%90/"}],"categories":[{"name":"web","slug":"web","permalink":"https://dogfun.top/categories/web/"}]},{"title":"从零开始写框架-SpringMVC","date":"2020-09-30T11:24:06.000Z","path":"2020/09/30/web/从零开始写框架-SpringMVC/","text":"前言： 最近打算提升下源码能力，跟着相关教程实现Spring框架，巩固下前面的学习知识，像反射、设计模式等，顺带熟悉一些API。像设计模式这类知识，只能通过代码实践来提升对其核心思想的理解，毕竟设计模式不是凭空产生的，而是在代码实践的过程中，通过不断地重构提炼，发现其奥妙之处，才产生相关的程序思想。 1.0 MVC准备工作配置文件application.properties1scanPackage=com.gupaoedu.demo 自定义注解这部分主要模拟Spring中我们常用的Autowired，Controller，RequestMapping，RequestParam，Service等。 注解文件： 12345678910111213141516171819202122232425262728293031323334@Target(&#123;ElementType.FIELD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface GPAutowired &#123; String value() default &quot;&quot;;&#125;@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface GPController &#123; String value() default &quot;&quot;;&#125;@Target(&#123;ElementType.TYPE,ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface GPRequestMapping &#123; String value() default &quot;&quot;;&#125;@Target(&#123;ElementType.PARAMETER&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface GPRequestParam &#123; String value() default &quot;&quot;;&#125;@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface GPService &#123; String value() default &quot;&quot;;&#125; web.xml文件： 12345678910111213141516171819&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot; version=&quot;4.0&quot;&gt; &lt;servlet&gt; &lt;servlet-name&gt;gpmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;com.gupaoedu.mvcframework.v1.servlet.GPDispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;application.properties&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;gpmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; Controller类： 12345678910111213141516171819202122232425262728293031@GPController@GPRequestMapping(&quot;/demo&quot;)public class DemoAction &#123; @GPAutowired private IDemoService demoService; @GPRequestMapping(&quot;/query&quot;) public void query(HttpServletRequest req, HttpServletResponse resp, @GPRequestParam(&quot;name&quot;) String name)&#123; String result = demoService.get(name); try&#123; resp.getWriter().write(result); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; @GPRequestMapping(&quot;/add&quot;) public void add(HttpServletRequest req,HttpServletResponse resp,@GPRequestParam(&quot;a&quot;)Integer a,@GPRequestParam(&quot;b&quot;) Integer b)&#123; try&#123; resp.getWriter().write(a+&quot;+&quot;+b+&quot;=&quot;+(a+b)); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; @GPRequestMapping(&quot;/remove&quot;) public void remove(HttpServletRequest req,HttpServletResponse resp,@GPRequestParam(&quot;a&quot;)Integer a,@GPRequestParam(&quot;b&quot;) Integer b)&#123; &#125;&#125; Service接口： 123public interface IDemoService &#123; public String get(String name);&#125; Service实现类： 1234567@GPServicepublic class DemoService implements IDemoService &#123; @Override public String get(String name) &#123; return &quot;my name is &quot; + name; &#125;&#125; 核心思路：思路：首先我们要实现SpringMVC，思考下需要什么组件，第一肯定是IOC容器，暂时可以使用Map来代替。还有就是能通过url来找controller的这么一个路由器，我们也可以用一个Map来存。上面的注解是标记文件的，我们需要扫描这部分标记有注解的文件，我们需要利用反射初始化相关类的实例，放到Map中，并且我们还要实现属性注入功能。 初始化中我们需要做以下工作： 扫描配置文件 通过项目路径将注解相关的类，通过反射实例化 实现类中的属性注入功能 实现url与handler的映射，也即路由。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137public class GPDispatcherServlet extends HttpServlet &#123; private Map&lt;String, Object&gt; mapping = new HashMap&lt;String, Object&gt;(); @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; this.doPost(req, resp); &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; try &#123; doDispatch(req, resp); &#125; catch (Exception e) &#123; e.printStackTrace(); resp.getWriter().write(&quot;500 error&quot;); &#125; &#125; private void doDispatch(HttpServletRequest req, HttpServletResponse resp) throws IOException, InvocationTargetException, IllegalAccessException &#123; //获取请求url String url = req.getRequestURI(); String contextPath = req.getContextPath(); url = url.replace(contextPath, &quot;&quot;).replaceAll(&quot;/+&quot;, &quot;&quot;); if (!this.mapping.containsKey(url)) &#123; resp.getWriter().write(&quot;404....&quot;); &#125; Method method = (Method) this.mapping.get(url); Map&lt;String, String[]&gt; params = req.getParameterMap(); method.invoke(this.mapping.get(method.getDeclaringClass().getName()), new Object[]&#123;req, resp, params.get(&quot;name&quot;)[0]&#125;); &#125; //简易版本实现全部在一个方法中 @Override public void init(ServletConfig config) throws ServletException &#123; InputStream is = null; try &#123; Properties configContext = new Properties(); is = this.getClass().getClassLoader().getResourceAsStream(config.getInitParameter(&quot;contextConfigLocation&quot;)); //读取配置文件 configContext.load(is); String scanPackage = configContext.getProperty(&quot;scanPackage&quot;); //扫描配置路径下的类 doScanner(scanPackage); //实例化标有注解的类 for (String className : mapping.keySet()) &#123; if (!className.contains(&quot;.&quot;)) &#123; continue; &#125; Class&lt;?&gt; clazz = Class.forName(className); if (clazz.isAnnotationPresent(GPController.class)) &#123; mapping.put(className, clazz.newInstance()); String baseUrl = &quot;&quot;; if (clazz.isAnnotationPresent(GPRequestMapping.class)) &#123; GPRequestMapping requestMapping = clazz.getAnnotation(GPRequestMapping.class); baseUrl = requestMapping.value(); &#125; Method[] methods = clazz.getMethods(); for (Method method : methods) &#123; if (!method.isAnnotationPresent(GPRequestMapping.class)) &#123; continue; &#125; GPRequestMapping requestMapping = method.getAnnotation(GPRequestMapping.class); String url = (baseUrl + &quot;/&quot; + requestMapping.value()).replaceAll(&quot;/+&quot;, &quot;/&quot;); mapping.put(url, method); System.out.println(&quot;Mapped &quot; + url + &quot;,&quot; + method); &#125; &#125; else if (clazz.isAnnotationPresent(GPService.class)) &#123; GPService service = clazz.getAnnotation(GPService.class); String beanName = service.value(); if (&quot;&quot;.equals(beanName)) &#123; beanName = clazz.getName(); &#125; Object instance = clazz.newInstance(); mapping.put(beanName, instance); for (Class&lt;?&gt; i : clazz.getInterfaces()) &#123; mapping.put(i.getName(), instance); System.out.println(i.getName()); &#125; &#125; else &#123; continue; &#125; &#125; //进行类的属性注入 for (Object object : mapping.values()) &#123; if (object == null) &#123; continue; &#125; Class clazz = object.getClass(); if (clazz.isAnnotationPresent(GPController.class)) &#123; Field[] fileds = clazz.getDeclaredFields(); for (Field field : fileds) &#123; if (!field.isAnnotationPresent(GPAutowired.class)) &#123; continue; &#125; GPAutowired autowired = field.getAnnotation(GPAutowired.class); String beanName = autowired.value(); if (&quot;&quot;.equals(beanName)) &#123; beanName = field.getType().getName(); &#125; field.setAccessible(true); //对象的属性设置为value field.set(mapping.get(clazz.getName()), mapping.get(beanName)); &#125; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (is != null) &#123; try &#123; is.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; System.out.println(&quot;GP mvc init...&quot;); &#125; //扫描所有的类 private void doScanner(String scanPackage) &#123; URL url = this.getClass().getClassLoader().getResource(&quot;/&quot; + scanPackage.replaceAll(&quot;\\\\.&quot;, &quot;/&quot;)); File classDir = new File(url.getFile()); for (File file : classDir.listFiles()) &#123; if (file.isDirectory()) &#123; doScanner(scanPackage + &quot;.&quot; + file.getName()); &#125; else &#123; if (!file.getName().endsWith(&quot;.class&quot;)) &#123; continue; &#125; String clazzName = (scanPackage + &quot;.&quot; + file.getName().replace(&quot;.class&quot;, &quot;&quot;)); mapping.put(clazzName, null); &#125; &#125; &#125;&#125; 2.0 MVC1.0版本将所有的代码逻辑都写在init方法内，我们需要将相关的步骤抽取出来，进行优化 init方法123456789101112131415public void init(ServletConfig config) throws ServletException &#123; //加载配置文件 doLoadConfig(config.getInitParameter(&quot;contextConfigLocation&quot;)); //扫描类 doScanner(contextConfig.getProperty(&quot;scanPackage&quot;)); //反射实例化类 doInstance(); //注入 doAutowired(); //初始化url与方法映射关系 initHandlerMapping(); System.out.println(&quot;GP mvc init...&quot;);&#125; doLoadConfig方法1234567891011121314151617private void doLoadConfig(String contextConfigLocation) &#123; InputStream is = null; try &#123; is = this.getClass().getClassLoader().getResourceAsStream(contextConfigLocation); contextConfig.load(is); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (null != is) &#123; try &#123; is.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; doScanner方法递归扫描所有类，将扫描到的类到放到List中，后面需要进行实例化。 123456789101112131415private void doScanner(String scanPackage) &#123; URL url = this.getClass().getClassLoader().getResource(&quot;/&quot; + scanPackage.replaceAll(&quot;\\\\.&quot;, &quot;/&quot;)); File classDir = new File(url.getFile()); for (File file : classDir.listFiles()) &#123; if (file.isDirectory()) &#123; doScanner(scanPackage + &quot;.&quot; + file.getName()); &#125; else &#123; if (!file.getName().endsWith(&quot;.class&quot;)) &#123; continue; &#125; String clazzName = (scanPackage + &quot;.&quot; + file.getName().replace(&quot;.class&quot;, &quot;&quot;)); classNames.add(clazzName); &#125; &#125;&#125; doInstance方法实例化Bean，模拟将实例化的Bean放进IOC中，我们用一个Map来代替。 1234567891011121314151617181920212223242526272829303132333435private void doInstance() &#123; if (classNames.isEmpty()) &#123; return; &#125; try &#123; for (String className : classNames) &#123; Class&lt;?&gt; clazz = Class.forName(className); if (clazz.isAnnotationPresent(GPController.class)) &#123; Object instance = clazz.newInstance(); String beanName = toLowerFirstCase(clazz.getSimpleName()); ioc.put(beanName, instance); &#125; else if (clazz.isAnnotationPresent(GPService.class)) &#123; GPService service = clazz.getAnnotation(GPService.class); String beanName = service.value(); if (&quot;&quot;.equals(beanName)) &#123; beanName = toLowerFirstCase(clazz.getSimpleName()); &#125; Object instance = clazz.newInstance(); ioc.put(beanName, instance); for (Class&lt;?&gt; i : clazz.getInterfaces()) &#123; if (ioc.containsKey(i.getName())) &#123; throw new Exception(&quot;the &quot; + i.getName() + &quot; is exists&quot;); &#125; ioc.put(i.getName(), instance); &#125; &#125; else &#123; continue; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; doAutowired方法进行注入这一步我们将容器内的类取出来，通过反射将属性给拿到，通过扫描注解，再从容器中拿到相关的Bean然后注入到当前类的属性中。 1234567891011121314151617181920212223242526private void doAutowired() &#123; if (ioc.isEmpty()) &#123; return; &#125; for (Map.Entry&lt;String, Object&gt; entry : ioc.entrySet()) &#123; //取出所有的属性 Field[] fields = entry.getValue().getClass().getDeclaredFields(); for (Field field : fields) &#123; if (!field.isAnnotationPresent(GPAutowired.class)) &#123; continue; &#125; GPAutowired autowired = field.getAnnotation(GPAutowired.class); String beanName = autowired.value().trim(); if (&quot;&quot;.equals(beanName)) &#123; beanName = field.getType().getName(); &#125; field.setAccessible(true); try &#123; field.set(entry.getValue(), ioc.get(beanName)); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; initHandlerMapping方法这一步我们将所有Controller的方法拿到，并且拿到对应的url相对路径，并且将url与处理方法映射给保存起来，在请求路由的时候就根据url来找到相应的方法，通过反射执行对应方法。 1234567891011121314151617181920212223242526272829303132private void initHandlerMapping() &#123; if (ioc.isEmpty()) &#123; return; &#125; for (Map.Entry&lt;String, Object&gt; entry : ioc.entrySet()) &#123; Class&lt;?&gt; clazz = entry.getValue().getClass(); if (!clazz.isAnnotationPresent(GPController.class)) &#123; continue; &#125; String baseUrl = &quot;&quot;; if (clazz.isAnnotationPresent(GPRequestMapping.class)) &#123; GPRequestMapping gpRequestMapping = clazz.getAnnotation(GPRequestMapping.class); baseUrl = gpRequestMapping.value(); &#125; for (Method method : clazz.getMethods()) &#123; if (!method.isAnnotationPresent(GPRequestMapping.class)) &#123; continue; &#125; GPRequestMapping gpRequestMapping = method.getAnnotation(GPRequestMapping.class); String url = (&quot;/&quot; + baseUrl + &quot;/&quot; + gpRequestMapping.value()).replaceAll(&quot;/+&quot;, &quot;/&quot;); handlerMapping.put(url, method); &#125; &#125;&#125; doDispatch路由逻辑请求路由逻辑，思路是这样的，拿到请求url，通过url找到初始化的method，这时候就有了目标类的执行方法。接下来就是填充请求参数，填充完后执行method.invoke方法执行目标类的方法，完成请求。 12345678910111213141516171819202122232425262728293031323334353637383940414243private void doDispatch(HttpServletRequest req, HttpServletResponse resp) throws IOException, InvocationTargetException, IllegalAccessException &#123; String url = req.getRequestURI(); String contextPath = req.getContextPath(); url = url.replace(contextPath, &quot;&quot;).replaceAll(&quot;//+&quot;, &quot;/&quot;); if (!this.handlerMapping.containsKey(url)) &#123; resp.getWriter().write(&quot;404....!&quot;); &#125; //拿到url对应的controller请求方法 Method method = (Method) this.handlerMapping.get(url); //请求传进来的实参 Map&lt;String, String[]&gt; parameterMap = req.getParameterMap(); //取到形参类型 Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); //实参数组初始化 Object[] paramValues = new Object[parameterTypes.length]; //这里只处理String类型 for (int i = 0; i &lt; parameterTypes.length; i++) &#123; Class paramterType = parameterTypes[i]; if (paramterType == HttpServletRequest.class) &#123; paramValues[i] = req; continue; &#125; else if (paramterType == HttpServletResponse.class) &#123; paramValues[i] = resp; continue; &#125; else if (paramterType == String.class) &#123; Annotation[][] pa = method.getParameterAnnotations(); for (int j = 0; j &lt; pa.length; j++) &#123; for (Annotation a : pa[i]) &#123; if (a instanceof GPRequestParam) &#123; String paramName = ((GPRequestParam) a).value(); if (!&quot;&quot;.equals(paramName.trim())) &#123; String value = Arrays.toString(parameterMap.get(paramName)).replaceAll(&quot;\\\\[|\\\\]&quot;, &quot;&quot;).replaceAll(&quot;\\\\s&quot;, &quot;,&quot;); paramValues[i] = value; &#125; &#125; &#125; &#125; &#125; &#125; String beanName = toLowerFirstCase(method.getDeclaringClass().getSimpleName()); method.invoke(this.ioc.get(beanName), paramValues); System.out.println(method);&#125; 3.0 MVC待更","tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"},{"name":"Spring","slug":"Spring","permalink":"https://dogfun.top/tags/Spring/"},{"name":"从零开始写框架","slug":"从零开始写框架","permalink":"https://dogfun.top/tags/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%86%99%E6%A1%86%E6%9E%B6/"}],"categories":[{"name":"web","slug":"web","permalink":"https://dogfun.top/categories/web/"}]},{"title":"Nacos","date":"2020-09-25T01:25:02.000Z","path":"2020/09/25/中间件/nacos/","text":"Nacosdocker启动123git clone https://github.com/nacos-group/nacos-docker.gitcd nacos-dockerdocker-compose -f example/standalone-derby.yaml up SpringCloud+namespaces 添加命名空间 maven中定义多个环境profile 1234567891011121314151617181920&lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;runtime.env&gt;dev&lt;/runtime.env&gt; &lt;nacos.server-addr&gt;10.91.22.7:8888&lt;/nacos.server-addr&gt; &lt;nacos.namespace&gt;aa96c495-c8fa-4078-b159-556c08592786&lt;/nacos.namespace&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;local&lt;/id&gt; &lt;properties&gt; &lt;runtime.env&gt;local&lt;/runtime.env&gt; &lt;nacos.server-addr&gt;10.91.22.7:8888&lt;/nacos.server-addr&gt; &lt;nacos.namespace&gt;aa96c495-c8fa-4078-b159-556c08592786&lt;/nacos.namespace&gt; &lt;/properties&gt; &lt;/profile&gt; ![image-20210512144727556](/Users/carytseng/Library/Application Support/typora-user-images/image-20210512144727556.png) maven中指定生效的profile，idea的active-profile指定的是项目下的对应环境的profile，非nacos上的配置 spring.cloud.nacos.discovery.namespace指定注册到相应的命名空间的注册列表，默认会在public ![image-20210512144838409](/Users/carytseng/Library/Application Support/typora-user-images/image-20210512144838409.png)","tags":[],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://dogfun.top/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"Presto","date":"2020-09-25T01:25:02.000Z","path":"2020/09/25/中间件/presto/","text":"Presto介绍​ Facebook开发的分布式查询引擎，采用master-slave架构，由一个Coordinator节点，一个Discovery节点，多个Worker节点组成，Coordinator负责解析SQL，生成执行计划，分发执行任务给多个Worker节点，Worker节点负责实际执行查询任务。Worker节点启动后向Discovery Server服务注册，Coordinator从Discovery Server获得可以正常工作的Worker节点。 优势 完全基于内存的并行计算 流水线 本地化计算 动态编译执行计划 小心使用内存和数据结构 类BlinkDB的近似查询 GC控制 隐式类型转换手工处理：try_cast([] as []) 美团修改版：https://github.com/MTDATA/presto/commits/mt-0.60","tags":[],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://dogfun.top/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"Elasticsearch","date":"2020-09-25T01:25:02.000Z","path":"2020/09/25/数据库/es/","text":"环境搭建(docker)Elasticsearch12345docker run -p 9200:9200 -p 9300:9300 -d -e &quot;discovery.type=single-node&quot; --name elasticsearch \\-v /Users/carytseng/envir/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\-v /Users/carytseng/envir/elasticsearch/data:/usr/share/elasticsearch/data \\-v /Users/carytseng/envir/elasticsearch/plugins:/usr/share/elasticsearch/plugins \\ docker.elastic.co/elasticsearch/elasticsearch:7.12.0 Kibana1docker run --link elasticsearch:elasticsearch --name kibana -p 5601:5601 -d docker.elastic.co/kibana/kibana:7.12.0 常用命令12345678查看集群状态GET /_cat/health?v查询所有创建的索引GET /_cat/indices?v创建索引PUT [index] 数据类型 text keyword 查询 term：查询keyword类型，用于精确匹配。查询text类型若不知道分词器，会无法命中数据 比如查text类型，关键词”Quick Foxes!”，该数据被分为[Quick,Foxes]，会出现无法命中 用关键词”Quick”，则能查出，因此对于模糊查询要用match查text类型的数据 match：查询text类型，用于模糊查询 Nested es中object类型的数组会被扁平化，打破数组中对象属性的关联关系，需要定义nested即嵌套对象来处理数组，保证数组中的对象会被独立处理。 多层嵌套对象处理inner_hitsinner_hits是用于筛选出命中对象的对应属性，当层级过多时，条件中有多个inner_hits，需要使用name来防止覆盖问题 删除所有文档数据123456chinaunicom_medical_search_dev/_delete_by_query&#123;&quot;query&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;&#125;# curl -XDELETE &#x27;http://127.0.0.1:9200/logstash&#x27;","tags":[],"categories":[{"name":"数据库","slug":"数据库","permalink":"https://dogfun.top/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"放量下跌","date":"2020-09-10T07:14:47.000Z","path":"2020/09/10/金融/放量下跌/","text":"今日的市场放量下跌，现在持有500股21.95的招商证券下跌0.5，500股25.50的三安光电，没有精确拿到当天的低价，行情全日震荡幅度大，拿到这个筹码不算最好，但也算不错，留有30%的仓位等补仓用。前日受美股影响A股也下跌，今天突破了3260点下挫到3234附近，目前持有的基金收益已经亏损了，科技股受影响严重，也是因为之前重仓科技基金，只能说看错了入场点，但问题不大，中长期还是看涨的，毕竟大环境越差，股市肯定要逆行，年初放出的货币怎么也要流向股市的，只是看上层怎么控场了，既不想急速拉升把场子弄臭，也不想资金跑掉砸盘，这时候就看各个大资金大机构怎么做好这个工作了。平稳的一个点位一个点位往上调整，这也是符合大众对股票市场建立信心的。虽然手上拿点小钱在股票市场实践，但对于股票市场的风险，参与之后是深有体会，指数区间对于个股某个区间的价位十分难以把握，所以对于散户来讲，要拿到好的价位入场很难，在这种震荡市中，小资金用来走短线获利是十分有优势的，但同时一不小心就被套在高点了，所以散户只能说跟着趋势走，把握大趋势。从长远来看，手持蓝筹股是最稳的选择，走价值投资的路子。路漫漫其修远兮，学点理财技能，给出自己的判断观点，对于世界，经济趋势的把握十分有益，知行合一。","tags":[{"name":"投资","slug":"投资","permalink":"https://dogfun.top/tags/%E6%8A%95%E8%B5%84/"},{"name":"股票","slug":"股票","permalink":"https://dogfun.top/tags/%E8%82%A1%E7%A5%A8/"}],"categories":[{"name":"金融","slug":"金融","permalink":"https://dogfun.top/categories/%E9%87%91%E8%9E%8D/"}]},{"title":"牛市?","date":"2020-08-17T10:51:34.000Z","path":"2020/08/17/金融/牛市/","text":"8.17今天的股市红红火火，浙商证券在上周的震荡盘中，亏了6、7个点，后续也没有补仓，虽然看多，600股成本16.44，上周收盘15.50，一块钱的亏损，受可转债转股的影响，担心股价受影响，因此打算换股，看好招商证券20块的价位，但最终没有买入。今天证券板块拉升，招商当了把领头羊，涨停，虽然上周就看出来机构在打压股价，不断地低吸拉成本，可惜了，一波短线没有买入。今天的大盘站到3400以上，拉升过大，后面的量能支撑表示有所怀疑，k线站到了5日线以上，明天之后也会有所回调，今天将手上的浙商16.60清仓了，防止风险，没什么盈利，三安光电25.78的300股，今天到达29.50，比较满意，手上的持仓也没有满上。今天的行情就是撬动金融板块，拉升指数，个股普遍没有大涨，二八行情。后续应该是大盘的板块轮动，今天加仓了手上的科技基金，科技基金之前高拉减仓了，震荡行情中没有什么亏损，提前埋伏科技板，等大盘资金轮动的时候能吃点肉，顺应国家的慢牛行情，小股民跟着赚点小钱，还是要对股市有所敬畏，看好中国的资本市场。","tags":[{"name":"投资","slug":"投资","permalink":"https://dogfun.top/tags/%E6%8A%95%E8%B5%84/"}],"categories":[{"name":"金融","slug":"金融","permalink":"https://dogfun.top/categories/%E9%87%91%E8%9E%8D/"}]},{"title":"茶多酚的功效","date":"2020-08-15T03:37:32.000Z","path":"2020/08/15/个人思考/茶多酚的功效/","text":"茶多酚 英德特产绿茶，号称绿茶中的茶王，期间特别驱车前往本地试茶，相比红茶的烈性，绿茶的茶性比较收敛，就茶感上比较中性，对中枢神经的兴奋作用没有那么大，有促排，消肿的功效 ，个人本身有鼻炎，鼻甲长期处于肿胀的状态，喝绿茶发现鼻甲的肿胀有减缓，脸上的油脂减少，查阅相关资料，发现绿茶中的茶多酚含量相比其他茶种含量较高，因为绿茶的发酵程度低，故而茶多酚含量高。茶多酚对人体有多重功效，特别是一些慢性疾病有一定的疗效。 功效 抗氧化 抗炎，鼻炎患者能够有效消肿，对鼻腔的炎症有一定的抑制作用 抗高血脂 延缓衰老 防水肿、抗过敏","tags":[],"categories":[{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"}]},{"title":"建仓","date":"2020-08-07T08:51:55.000Z","path":"2020/08/07/金融/建仓/","text":"8.4入场建仓，300股的浙商证券，成本16.65，500股的三安光电，成本26.14。基本是买在跌位，8.6涨了一块钱，在8.7又猛跌猛拉，基本上没有多大的盈利，后续看好，持股不动。 8.11，今天尾盘跳水，将这段时间的收益吐回去了，尾盘还加仓了浙商证券，拉低成本到16.44，虽然大盘整体下挫，但是聪明的钱，北上资金净流入60亿，说明在买筹，还是看好后市，持股不动。","tags":[{"name":"投资","slug":"投资","permalink":"https://dogfun.top/tags/%E6%8A%95%E8%B5%84/"},{"name":"股票","slug":"股票","permalink":"https://dogfun.top/tags/%E8%82%A1%E7%A5%A8/"}],"categories":[{"name":"金融","slug":"金融","permalink":"https://dogfun.top/categories/%E9%87%91%E8%9E%8D/"}]},{"title":"观察者模式","date":"2020-07-14T01:44:08.000Z","path":"2020/07/14/设计模式/design-pattern-观察者模式/","text":"定义 定义对象的一种一对多的依赖关系，当一个对象的状态发生改变，所有依赖它的对象都得到通知并自动更新。 场景 当一个对象状态发生变化时，依赖的对象需要得到通知时使用。 代码被观察对象12345678910111213141516171819202122232425public class Subject &#123; //目标类保持所有观察者的引用，才能通知到 private List&lt;Observer&gt; observers = new ArrayList&lt;Observer&gt;(); private int state; public int getState() &#123; return state; &#125; //改变状态时，通知所有观察者 public void setState(int state) &#123; this.state = state; notifyAllObservers(); &#125; public void attach(Observer observer)&#123; observers.add(observer); &#125; public void notifyAllObservers()&#123; for (Observer observer : observers) &#123; observer.update(); &#125; &#125; &#125; 观察者抽象类1234public abstract class Observer &#123; protected Subject subject; public abstract void update();&#125; 实际观察者实现类123456789101112131415161718192021222324252627public class BinaryObserver extends Observer&#123; public BinaryObserver(Subject subject)&#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println( &quot;Binary String: &quot; + Integer.toBinaryString( subject.getState() ) ); &#125;&#125;public class OctalObserver extends Observer&#123; public OctalObserver(Subject subject)&#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println( &quot;Octal String: &quot; + Integer.toOctalString( subject.getState() ) ); &#125;&#125; 客户端12345678910111213public class ObserverPatternDemo &#123; public static void main(String[] args) &#123; Subject subject = new Subject(); new OctalObserver(subject); new BinaryObserver(subject); System.out.println(&quot;First state change: 15&quot;); subject.setState(15); System.out.println(&quot;Second state change: 10&quot;); subject.setState(10); &#125;&#125;","tags":[{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"入场梭哈","date":"2020-07-07T10:29:26.000Z","path":"2020/07/07/金融/入场梭哈/","text":"今天是7.7号，距离昨天开始宣传牛市启动仅一天之隔，作为一条韭菜，进场梭哈300股的招商证券，入手价是29.6，收市价是28.4，额……可以说进场就没了300多块钱，个人预期这波外资短时间不会那么快退场，因为资金吸水的作用还未曾达到，现在的资金来源是外资+机构在烘托，一波氛围烘托出来势必需要有人顶上，没错就是像楼主这样的韭菜，我的看法是现在还在中期，没到下跳的时候，如果我是外资，A股的股价这么低，加上长期的熊市周期，这波疫情下发的货币，总得有地方释放，没错，就是来圈释放的rmb，几天时间靠外资和机构拉到3300多点，剩下的就是要等散户进场，抬到3500以上，然后下跳。我个人预期股价到32块就清掉，不贪心，没错典型的韭菜思维，现在市场的空军是大于多军的，很多人在这波上涨中，吸取了年前的教训不恋战，及早止盈，离场，但我的看法还是那句话，增量的资金在对冲这些放量，大盘是下不来的，所以会造成及早下车的人在揪心少了几个点，其实都是没意义的，市场的变化太快没人能判断准，只要还在赌盘上，就没有赢家，我一直是这个思维，有人的地方就会一直有市场，有市场就会一直有买卖，资产总是放在那里，就看是否有交易的价值了，这些逃跑的资金我猜测它们的心理变化是会再度杀回来，而且会无比地猛烈，好了就看明天打脸了。 2020.7.8 今天最高跳到31块，股票公告说要停牌10天，10天后行情不知道啥样子，惊心动魄地在29.8抛了，净赚42块，第一次买股票，发现太刺激了，一上一下，几百块对于我这些小韭菜真觉得不是一般人能玩得起的，从7.1到现在，基金果断买了军工、消费、科技，刚好持有7天，而且是天天2-3个点的盈利，军工提前看好买了2000，才一周就17%的收益就很可怕的收益，从年前的经验来看，真的会来波跳水将这些收益给吸掉，现在的拉升是90°上升，这完全就是靠大资金拉上去的，到底场外资金的看客有多少不好说，看空的人都在等跳水进场收尸，如果市场完全无视呢，硬生生拉到3500点以上，那么也更加不敢进场了，营造出你不信我偏上的一种资本态度，还是要敬畏市场，适度止盈，还是那句话一天还在赌盘上，谁赢谁输还不好说。 2020.7.10 从6.30到今天，短短10天，2w的基金持仓，收益净赚2000，今天兑现收益，这收益率在平时可能要几个月才能达到，生生体会到资本的力量，只有兑现才真的是袋袋平安，今天的行情小幅度下跌，北向资金负流入了，昨晚美股大调整，说明这些天外资是在避险才把资金疯狂买入A股市场，现在已经是净流出了，个人看法是A股这波牛市行情快到点了，今天就兑现，提前避险，毕竟这些天的收益已经很满足了，留下一只长期看好的科技基金，持半仓，即使跌也跌不了多少，毕竟长期看好，后面跌下来再慢慢定投，相信时间的力量吧。","tags":[{"name":"投资","slug":"投资","permalink":"https://dogfun.top/tags/%E6%8A%95%E8%B5%84/"}],"categories":[{"name":"金融","slug":"金融","permalink":"https://dogfun.top/categories/%E9%87%91%E8%9E%8D/"}]},{"title":"单点登录","date":"2020-07-06T06:24:01.000Z","path":"2020/07/06/web/单点登录/","text":"定义 单点登录英文全称Single Sign On，简称就是SSO。它的解释是：在多个应用系统中，只需要登录一次，就可以访问其他相互信任的应用系统。 概览 客户端会访问三个系统中的一个，当初次登录Node2时，首先去sso验证登录，之后访问Node1、Node3都无须再次登录。 SSO登录流程 用户访问Node1，判断未登录。 跳转到CAS server，弹出登录页。 填写用户密码登录成功，session写入CAS server，将server ticket返回给客户端，客户端拿到ST去访问Node1。 Node1拿ST去CAS server验证有效性。 通过后Node1写入session并设置Cookie。","tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"}],"categories":[{"name":"web","slug":"web","permalink":"https://dogfun.top/categories/web/"}]},{"title":"策略模式","date":"2020-07-06T02:40:45.000Z","path":"2020/07/06/设计模式/design-pattern-策略模式/","text":"定义 类的行为在运行时可以更改，根据策略选择不同的执行算法。 什么时候使用 程序需要根据某个条件选择不同的执行方式时，一般会使用if/else分支逻辑，但不利于维护，如果只是执行方式不同，可以使用策略模式。 特点 避免多重判断，扩展性好。 代码 策略接口 123public interface Strategy &#123; public int exec(int n);&#125; 策略执行子类 1234567891011121314151617public class Add implements Strategy &#123; public int exec(int n)&#123; return n+1; &#125;&#125;public class Sub implements Strategy &#123; public int exec(int n)&#123; return n-1; &#125;&#125;public class Mul implements Strategy &#123; public int exec(int n)&#123; return n/1; &#125;&#125; 执行对象 1234567891011public class Context &#123; private Strategy strategy; public Context(Strategy strategy)&#123; this.strategy = strategy; &#125; public int executeStrategy(int n)&#123; return strategy.exec(n); &#125;&#125; 客户端 12345678910111213public class Client &#123; public static void main(String[] args) &#123; Context context = new Context(new Add()); context.exec(10); context = new Context(new Sub()); context.exec(10); context = new Context(new Mul()); context.exec(10); &#125;&#125;","tags":[{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"模板模式","date":"2020-07-01T02:48:58.000Z","path":"2020/07/01/设计模式/design-pattern-模板模式/","text":"定义 在一个抽象类中定义了方法的模板，子类可以按照需要重写，调用以抽象类中定义的方式执行。 什么时候使用 有一些通用的方法时，步骤基本一样，可以将通用的步骤抽象出来，具体的实现方法留给子类去实现。 特点 封装不变部分，扩展可变部分，提取公共代码。缺点是每一个不同的实现都需要一个子类实现，子类数量庞大。 代码 抽象模板类 123456789101112131415public abstract AbstractHouse&#123; final void decorate()&#123; //抽象出模板步骤，具体方法留给子类实现 decorateDoor(); decorateWall(); decorateWindow(); &#125; abstract void decorateDoor(); abstract void decorateWall(); abstract void decorateWindow(); &#125; 扩展实现类 123456789101112131415public class SubHouse&#123; void decorateDoor()&#123; System.out.println(&quot;装饰地板&quot;); &#125; void decorateWall()&#123; System.out.println(&quot;装饰墙面&quot;); &#125; void decorateWindow()&#123; System.out.println(&quot;装饰窗户&quot;); &#125; &#125; 客户端 123456public class Client&#123; public static void main(String args[])&#123; AbstractHouse house = new SubHouse(); house.decorate(); &#125;&#125;","tags":[{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"基金布局","date":"2020-06-30T04:20:39.000Z","path":"2020/06/30/金融/基金布局/","text":"上半年疫情看好的医疗板块，没有坚定持有，当时的想法是持有至六月份，判定依据是国内是最早稳定疫情的，外部环境的综合生产能力或者控制能力相对中国这种集大力办大事的处理能力肯定是完全不在一个等级上的，因此中国这个外贸型国家在一段时间内必然是医疗设备输出国，有需必有供，在此认为下半年医疗还是可以持有的。另外就是布局消费、航空、军工、科技。 在低净值开始针对消费，军工建仓，当前中国的地缘环境，在全球经济衰退的这个阶段，必然是背锅对象，近期的西部中印边境对峙，或者朝韩关系紧张，抑或东部台湾与日本，都是美国转移经济下行制造事端的一种潜在手段，中国势必会通过秀肌肉，加强军工产业，实战化演练来起到震慑周边国家的效果，因此军工相关的产业链会利好。至于消费或者航空，在经济下行的阶段，想将GDP20%外贸转内需，说实话，个人感受，在房价及物价飞涨的情况下，每个人或多或少都能感受到经济冲击的影响，必然会由消费走向储蓄，尽管政府的基调是通过内需来消耗掉，拉动消费，拉动经济增长，这是一个点，相对会有所增长，这是我判断的依据，但前面说了物价与房价决定了大多数人的消费心理，那么少部分消费基数在我看来是起不了大作用的，当前3%的通胀及银行如此低的利率。居民的心理必然会将钱拿出来投资，问题是钱会流向哪里？个人并不看好房产，一来是国家的定调，二来房产的泡沫没有对应的生产力与购买力，势必只是有价无市，只能是国家作为稳定市场的手段。所以我认为钱会流向股市，国内A股尚且处于低估值阶段，有很大的上升空间，这波上涨需要一个推力，我预估将会来自于外资。一个是稳定健康的市场环境，尽管政治上不待见，但对于资本家来说，资本无国界，国家也在营造一个健康的资本环境，为的也就是吸引外资，吸引国内的资本，推动股市上行，这样才能消解掉这次黑天鹅带来的危机，货币的市场流动性，社会分工的再循环，这才是重中之重。我的决策是消费航空军工开始建仓，逐步重仓医疗与科技，是成是败就看半年后回首今天写下的内容了。","tags":[{"name":"投资","slug":"投资","permalink":"https://dogfun.top/tags/%E6%8A%95%E8%B5%84/"},{"name":"基金","slug":"基金","permalink":"https://dogfun.top/tags/%E5%9F%BA%E9%87%91/"}],"categories":[{"name":"金融","slug":"金融","permalink":"https://dogfun.top/categories/%E9%87%91%E8%9E%8D/"}]},{"title":"原型模式","date":"2020-06-28T06:06:33.000Z","path":"2020/06/28/设计模式/design-pattern-原型模式/","text":"定义 根据原型实例创建对象的种类，并通过拷贝原型来创建新的对象。 实现方式 实现Cloneable接口。在java中实现了此接口的类才可以被拷贝。 重写Object的clone方法，Object的clone方法作用域是protected类型，需要重写修改作用域为public。 特点 比new对象性能好，clone方法调用本地方法复制对象。不会调用类的构造方法。clone方法只会浅拷贝，即是拷贝对象的基本数据类型，若要实现深拷贝，重写方法中需要针对数组、容器对象、引用对象做另外的拷贝。 代码 123456789101112131415161718192021222324252627282930class Prototype implements Cloneable &#123; private ArrayList list = new ArrayList(); public Prototype clone()&#123; Prototype prototype = null; try&#123; prototype = (Prototype)super.clone(); prototype.list = (ArrayList) this.list.clone(); &#125;catch(CloneNotSupportedException e)&#123; e.printStackTrace(); &#125; return prototype; &#125;&#125; class ConcretePrototype extends Prototype&#123; public void show()&#123; System.out.println(&quot;原型模式实现类&quot;); &#125;&#125; public class Client &#123; public static void main(String[] args)&#123; ConcretePrototype cp = new ConcretePrototype(); for(int i=0; i&lt; 10; i++)&#123; ConcretePrototype clonecp = (ConcretePrototype)cp.clone(); clonecp.show(); &#125; &#125;&#125;","tags":[{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"JSON Web Token","date":"2020-06-26T10:28:44.000Z","path":"2020/06/26/web/JSON-Web-Token/","text":"定义 是一种跨域认证的令牌技术。 解决场景 用户向服务器发送用户名和密码。 服务器验证通过后，则在session中保存用户的相关信息，如用户角色，权限等。 服务器返回一个sessionId给客户端 ，写入浏览器的cookie中。 用户的每次请求都带上seesionId。 服务端找到sessionId，知道用户的身份。 缺点：单机没问题，集群或者跨域，则需要session共享。一种方案是将session持久化，每个服务受到请求都请求持久层。 JWT的方案：服务端不在保存session，session保存在客户端，每次请求发送给服务端。 原理 服务端认证后，生成一个JSON对象给客户端，以后客户端就用这个对象去跟服务端交互，防止数据被篡改，需要对其进行签名，可以理解为配一对无法修改的钥匙，用户可以用其来开门。 数据结构 头部（header） 1234&#123; “typ”: “JWT”, “alg”: “HS256” &#125; 有效载荷（PayLoad） 1234567&#123; “iss”: “Online JWT Builder”, “iat”: 1416797419, “exp”: 1448333419, ……. “userid”:10001 &#125; 签名 将Header和Playload拼接生成一个字符串,str=“eyJhbGciOiJIUzI1NiJ9.eyJ1c2VyaWQiOjB9”，使用HS256算法和我们提供的密钥（secret,服务器自己提供的一个字符串）对str进行加密生成最终的JWT，即我们需要的令牌（token），形如：str.”签名字符串”。 交互过程 1、客户端通过用户名和密码登录 2、服务端进行鉴权，通过则返回token给客户端 3、客户端收到token后每次访问服务端都带上该token，相当于令牌表示有权访问 4、服务端一般会在网关验证token的合法性，若token合法，则允许请求，若token不合法或者过期，返回请求失败 JWT的时序图 验证token有效性 HS256加密算法：使用对称算法加密，共享同一个密钥，验证的时候，取头部和载荷base64后的字符串再使用该算法加密，将生成与传过来的签名比对，一致则有效。 RS256加密算法：使用非对称算法加密，提供方使用私钥加密后，生成签名，接收方使用公钥验证签名 特点 JWT默认不加密，可以生产token后再用密钥加密一次。 不加密时不能将敏感数据写入body。 可以降低服务端的查库压力，因为每次仅校验token。 缺点是token生成后续签难，且无法废弃。 尽可能使用https协议传输。 实践 项目架构是微服务架构，采用JWT鉴权与数据交互，采用RSA256非对称加密算法，统一通过gateway进行token的合法性校验。","tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"},{"name":"JWT","slug":"JWT","permalink":"https://dogfun.top/tags/JWT/"}],"categories":[{"name":"web","slug":"web","permalink":"https://dogfun.top/categories/web/"}]},{"title":"SpringMVC参数校验","date":"2020-06-26T10:28:44.000Z","path":"2020/06/26/web/Validator参数校验/","text":"参数校验依赖12345678910111213&lt;!--jsr 303 参数校验start--&gt;&lt;dependency&gt; &lt;groupId&gt;javax.validation&lt;/groupId&gt; &lt;artifactId&gt;validation-api&lt;/artifactId&gt; &lt;version&gt;1.1.0.Final&lt;/version&gt;&lt;/dependency&gt;&lt;!-- hibernate validator--&gt;&lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;version&gt;5.2.0.Final&lt;/version&gt;&lt;/dependency&gt;&lt;!--jsr 303 参数校验end--&gt; 123@Validated：在多个参数校验,或者@RequestParam 形式时候,需要在controller上加注@Validated@Valid：对象参数，存在嵌套，则在嵌套属性标识 验证注解 验证的数据类型 说明 @AssertFalse Boolean,boolean 验证注解的元素值是false @AssertTrue Boolean,boolean 验证注解的元素值是true @NotNull 任意类型 验证注解的元素值不是null @Null 任意类型 验证注解的元素值是null @Min(value=值) BigDecimal，BigInteger, byte,short, int, long，等任何Number或CharSequence（存储的是数字）子类型 验证注解的元素值大于等于@Min指定的value值 @Max（value=值） 和@Min要求一样 验证注解的元素值小于等于@Max指定的value值 @DecimalMin(value=值) 和@Min要求一样 验证注解的元素值大于等于@ DecimalMin指定的value值 @DecimalMax(value=值) 和@Min要求一样 验证注解的元素值小于等于@ DecimalMax指定的value值 @Digits(integer=整数位数, fraction=小数位数) 和@Min要求一样 验证注解的元素值的整数位数和小数位数上限 @Size(min=下限, max=上限) 字符串、Collection、Map、数组等 验证注解的元素值的在min和max（包含）指定区间之内，如字符长度、集合大小 @Past java.util.Date,java.util.Calendar;Joda Time类库的日期类型 验证注解的元素值（日期类型）比当前时间早 @Future 与@Past要求一样 验证注解的元素值（日期类型）比当前时间晚 @NotBlank CharSequence子类型 验证注解的元素值不为空（不为null、去除首位空格后长度为0），不同于@NotEmpty，@NotBlank只应用于字符串且在比较时会去除字符串的首位空格 @Length(min=下限, max=上限) CharSequence子类型 验证注解的元素值长度在min和max区间内 @NotEmpty CharSequence子类型、Collection、Map、数组 验证注解的元素值不为null且不为空（字符串长度不为0、集合大小不为0） @Range(min=最小值, max=最大值) BigDecimal,BigInteger,CharSequence, byte, short, int, long等原子类型和包装类型 验证注解的元素值在最小值和最大值之间 @Email(regexp=正则表达式,flag=标志的模式) CharSequence子类型（如String） 验证注解的元素值是Email，也可以通过regexp和flag指定自定义的email格式 @Pattern(regexp=正则表达式,flag=标志的模式) String，任何CharSequence的子类型 验证注解的元素值与指定的正则表达式匹配 @Valid 任何非原子类型 指定递归验证关联的对象如用户对象中有个地址对象属性，如果想在验证用户对象时一起验证地址对象的话，在地址对象上加@Valid注解即可级联验证","tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"},{"name":"JWT","slug":"JWT","permalink":"https://dogfun.top/tags/JWT/"}],"categories":[{"name":"web","slug":"web","permalink":"https://dogfun.top/categories/web/"}]},{"title":"调理脾胃","date":"2020-06-26T02:28:13.000Z","path":"2020/06/26/个人思考/调理脾胃/","text":"近来生活不规律，饮食好生冷，多熬夜，作息不规律，感觉脾胃瘀滞，气机不畅感明显。查阅中医相关资料，是为脾胃虚弱之症。 判定 舌头边缘有齿痕，湿气重，脾胃虚 食欲下降，转化率差 早起不适，起床就胸闷气短，头晕。 湿气重 如何养脾胃 忌生冷 忌多 忌忧思过度 适量服用归脾丸或补中益气丸提升脾胃的运化 慢跑运动提升血液循环，提升脾胃的运化能力，且能去除体内的湿气。 健康是革命的资本，关注健康，关注自我。","tags":[],"categories":[{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"}]},{"title":"FTP模式设置引发的问题","date":"2020-05-21T00:49:28.000Z","path":"2020/05/21/linux/FTP模式设置引发的问题/","text":"前言 最近写了一个程序使用FTP去服务器批量下载文件，按道理应该是比较简单的。但上了生产环境就发生了异常，程序下载的过程中莫名其妙进入假死状态，日志也没有继续打，起初以为是递归加载文件的时候找不到出口，后来经过排查原因是FTP的工作模式问题引起的。 FTP的工作模式FTP工作端口默认有两个，通常21是命令端口，20是数据端口，当混入主被动模式，数据端口就不一定是20了。 主动模式（PORT） 被动模式（PASV） 主动模式 FTP默认是启动主动模式，client与server的21端口建立连接后，client随机开放一个1024以上的端口，发送命令给server，告诉server我client将采用主动模式并开放端口，server主动连接并传输。 被动模式 不同点在于在建立了连接后，client发送pasv命令给server，server随机开放一个端口给client，简单说就是让server告诉client应该连接哪个端口来进行数据传输，server是被动等待client连接的。 分析 程序发生假死的原因是因为默认采用主动模式，当服务器连接客户端的传输端口时，有可能被客户端防火墙挡住，采用被动模式让服务端打开随机端口，被动等待客户端进行连接。","tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"}],"categories":[{"name":"linux","slug":"linux","permalink":"https://dogfun.top/categories/linux/"}]},{"title":"Linux文件删除原理","date":"2020-05-14T03:15:15.000Z","path":"2020/05/14/linux/Linux文件删除原理/","text":"Linux磁盘上的文件有两个link计数器，分别是i_count和i_link，表示进程的引用计数和硬连接的数量。只有当i_count=0并且i_link=0才会删除文件。当我们使用rm命令时，只是使i_link减少，如果此时文件依然被进程引用，文件还未被真正的删除。 实践场景 实现的一个功能点是通过FTP将文件从其他机子同步到本机，需要删除本机当日的数据，覆写新的数据，并且这些数据会被一个程序定时读取使用。这里的问题是如果此时程序正在读取数据，而同步程序也在跑，会不会影响业务。首先这里程序不涉及写操作，只读，那么当同步程序删除文件时，应用程序load到内存中，完成业务操作都是在内存中，当然如果发生程序异常，那么重跑也会以最新的文件为基础。","tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"Linux","permalink":"https://dogfun.top/tags/Linux/"}],"categories":[{"name":"linux","slug":"linux","permalink":"https://dogfun.top/categories/linux/"}]},{"title":"NetworkManager","date":"2020-05-14T03:15:15.000Z","path":"2020/05/14/linux/NetworkManager/","text":"1234567891011121314nmcli connection 网络连接管理$ nmcli connection show # 查看所有网卡配置$ nmcli connection reload # 重新加载网卡配置，不会立即生效$ nmcli connection down ens160 &amp;&amp; nmcli connection up ens160 # 立即生效Connection配置$ nmcli connection add type ethernet con-name ens160-con ifname ens160 ipv4.addr 1.1.1.2/24 ipv4.gateway 1.1.1.1 ipv4.method manual # 为device创建connection$ nmcli connection add type ethernet con-name ens160-con ifname ens160 ipv.method auto # dhcp$ nmcli connection modify ens160-con ipv.addr 1.1.1.3/24 &amp;&amp; nmcli connection up ens160-con # 修改IP地址并立即生效​交互方式修改IP$ nmcli connection edit ens160-con​nmcli device 网卡设备管理$ nmcli device status # 查看所有网卡设备状态$ nmcli device show ens160 # 查看网卡配置$ nmcli device reapply ens160 # 立即生效网卡配置","tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"Linux","permalink":"https://dogfun.top/tags/Linux/"}],"categories":[{"name":"linux","slug":"linux","permalink":"https://dogfun.top/categories/linux/"}]},{"title":"Kafka","date":"2020-05-14T03:15:15.000Z","path":"2020/05/14/中间件/kafka/","text":"Kafka消息队列作用解耦：降低系统间的耦合度，方便日后扩展 削峰：通过异步处理消息，并且提供多消费端来消费消息，达到削峰的作用 冗余 可恢复 Kafka特点Kakfa是一个分布式流处理平台，特点是高性能、分布式、高吞吐，底层写消息是顺序写磁盘，因此写入和读取速度非常快。大部分用于大数据处理平台和日志处理，其出身的原因也是LinkIn公司为了处理海量日志 支持消息模型 队列模型 同一个消息会被多个消费者一个个处理，不会重复处理 发布订阅模型 同一个消息会被所有消费者消费，类似通知 组件概念 topic：某队列的表示，同一类消息放入的queue partition：按照某个topic分多个分区，同一topic下的partition都会写入消息，提升消息处理的吞吐率 broker：消息服务器 Producers：Producer可以根据自己的选择发布消息到一个主题，Producer也可以自己决定把消息发布到这个主题的哪个Partition，当然我们可以选择API提供的简单的分区选择算法，也可以自己去实现一个分区选择算法。默认情况下，往一个topic发布消息，多个生产者会将消息均衡分配到topic下的每个partition，保证数据不会重复。 Consumers：消息传递通常由两种模式，queuing（队列）和publish-subscribe （发布-订阅） queuing：每个Consumer从消息队列中取走一个消息 pub-scrib:消息被广播到每个Consumer Kafka通过提供了一个对Consumer的抽象来同时实现这两种模式-ConsumerGroup。Consumer实例需要给自己指定一个ConsumerGroup的名字，如果所有的实例都用同一个ConsumerGroup名字，那么这些Consumer就会以queuing的模式工作；如果所有的实例分别用的不同的ConsumerGroup名字，那么它们就以public-subscribe模式工作。 如下图所示：含两台server的集群一共有p0~p3四个Partition，两个Consumer Group，在Group内部是以queuing的模式消费Partition，在Group之间是以pub-scrib模式消费。 消息顺序性： Kafka是如何确保消息消费的顺序性的呢？前面讲到过Partition，消息在一个Partition中的顺序是有序的，但是Kafka只保证消息在一个Partition中有序，如果要想使整个topic中的消息有序，那么一个topic仅设置一个Partition即可。 消费模型topic下的多个partition可以分布在多个broker中，一般N个partition分布在N个broker上，或者N个partition分布在M个broker，尽量保证N&lt;M，并且消费者数量&lt;=N，多余的消费者是拿不到partition的 副本机制Kakfa提供副本机制来保证高可用，副本不用于消费，仅用来冗余数据。比如一个topic有N个partition，分布在N个broker上。一个partition可以有多个副本，副本间有一个leader和多个follower，读写都是在leader中，follower和leader会保持数据同步。假设topic有3个partition设置3个副本，则第一个partition的数据会复制到2、3上，最简单的策略就是2存储1的数据副本，3存储2的数据副本，当某个broker宕了，则保证另外的broker中有数据冗余，这就保证了消息能继续消费，保证高可用 存在情况 假设leader所在的broker挂了，其他的follower还来不及同步消息，导致数据丢失，这种情况可以设置acks=all，表示当所有follower都收到该消息才算发送成功。 常用命令123456789101112#列出所有主题./kafka-topics.sh --list --zookeeper 10.15.8.79:2181#查看消息情况 ./kafka-topics.sh --zookeeper 10.15.8.79:2181 --describe --topic cameraTopicEER#生产消息./kafka-console-producer.sh --broker-list 10.15.8.79:9092 --topic cameraTopicEER#消费消息./kafka-console-consumer.sh —bootstrap-server 10.15.8.79:9092 —topic test —-from-beginning","tags":[],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://dogfun.top/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"布隆过滤器","date":"2020-05-12T09:19:22.000Z","path":"2020/05/12/web/布隆过滤器/","text":"布隆过滤器 在防止缓存穿透场景中，接触到布隆过滤器这个东西，总结下个人对这玩意的理解 组成简单来说，这个东西就是由一个bit数组和几个哈希函数组成，数组上只存放0或1，好处就是这个数组可以搞得非常大，毕竟bit数组，100w的数据，撑死 1000000Bit / 8 = 125000 Byte = 125000/1024 kb ≈ 122kb 的空间。 用法加入元素 加入元素先拿这个元素通过几个hash函数去算一下值，然后将数组上的这几个位置的值设为1 搜索元素 同样也是用这个元素通过几个hash函数去算一下值，然后判断数组上的这几个位置的值是否1，如果都为1，则说明元素存在，否则元素不在。存在的问题是有可能同一个元素算出同一个位置的值，存在误判的概率，但是如果存在不为1，则肯定是不存在这个元素。 解决场景 判断一个数字是否存在大量的数字集中 防止缓存穿透 邮件的垃圾邮件过滤、黑名单","tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"}],"categories":[{"name":"web","slug":"web","permalink":"https://dogfun.top/categories/web/"}]},{"title":"软件工程实践","date":"2020-05-09T13:01:01.000Z","path":"2020/05/09/个人思考/软件工程实践/","text":"在软件工程工作实践中，很多时候由于项目工期紧，一个需求提出后，由于急于落地结果，前期的需求调研的时间可能只有一两次的需求会议，作为开发人员，个人体会是在会议中陷入考虑编码和实现的思维中，往往这会造成开发人员对于需求的理解不准确，有时由于业务点或者业务规则过多，会给初次接触需求的开发人员过大的压力，从不理解需求开始，就开始实践编码，往往会造成不可避免的返工，如果团队有专业的需求分析人员，从需求分析人员到开发人员的沟通传递中，不可避免会遗漏信息，若果没有落地的需求文档，更加如此。因此在需求会议中应该以业务人员的角度，抛开开发人员的思维方式，无需考虑编码细节，因为这往往会影响我们的理解和会议的效果，站在对方的角度去思考，但需要考虑的是软件设计合理性，毕竟业务人员不懂技术，也不一定懂软件设计，必须引导用户，保证软件交互的合理性。 作为开发人员需要清楚需求才可动手，只有当手上输出了该有的设计文档开始编码才能做到胸有成竹，以文档来驱动开发的好处在于，当业务快速变化的时候，能够适时查阅新增的业务点对现有的业务流程和程序流程的影响会有多大，改动一个点会造成多大的影响。 从个人的实践来看，对于一个从零开始的需求，至少包含以下几个文档 1、业务需求文档，包含业务提出的所有需求点和业务规则。 2、程序流程图，需要开发根据业务需求说明书转化成程序流程图，程序流程可以作为与业务确认的稿件，保证设计方案不会与业务需求有较大的差距，最终的稿件应该是编码的可依据基础。 3、ER图，数据库表设计，这两个工具应该能确保扩展性，否则后续的加表返工设计数据表或者加表成本都会引发一系列的编码成本。 如果团队是需要应对快速变化的业务，那么引入敏捷开发的工程模式是比较适合的，当有了以上几个文档后，以最简单的方式构建代码架子，不考虑过多的设计，设计一个核心的架构，慢慢改进，不需要就干掉，交付最小成果，快速反馈业务人员，与业务人员探讨改进。","tags":[],"categories":[{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"}]},{"title":"投资思考","date":"2020-02-21T13:01:17.000Z","path":"2020/02/21/金融/投资思考/","text":"高度信息化的社会，身处巨大的信息洪流中，每个社会个体接触信息源的渠道丰富多样，有效甄别信息的有效性并能形成投资的决策根据。市场的变化来源于大众对于当下事态的反应，抓去这种心理变化，去洞察分析，进行投机获取相应的收益。 市场是自由交易的。 劳动产生报酬，个人对雇主负责，雇主角度来讲，只有当你的有效成果直接或间接促成公司收益，才是有效的，才能提高你的议价权。你的职位价格由市场供需关系确定，其上限最终会受限与市场整体的价位，除非你能够通过差异性综合提高公司收益，不仅仅你的职位能力。 投资性收入来源于个人对市场的把握，手段及渠道是多样化的，决策的正确根据对市场未来一段时间的预测，市场是敏感的，是大众心里变化的反映，如何从其中抽取对未来有效的信息源，并根据时势预估未来一段时间的市场变化，作出相应的投资决策，其正确性只能在你的收益中得到反映。","tags":[{"name":"理哲","slug":"理哲","permalink":"https://dogfun.top/tags/%E7%90%86%E5%93%B2/"}],"categories":[{"name":"金融","slug":"金融","permalink":"https://dogfun.top/categories/%E9%87%91%E8%9E%8D/"}]},{"title":"Web实时消息推送","date":"2019-12-20T02:43:34.000Z","path":"2019/12/20/web/Web实时消息推送/","text":"序 一个Web项目中，构建过一个消息推送服务，项目使用SpringCloud微服务架构，系统多数的业务场景是发送邮件通知系统用户，为了提高系统的用户粘度，希望通过系统内的实时通知来取代邮件服务。 WebSocket背景 ws出现之前，网站实时消息技术一般采用http轮询，这种方式缺点明显，由于http协议消息包含的头部信息较长其中的有效会消耗大量的带宽资源。ws通过兼容80和443端口来实现客户端与服务端的全双工通信。 特点 减少控制开销 更强的实时性 保持连接状态，是有状态协议 可以传输二进制数据 协议细节 客户端通过http协议发起连接请求，Upgrade字段是websocket，表明需要升级为ws进行通讯。 服务端收到请求后，返回101状态码表示理解，并返回Upgrade消息头表明采用ws来处理请求。 客户端请求头 12345678GET /chat HTTP/1.1Host: server.example.comUpgrade: websocketConnection: UpgradeSec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==Origin: http://example.comSec-WebSocket-Protocol: chat, superchatSec-WebSocket-Version: 13 服务端请求头 12345678GET /chat HTTP/1.1Host: server.example.comUpgrade: websocketConnection: UpgradeSec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==Origin: http://example.comSec-WebSocket-Protocol: chat, superchatSec-WebSocket-Version: 13 SpringBoot搭建WebSocket服务 最简单的消息推送模型，前端+后端服务对应客户端与服务端 依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt;&lt;/dependency&gt; 配置类123456789101112131415161718import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.socket.server.standard.ServerEndpointExporter;@Configurationpublic class WebSocketConfig &#123; /** * ServerEndpointExporter 作用 * * 这个Bean会自动注册使用@ServerEndpoint注解声明的websocket endpoint * * @return */ @Bean public ServerEndpointExporter serverEndpointExporter() &#123; return new ServerEndpointExporter(); &#125;&#125; 核心处理类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889import org.springframework.stereotype.Component;import javax.websocket.*;import javax.websocket.server.PathParam;import javax.websocket.server.ServerEndpoint;import java.io.IOException;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.atomic.AtomicInteger;@ServerEndpoint(&quot;/webSocket/&#123;sid&#125;&quot;)@Componentpublic class WebSocketServer &#123; //静态变量，用来记录当前在线连接数。应该把它设计成线程安全的。 private static AtomicInteger onlineNum = new AtomicInteger(); //concurrent包的线程安全Set，用来存放每个客户端对应的WebSocketServer对象。 private static ConcurrentHashMap&lt;String, Session&gt; sessionPools = new ConcurrentHashMap&lt;&gt;(); //发送消息 public void sendMessage(Session session, String message) throws IOException &#123; if(session != null)&#123; synchronized (session) &#123;// System.out.println(&quot;发送数据：&quot; + message); session.getBasicRemote().sendText(message); &#125; &#125; &#125; //给指定用户发送信息 public void sendInfo(String userName, String message)&#123; Session session = sessionPools.get(userName); try &#123; sendMessage(session, message); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; //建立连接成功调用 @OnOpen public void onOpen(Session session, @PathParam(value = &quot;sid&quot;) String userName)&#123; sessionPools.put(userName, session); addOnlineCount(); System.out.println(userName + &quot;加入webSocket！当前人数为&quot; + onlineNum); try &#123; sendMessage(session, &quot;欢迎&quot; + userName + &quot;加入连接！&quot;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; //关闭连接时调用 @OnClose public void onClose(@PathParam(value = &quot;sid&quot;) String userName)&#123; sessionPools.remove(userName); subOnlineCount(); System.out.println(userName + &quot;断开webSocket连接！当前人数为&quot; + onlineNum); &#125; //收到客户端信息 @OnMessage public void onMessage(String message) throws IOException&#123; message = &quot;客户端：&quot; + message + &quot;,已收到&quot;; System.out.println(message); for (Session session: sessionPools.values()) &#123; try &#123; sendMessage(session, message); &#125; catch(Exception e)&#123; e.printStackTrace(); continue; &#125; &#125; &#125; //错误时调用 @OnError public void onError(Session session, Throwable throwable)&#123; System.out.println(&quot;发生错误&quot;); throwable.printStackTrace(); &#125; public static void addOnlineCount()&#123; onlineNum.incrementAndGet(); &#125; public static void subOnlineCount() &#123; onlineNum.decrementAndGet(); &#125;&#125; 前端页面1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;!DOCTYPE html&gt;&lt;br lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;!--&lt;input type=&quot;text&quot; placeholder=&quot;channelId&quot; id=&quot;channelId&quot;&gt;&lt;input type=&quot;button&quot; value=&quot;连接&quot; onclick=&quot;link()&quot;&gt;&lt;input type=&quot;button&quot; value=&quot;关闭&quot; onclick=&quot;close()&quot;&gt;--&gt;&lt;input type=&quot;text&quot; placeholder=&quot;&quot; id=&quot;sendText&quot;&gt;&lt;input type=&quot;button&quot; value=&quot;发送数据&quot; onclick=&quot;send()&quot;&gt;&lt;/br&gt;&lt;textarea id=&quot;txa&quot; rows=&quot;10&quot; cols=&quot;30&quot;&gt;&lt;/textarea&gt;&lt;body&gt;&lt;/body&gt;&lt;script&gt; var ws var timer function send() &#123; var sendId = &quot;客户端&quot;; var text = document.getElementById(&#x27;sendText&#x27;); var txa = document.getElementById(&#x27;txa&#x27;); console.log(text.value); txa.value =txa.value + sendId+&quot;:&quot;+ text.value + &quot;\\n&quot;; ws.send(text.value); &#125; // 打开一个 web socket ws = new WebSocket(`ws://localhost:8080/webSocket/1`); ws.onopen = function () &#123; console.log(&quot;连接完成，可以发送数据&quot;); // 固定频率发送消息保持连接在线 /* timer = setInterval(() =&gt; &#123; ws.send(Date.now()) &#125;, 10000)*/ &#125;; ws.onmessage = function (evt) &#123; var received_msg = evt.data; console.log(&quot;数据已接收...&quot;); console.log(received_msg) &#125;; ws.onclose = function () &#123; // 关闭 websocket console.log(&quot;连接已关闭...&quot;); &#125;; ws.onerror = function (err) &#123; console.error(err) &#125; function close() &#123; if (ws === null || ws === undefined) &#123; alert(&quot;请先连接&quot;) &#125; ws.close() if (!timer) &#123; alert(&quot;请先连接&quot;) &#125; timer.clear() &#125;&lt;/script&gt;&lt;/html&gt; 微服务架构下session处理 由于WebSocket是有状态的，当前端与某个服务节点连接上后，只能与该节点进行通信。session也不能通过外部缓存，那么如果需要发送消息给某个用户，怎么找到用户所连的节点呢？ 定向分配 通过redis存储用户与连接节点的映射，当需要发送时，该路由表发送到真实节点，节点再转给用户。适合大型架构，精准投放消息。 MQ广播 使用MQ的订阅模式，所有服务节点订阅相同的主题，需要发送消息时，进行广播，节点收到消息后判断用户是否在自己的节点上，在则发送消息。这种方式适合小型架构。 引入RabbitMQ订阅推送消息 RabbitMQ的模型有生产者、交换机、消费者，主要有三种模式，Direct、Topic、Fanout模式 Direct模式 发送到DirectExchange的消息转发到RouteKey制定的Queue，RouteKey需要完全匹配。 Topic模式 根据通配符发送到相应的队列。 Fanout模式 广播模式，绑定到交换机上的队列都会收到消息。 实现的功能点 WebSocket的中继节点会有多个，我们希望的是每个中继节点订阅队列，消费同一批消息，将消息发送到当前节点的用户上。这里采用RabbitMQ的Fanout模式，随机生成多个队列名称绑定到同一个交换机上，该交换机上所有队列都能收到消息。 RabbitMQ配置类 123456789101112131415161718192021222324252627@Configurationpublic class FanoutRabbitConfig &#123; /** * 每个节点创建随机队列 * 将三个队列都绑定在交换机 fanoutExchange 上 * 因为是扇型交换机, 路由键无需配置,配置也不起作用 */ @Bean public Queue queueRandom() &#123; //可直接根据本机ip生成队列名 String queueName=&quot;random&quot;+ 2; return new Queue(queueName); &#125; @Bean FanoutExchange fanoutExchange() &#123; return new FanoutExchange(&quot;messageFanoutExchange&quot;); &#125; @Bean Binding bindingExchangeA() &#123; return BindingBuilder.bind(queueRandom()).to(fanoutExchange()); &#125;&#125; 消费者 12345678910111213@Slf4j@Componentpublic class MessageConsumer &#123; //直接关联交换机名称，消费其中一条随机队列 @RabbitListener(bindings = @QueueBinding( value = @Queue(), //注意这里不要定义队列名称,系统会随机产生 exchange = @Exchange(value = &quot;messageFanoutExchange&quot;, type = ExchangeTypes.FANOUT) ) ) public void process(String payload) &#123; log.info(&quot;receive:&#123;&#125;&quot;, payload); &#125;&#125; 消费幂等性​ 发送前进行入库，并且设置对应的消费状态；消费端也要判断是否存在该数据，存在且未消费则消费，否则丢弃。 消息发送确认机制 发送到exchange中会有个回调方法，可以在里面记录数据状态 消费确认机制 在消费端做了捕获，如果失败设置channel.basicNack(tag, false, true)，消息重新入队 消息重新投递 可以采用定时任务重新投递消息，引入重试机制","tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"},{"name":"WebSocket","slug":"WebSocket","permalink":"https://dogfun.top/tags/WebSocket/"}],"categories":[{"name":"web","slug":"web","permalink":"https://dogfun.top/categories/web/"}]},{"title":"GitFlow","date":"2019-11-11T10:24:58.000Z","path":"2019/11/11/git/gitflow实践/","text":"团队中使用git来做版本管理，为尽可能贯彻gitflow的实践，做个总结 提交代码原则 提交的粒度是一个小功能点或一个bugfix comment简练且描述清楚修改的位置或增加的功能 尽可能几次提交再进行一次推送 GitFlow master——最为稳定功能最为完整的随时可发布的代码； hotfix——修复线上代码的 bug； develop——永远是功能最新最全的分支； feature——某个功能点正在开发阶段； release——发布定期要上线的功能。 Master和develop需要保护起来，只有项目负责人可以推送和删除。 开发阶段​ 从develop拉取一条feature的新分支出来进行开发 完成开发阶段​ 在develop合并feature分支，创建release版本分支，发布测试环境。相关bug问题都在release分支修改，没问题后发布master分支 clear阶段​ 删除feature、release分支 生产环境bug处理​ 在master上创建hotfix分支，修改代码直接推，然后记得将hotfix分支合并到develop再删除hotfix，原则上要保证develop上的代码是最新的。因为在并行开发的阶段会有多种情况涉及对生产环境等代码的提交，而实践中开发人员很多时候没有定时更新feature分支，导致后面合并的时候将生产代码给覆盖了，引发生产问题","tags":[],"categories":[{"name":"git","slug":"git","permalink":"https://dogfun.top/categories/git/"}]},{"title":"linux","date":"2019-11-11T10:24:58.000Z","path":"2019/11/11/linux/linux/","text":"系统监控查看内存1free -h 查看磁盘空间 df -hl：查看磁盘剩余空间 df -h：查看每个根路径的分区大小 查看当前系统占用端口的进程信息1lsof -i :5900 目录管理目录与路径 . 当前目录 .. 上一层目录 - 前一次目录 ~ 当前用户所在home目录 操作目录 cd 切换目录 pwd 显示当前目录路径 mkdir 创建目录文件夹 -p 设置多层递归目录，创建不存在的子目录，例如：mkdir -p a/b/c -m 设置目录权限 -m 711 rmdir cp mv rm 查看文件内容 cat head tail 查看列表 ls -a ll 查询当前目录总大小 du -sh * 当前目录下查找文件 find . -name java.md 文件权限与目录1drwxr-xr-x 11 carytseng staff 352B 1 20 20:13 file drwxr-xr-x 第一个字符 rwx固定位置，可读、可写、可执行，第一个字符后9个字符分别为文件拥有者权限、文件所属组权限、其他人权限 -代表无权限 11：代表链接数 carytseng：文件拥有者 staff：文件所属用户组 352B：文件容量大小 20 20:13：创建日期或最近修改日期 权限设置群组列表 cat /etc/group chgrp [group] [file] 文件拥有者 cat /etc/passwd chown -R [owner] [file] 改变文件权限 数字型[r:4] [w:2] [x:1] chmod -R xyz [file] x:owner y:group others 1chmod -R 777 file 符号型改变 chmod u=rwx,go=rx [file] u:文件拥有者 g:文件用户组 o:其他用户 a:所有即三者 +:增加 -:去除 =:设定 12赋予文件执行权限chmod a+x [file] systemctl 主要用于管理服务，设置服务是否开机启动，服务的启动、停止、重启 服务管理 systemctl [command] [unit] command: status:查看状态 start:启动 stop:停止 restart:重启 reload:不关闭unit的情况下重新加载配置文件 enable:设置开机启动 disable:设置不开机启动 is-active:是否正在运行 is-enable:开机是有默认启动 查看所有服务 systemctl [command] [–type=TYPE] [–all] command: list-units list-unit-files type: service target socket Example:仅查看系统service类别的daemon systemctl list-units –type=service –all 日志grep -A -B -C 后面都跟阿拉伯数字-A是显示匹配后和它后面的n行。-B是显示匹配行和它前面的n行。-C是匹配行和它前后各n行。 1grep -A 4 wikipedia 密码文件.txt 文件打包压缩tar命令 参数解析 -c:建立打包文件 -x:解包/解压缩 -v:在压缩/解压缩的过程，将正在处理的文件名显示出来 -z:通过gzip来压缩/解压缩 -f:跟着被处理的文件名 12345#打包并压缩使用gziptar -zcvf filename.tar.gz [files]#解压缩tar -zxvf filename.tar.gz Firewall一、服务命令1234567891011121314查看版本：firewall-cmd --version开启、关闭firewallsystemctl start firewalld查看状态：systemctl status firewalld停止：systemctl disable firewalld禁用：systemctl stop firewalld 二、端口操作1234567891011121314151617181920212223242526查看打开的端口：firewall-cmd --list-ports打开一个端口：firewall-cmd --permanent --add-port=8080/tcp打开范围内端口：firewall-cmd --add-port=8989-9999/tcp --permanent关闭一个端口：firewall-cmd --permanent --remove-port=8080/tcp打开某项服务：firewall-cmd --permanent --add-service=http关闭某项服务：firewall-cmd --permanent --remove-service=http进行端口转发：firewall-cmd --permanent --add-forward-port=port=80:proto=tcp:toport=8080:toaddr=192.0.2.55允许转发到其他地址：firewall-cmd --permanent --add-masquerade重新加载防火墙：firewall-cmd --reload","tags":[],"categories":[{"name":"linux","slug":"linux","permalink":"https://dogfun.top/categories/linux/"}]},{"title":"x-ui","date":"2019-11-11T10:24:58.000Z","path":"2019/11/11/vps/x-ui/","text":"安装&amp;升级1bash &lt;(curl -Ls https://raw.githubusercontent.com/sprov065/x-ui/master/install.sh) x-ui 管理脚本使用方法:x-ui - 显示管理菜单 (功能更多)x-ui start - 启动 x-ui 面板x-ui stop - 停止 x-ui 面板x-ui restart - 重启 x-ui 面板x-ui status - 查看 x-ui 状态x-ui enable - 设置 x-ui 开机自启x-ui disable - 取消 x-ui 开机自启x-ui log - 查看 x-ui 日志x-ui v2-ui - 迁移本机器的 v2-ui 账号数据至 x-uix-ui update - 更新 x-ui 面板x-ui install - 安装 x-ui 面板 x-ui uninstall - 卸载 x-ui 面板bbr1234wget -N --no-check-certificate &quot;https://raw.githubusercontent.com/chiakge/Linux-NetSpeed/master/tcp.sh&quot; &amp;&amp; chmod +x tcp.sh &amp;&amp; ./tcp.shlsmod | grep bbr","tags":[],"categories":[{"name":"vps","slug":"vps","permalink":"https://dogfun.top/categories/vps/"}]},{"title":"jvm","date":"2019-11-11T10:24:58.000Z","path":"2019/11/11/java/jvm/","text":"JVM 程序计数器：指向下一条需要执行的字节码；记录当前线程的位置便于线程切换与恢复； 唯一 一个不会出现 OOM 的区域 虚拟机栈：描述了Java方法执行的内存模型，创建栈帧，保存该本地方法的局部变量表、操作数栈、动态链接、出口信息。 本地方法栈：描述 native 的方法执行，会创建栈帧。也保存了该本地方法的局部变量表、操作数栈、动态链接、出口信息。 堆：主要用于存放对象 为什么要分代：为了更好、更快的回收内存 老年代：占 2/3 新生代： 占 1/3 Eden： 占比 8 To： 占比 1 From： 占比 1 1.7 之前的方法区：存储已被加载的类信息、常量、静态变量、JIT 编译后的代码。包含运行时常量池。 从 JDK 1.7 开始 方法区不含运行时常量池，运行时常量池放到 堆 里面去了 字符串常量池也放到堆里面去了 并且，加载的类信息…等被转移到 堆 里面的运行时常量池中了 1.8 开始不存在永久代了 元空间：使用直接内存，理论上不会出现 OOM 了，当然内存要足。可以使用参数：-XX:MetaspaceSize来指定元数据区的大小，若不规定大小，会耗尽全部机器内存。 浅拷贝与深拷贝前言 一般在Java中我们创建一个对象是使用new关键字来创建的，new关键字会调用类的构造方法来创建对象，那么有一些场景我们想以现成的对象为模板来复制对象，回避构造函数的过程，毕竟构造函数中或多或少会有初始化的过程，性能难免较低，这时候就可以考虑使用拷贝，copy一个对象。 实例 以下这个类创建对象如果使用new关键字，调用构造函数会消耗较多时间。 123456789101112public class Person&#123; String name; int age; public Person()&#123; try&#123; //模拟构造函数初始化需要较多的性能 Thread.sleep(1000); &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; clone方法代替Person 我们如果想直接复制一个对象，使用现有对象，避免多余的代码，可以使用clone方法，这个是Object的方法，默认实现会返回现有对象的拷贝，但仅仅是浅拷贝。 浅拷贝：快速复制一个对象，底层调用的是本地方法，对于基本数据类型会直接复制到新对象，而对象类型，仅仅是将引用指向原有对象的地址空间，即是复制后的对象与复制前的对象，对象中的引用对象都是同一个对象。 12345678910111213141516171819202122232425262728public class Person implements Cloneable&#123; String name; int age; Vector v; public Person(String name,int age)&#123; try&#123; //模拟构造函数初始化需要较多的性能 Thread.sleep(1000); this.name=name; this.age=age; &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125; public static void main(String args[])&#123; Person p = new Person(&quot;Ben&quot;,20); p.v=new Vector(); Person c = (Person) p.clone(); log.info(p.name+&quot;:&quot;+p.age); log.info(c.name+&quot;:&quot;+c.age); log.info(&quot;&#123;&#125;&quot;,p==c); log.info(&quot;&#123;&#125;&quot;,p.v==c.v); &#125;&#125; 深拷贝：在浅拷贝的基础上，如果我们想把对象的对象类型也按照新的对象的创建，即分配一块新的内存空间，则需要在clone方法中重写相应的实现。 12345678910111213141516171819202122232425262728293031323334353637@Data@Slf4jpublic class CloneDemo &#123; static class Person implements Cloneable&#123; String name; int age; Vector v; public Person(String name,int age)&#123; try&#123; //模拟构造函数初始化需要较多的性能 Thread.sleep(1000); this.name=name; this.age=age; &#125;catch(Exception e)&#123; e.printStackTrace(); &#125; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; Person t = (Person)super.clone(); Vector vv = new Vector(); Collections.copy(vv,t.v); t.v=vv; return t; &#125; &#125; public static void main(String args[]) throws CloneNotSupportedException &#123; Person p = new Person(&quot;Ben&quot;,20); p.v=new Vector(); Person c = (Person) p.clone(); log.info(p.name+&quot;:&quot;+p.age); log.info(c.name+&quot;:&quot;+c.age); log.info(&quot;&#123;&#125;&quot;,p==c); log.info(&quot;&#123;&#125;&quot;,p.v==c.v); &#125;&#125; GC垃圾收集JVM针对堆中的对象，启用守护线程进行无用对象的回收，防止JVM的内存溢出造成程序不可用。 判断可否回收 引用计数法 简单来讲就是判断对象是否存在引用，没有则认为可回收，但若存在循环引用的情况，就无法判断导致内存泄漏 可达性分析 通过GC Roots对象作为起点进行搜索，如果一个对象与GC Roots之前没有可达路径，则认为该对象不可达，但还需要经过两次标记才能进行回收 强、软、弱、虚引用强引用：存在引用的对象就是强引用对象，gc即使溢出都不会收集这类对象 软引用：SoftReference对象，如果gc快溢出了，会收集这类对象 弱引用：WeakReference对象，不管gc空间是否足够都会回收 虚引用：主要用来跟踪垃圾回收器的活动 垃圾收集算法 复制算法 对内存分区，创建放一边，回收时存活的复制到另一边，然后对原来的空间直接清除。缺点是空间利用率不高，改进可按一定比例划分空间 标记清除算法 垃圾的对象标记起来，然后清除垃圾对象。缺点是容易产生内存碎片，导致大对象创建时，发生多次gc 标记整理算法 复制算法与标记清除算法的折中策略，标记垃圾对象，将存活的对象复制到边端，然后清除垃圾对象。 商业化虚拟机的方式采用分代收集算法，也即不同的年代采用不同的回收策略 新生代采用复制算法，按照一定的比例默认是8:1:1，分为Eden、From、To三个区域 Minor GC的过程：开始Eden和From都是空的，新建对象会创建在Eden，一次minor gc时，会把所有存活的对象放到From，清除Eden，下一次gc，Eden和From的存活对象移动到To，清空Eden和From，重复这个过程，当然在过程中会判断对象的年龄阈值，当达到一定的程度会移动到老年代 老年代采用标记整理算法 Full GC的过程：主要针对老年代的对象进行回收 垃圾收集器Serial 单线程，需暂停其他工作线程，复制算法，Client模式下默认新生代收集器 ParNew 多线程版本的Serial，同样需要暂停工作线程，Server模式下新生代收集器 Parallel Scavenge 关注吞吐量，即用户代码执行时间/(用户代码+回收时)，多线程。复制算法 Serial Old 单线程，采用标记整理算法 Parallel Old 多线程，标记整理算法，Parallel Scavenge的年老代版本 CMS 多线程标记清除算法，目标是获取最短垃圾回收停顿时间。优点在于并发收集、低停顿 初始标记 并发标记 重新标记 并发清除 G1相比CMS，改进 基于标记整理算法，不产生内存碎片 可以精确控制停顿时间","tags":[],"categories":[{"name":"java","slug":"java","permalink":"https://dogfun.top/categories/java/"}]},{"title":"nginx","date":"2019-11-11T10:24:58.000Z","path":"2019/11/11/中间件/nginx/","text":"一键安装脚本1234567891011#!/bin/bash echo &#x27;start install nginx...&#x27; wget http://nginx.org/download/nginx-1.10.2.tar.gz tar -xvf nginx-1.10.2.tar.gz cd nginx-1.10.2 yum -y install gcc pcre-devel openssl-devel ./configure make make install echo &#x27;install nginx successful.&#x27; 建立全局变量1ln -s /usr/local/nginx/sbin/nginx /usr/bin/nginx docker 安装1234docker run -d -p 80:80 -p 443:443 --name nginx --restart=always -e TZ=&quot;Asia/Shanghai&quot; \\-v /home/appuser/nginx/html:/usr/share/nginx/html \\ -v /home/appuser/nginx/conf/nginx:/etc/nginx/ \\ -v /home/appuser/nginx/log:/var/log/nginx nginx proxy_pass转发假设下面四种情况分别用 http://192.168.1.1/proxy/test.html 进行访问。 第一种：location /proxy/ { proxy_pass http://127.0.0.1/;}代理到URL：http://127.0.0.1/test.html 第二种（相对于第一种，最后少一个 / ）location /proxy/ { proxy_pass http://127.0.0.1;}代理到URL：http://127.0.0.1/proxy/test.html 第三种：location /proxy/ { proxy_pass http://127.0.0.1/aaa/;}代理到URL：http://127.0.0.1/aaa/test.html 第四种（相对于第三种，最后少一个 / ）location /proxy/ { proxy_pass http://127.0.0.1/aaa;}代理到URL：http://127.0.0.1/aaatest.html 隐藏Server头，docker镜像1FROM jboesl/docker-nginx-headers-more","tags":[],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://dogfun.top/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"git","date":"2019-11-11T10:24:58.000Z","path":"2019/11/11/git/git/","text":"一. 安装git sudo apt-get install git $ git config –global user.name “Your Name” ​ $ git config –global user.email “email@example.com“ 二. 创建版本库 git init git add：添加文件到缓存区 ​ git commit -m “”：提交文件到本地库 三. 基本操作 版本回退 ​ git log –pretty=oneline:查看版本 ​ git reset —hard HEAD^：返回上一版本 &lt;HEAD^^：上上版本. HEAD~100&gt; ​ git reflog：查看历史操作. 找到commit id 版本对比 ​ git diff：工作区和暂存区 ​ git diff —cached：版本库和暂存区 ​ git diff HEAD：工作区和版本库 撤销修改 ​ git checkout — file :回到最近的修改 一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态； 一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。 删除文件 ​ 删除了文件后，两种情况：1. 文件需要从版本库删除：git rm file . git commit 2. 文件误删需要恢复：git checkout — file 四. git分支管理 查看分支：git branch 创建分支：git branch 切换分支：git checkout 创建+切换分支：git checkout -b 合并某分支到当前分支：git merge 删除分支：git branch -d git合并分支默认使用fast forward模式，删除掉分支后，会丢掉分支信息。禁用merge时会产生一个新的commit。 五. 分支管理策略 六. bug分支 修复bug：若在master创建一个分支来进行修复，但当前dev上的工作没有提交，编码到一半。使用stash功能保留现场。 git stash：保留现场 git stash apply：恢复内容不删除，再通过 git stash drop git stash pop：恢复的同时把stash的内容也删除 git stash list：多次stash可使用该命令查看 git stash apply stash@{0} 七. Git创建项目并推送远程origin进入项目目录，初始化 git init 添加修改的文件 git add . 提交到本地仓库 git commit -m “” 连接到远程仓库 git remote add origin 本地变化连接到远程仓库 git pull origin master 推送到远程分支 git push -u origin master git status 八. 修改远程仓库地址方式一 git remote rm origin git remote add origin 你的新远程仓库地址 九. 统计代码提交1git log --author=&quot;郑剑锋&quot; --pretty=tformat: --numstat | awk &#x27;&#123; add += $1; subs += $2; loc += $1 - $2 &#125; END &#123; printf &quot;added lines: %s, removed lines: %s, total lines: %s\\n&quot;, add, subs, loc &#125;&#x27; -","tags":[],"categories":[{"name":"git","slug":"git","permalink":"https://dogfun.top/categories/git/"}]},{"title":"docker","date":"2019-09-15T02:14:13.000Z","path":"2019/09/15/docker/docker/","text":"脚本1234#方式1curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun#方式2curl -sSL https://get.daocloud.io/docker | sh 启动docker12sudo systemctl start dockersudo systemctl enable docker 授权普通用户docker运行权限1sudo usermod -aG docker [user] Dockerfile应用容器化 编写Dockerfile 在应用代码和Dockerfile目录下执行命令 docker image build -t test:latest 运行 docker container run -d —- name web1 —publish 8080:8080 test:latest Docker引擎 Docker采用模块化设计 Docker daemon实现了Docker API，基于HTTP 对容器的操作由containerd完成，containerd主要负责容器的生命周期管理，它指挥与OCI兼容的容器运行时来创建容器，runc是OCI容器运行时规范的实现，其基于Docker公司开发的Libcontainer与系统内核交互，Libcontainer是为了代替LXC，达到平台无关化。containerd调用runc，确保Docker镜像以OCI bundle的格式给runc。Docker daemon剩下的主要职责有API、镜像管理、身份认证、安全特性、核心网络等。 应用容器化 docker image build命令会读取Dockerfile,并将应用容器化。使用-t打标签，使用-f指定Dockerfile的路径和名称，-f指定任意路径下的任意名称的Dockerfile from指定构建的镜像的基础镜像 run用于在镜像中执行命令，每个run创建一个新的镜像层 copy将新的层添加到镜像中 EXPOSE用于记录应用所用的网络端口 ENTRYPOINT用于指定镜像以容器方式启动默认 常用命令镜像类123456789101112131415161718192021222324查看远程仓库镜像所有版本，需要安装jq工具处理json响应curl -s https://registry.hub.docker.com/v1/repositories/mysql/tags | jq | grep name | awk &#x27;&#123;print $2&#125;&#x27; | sed -e &#x27;s/&quot;//g&#x27;docker build --rm=true . 构建镜像docker pull $&#123;IMAGE&#125; 安装镜像docker images 显示已经安装的镜像docker images --no-trunc 显示已经安装镜像的详细内容docker rmi $&#123;IMAGE_ID&#125; 删除指定镜像docker rmi $(docker images | grep &quot;^&quot; | awk &quot;&#123;print $3&#125;&quot;) 删除所有没有标签的镜像docker rm $(docker ps -aq) 删除所有的镜像docker rmi $(docker images --quiet --filter &amp;quot;dangling=true&amp;quot;) 删除未使用的镜像docker save -o ubuntu_14.04.tar ubuntu:14.04 导出镜像，打出tar包cat ubuntu-14.04-x86_64-minimal.tar.gz |docker import - ubuntu:14.04 导入镜像sudo docker load --input ubuntu_14.04.tar = $ sudo docker load &lt; ubuntu_14.04.tar 载入镜像 容器类123456789101112131415161718192021222324252627docker run 运行容器docker ps 显示正在运行的容器docker ps -a 显示所有的容器docker stop $&#123;CID&#125; 停止指定容器docker stop docker ps -q 停止所有正在运行的容器docker ps -a --filter &amp;quot;exited=1&amp;quot; 显示所有退出状态为1的容器docker rm $&#123;CID&#125; 删除指定容器docker ps -a | grep wildfly | awk &#x27;&#123;print $1&#125;&#x27; | xargs docker rm -f 使用正则表达式删除容器docker rm -f $(docker ps -a | grep Exit | awk &#x27;&#123; print $1 &#125;&#x27;) 删除所有退出的容器docker rm $(docker ps -aq) 删除所有的容器docker inspect --format &#x27;&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;&#x27; $&#123;CID&#125; 显示指定容器的IPdocker attach $&#123;CID&#125; 进入容器docker exec -it $&#123;CID&#125; bash 进入容器打开一个shelldocker ps | grep wildfly | awk &#x27;&#123;print $1&#125;&#x27; 通过正则表达式查找容器的镜像ID 网络类12345678查看所有网络docker network ls创建自定义网络docker network create --driver bridge name查看指定网络详情docker network inspect [cid] 日志查询docker logs [option] [container] Options: –details 显示更多的信息 -f, –follow 跟踪实时日志 –since string 显示自某个timestamp之后的日志，或相对时间，如42m（即42分钟） –tail string 从日志末尾显示多少行日志， 默认是all -t, –timestamps 显示时间戳 –until string 显示自某个timestamp之前的日志，或相对时间，如42m（即42分钟） 12345查看从某个时间开始的日志docker logs -f -t --since=&quot;2018-02-08&quot; --tail=100 CONTAINER_ID查看时间段日志docker logs -t --since=&quot;2018-02-08T13:23:37&quot; --until &quot;2018-02-09T12:23:37&quot; CONTAINER_ID 资源占用分析12docker stats Docker-compose安装1234567891011sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose将可执行权限应用于二进制文件：sudo chmod +x /usr/local/bin/docker-compose创建软链：sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose测试是否安装成功：docker-compose --version 用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，您可以使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。 Compose 使用的三个步骤： 使用 Dockerfile 定义应用程序的环境。 使用 docker-compose.yml 定义构成应用程序的服务，这样它们可以在隔离环境中一起运行。 最后，执行 docker-compose up 命令来启动并运行整个应用程序。 docker-compose.yml1234567891011121314151617# yaml 配置实例# 指定使用docker-compose哪个版本version: &#x27;3&#x27;services: web: build: . ports: - &quot;5000:5000&quot; volumes: - .:/code - logvolume01:/var/log links: - redis redis: image: redisvolumes: logvolume01: &#123;&#125; 常用命令12345678//默认启动docker-compose up //指定文件启动 -f docker-compose -f docker-compose-redis.yml up -d//停止服务docker-compose down Docker-network bridge：桥接方式，宿主机与容器间的网络进行桥接，进行端口映射，共用ip host：去除宿主机与容器间的网络隔离，直接用宿主机的ip overlay：将多个Docker守护程序连接在一起，并使群集服务能够相互通信。 None：禁止联网 常用命令12345678#展示所有网络docker network ls#查看网络详情docker network inspect [id]#创建自定义网络docker network create --driver [bridge|host|overlay] [name] 场景选择 多个容器在同一个主机上通信，使用桥接。默认的桥接会加入同一个网络，生产上建议使用自定义的桥接网络 当不与主机隔离，直接使用主机网络 集群服务选择overlay 自定义桥接网络 创建桥接网络 1docker network create --driver bridge sample docker-compose.yml文件添加networks配置引入外部链接 1234567891011121314version: &#x27;2.1&#x27;services: zookeeper: container_name: zookeeper_kafka image: wurstmeister/zookeeper ports: - &quot;2181:2181&quot; networks: - sms #通过链接外部创建的网络networks: sms: external: true","tags":[],"categories":[{"name":"docker","slug":"docker","permalink":"https://dogfun.top/categories/docker/"}]},{"title":"装饰器模式","date":"2019-07-26T01:49:02.000Z","path":"2019/07/26/设计模式/design-pattern-装饰器模式/","text":"定义 用于向一个现有对象添加新的功能，同时不改变其现有结构。通过创建一个类的装饰类，包装原有类，并保证原有类的签名的前提下提供额外功能。 为什么及什么时候应用 一般拓展一个类的功能会先想到使用继承的基础上添加，但那样会对原有类的层级结构增添多个子类，且往往我们的需求仅仅是针对某个类做一下简单的功能拓展，而并不是为了定义一个新的子类。此时仅仅增加一个装饰类即可。 优点 装饰类和被装饰类能独立发展，不相互耦合。装饰模式是继承的一个替代，可以动态扩展一个实现类的功能。 代码 被装饰类接口 123public interface Shape &#123; void draw();&#125; 被装饰类具体实现 123456789101112131415public class Rectangle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Shape: Rectangle&quot;); &#125;&#125;public class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Shape: Circle&quot;); &#125;&#125; 装饰类抽象接口 1234567891011public abstract class ShapeDecorator implements Shape &#123; protected Shape decoratedShape; public ShapeDecorator(Shape decoratedShape)&#123; this.decoratedShape = decoratedShape; &#125; public void draw()&#123; decoratedShape.draw(); &#125; &#125; 装饰类具体实现 12345678910111213141516public class RedShapeDecorator extends ShapeDecorator &#123; public RedShapeDecorator(Shape decoratedShape) &#123; super(decoratedShape); &#125; @Override public void draw() &#123; decoratedShape.draw(); setRedBorder(decoratedShape); &#125; private void setRedBorder(Shape decoratedShape)&#123; System.out.println(&quot;Border Color: Red&quot;); &#125;&#125; 客户端 123456789101112131415161718public class Client &#123; public static void main(String[] args) &#123; Shape circle = new Circle(); ShapeDecorator redCircle = new RedShapeDecorator(new Circle()); ShapeDecorator redRectangle = new RedShapeDecorator(new Rectangle()); //Shape redCircle = new RedShapeDecorator(new Circle()); //Shape redRectangle = new RedShapeDecorator(new Rectangle()); System.out.println(&quot;Circle with normal border&quot;); circle.draw(); System.out.println(&quot;\\nCircle of red border&quot;); redCircle.draw(); System.out.println(&quot;\\nRectangle of red border&quot;); redRectangle.draw(); &#125;&#125;","tags":[{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"适配器模式","date":"2019-06-23T02:41:34.000Z","path":"2019/06/23/设计模式/design-pattern-适配器模式/","text":"将一个类的接口转换成客户端希望的接口，通常用于使用现有类适配新的系统接口。优点是复用现有类。 代码层面：适配器类继承或依赖已有的对象，实现想要的目标接口。 组成 关系 作用 客户接口 适配的接口 客户端想要的接口形式 现有目标类 现有的可被复用的类 提供现有接口实现 适配器类 实现目标接口，依赖目标类 实现目标接口，做接口兼容 客户接口 123abstract class Player&#123; void play();&#125; 目标类 12345class RgbPlayer&#123; public void specialPlay()&#123; //自有实现方法； &#125;&#125; 适配器类 123456789class PlayerAdapter extends RgbPlayer implements Player &#123; //也可以通过对象依赖的方式注入 //private RgbPlayer rgbPlayer; public void play()&#123; //转换并调用目标类的方法,比如换参数 this.specialPlay(); &#125;&#125; 客户端 123456public class Client&#123; public static void main(String args[])&#123; Player p = new PlayerAdapter(); p.play(); &#125;&#125;","tags":[{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"List遍历过程remove的ConcurrentModificationException","date":"2019-05-03T08:21:50.000Z","path":"2019/05/03/java/List遍历过程remove的ConcurrentModificationException/","text":"12345678ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();list.add(2);Iterator&lt;Integer&gt; iterator = list.iterator();while(iterator.hasNext())&#123; Integer integer = iterator.next(); if(integer==2) list.remove(integer);&#125; 以上代码List在遍历的过程中，通过判定索引，移除List的元素，程序抛出ConcurrentModificationException异常。 原因 在迭代器的实现中，checkForComodification()方法会检查List的modCount与expectedModCount的值，不相等则抛出该异常。我们调用的是List的remove方法， 可以看到程序修改了modeCount的值，但是没有修改expectedModCount的值，导致问题的产生。modCount表示List被修改的次数，expectedModCount表示期待值。 List的remove方法 123456789101112131415public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; 迭代器的遍历实现 12345678910111213141516public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i];&#125;final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException();&#125; 解决方案 调用iterator的remove方法取代List的remove方法， 该方法多了一步操作，expectedModCount=modCount。 1234567891011121314public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125;&#125;","tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"},{"name":"Java基础","slug":"Java基础","permalink":"https://dogfun.top/tags/Java%E5%9F%BA%E7%A1%80/"},{"name":"异常","slug":"异常","permalink":"https://dogfun.top/tags/%E5%BC%82%E5%B8%B8/"}],"categories":[{"name":"java","slug":"java","permalink":"https://dogfun.top/categories/java/"}]},{"title":"责任链模式","date":"2019-03-24T02:52:12.000Z","path":"2019/03/24/设计模式/design-pattern-责任链模式/","text":"用来处理相关事务责任的一条执行链，执行链上有多个节点，每个节点都有机会根据匹配条件处理事务，处理完就根据实际业务需求传递给下一个节点或者返回。 组成 抽象责任处理类 请求类 具体节点处理类 抽象责任处理类 123456789101112131415161718192021222324abstract class AbstractLeaveHandler&#123; /**直接主管审批处理的请假天数*/ protected int MIN = 1; /**部门经理处理的请假天数*/ protected int MIDDLE = 3; /**总经理处理的请假天数*/ protected int MAX = 30; /**领导名称*/ protected String handlerName; /**下一个处理节点（即更高级别的领导）*/ protected AbstractLeaveHandler nextHandler; /**设置下一节点*/ protected void setNextHandler(AbstractLeaveHandler handler)&#123; this.nextHandler = handler; &#125; /**处理请假的请求，子类实现*/ protected void handlerRequest(Request request)&#123; &#125;&#125; 请求类 1234567class Request&#123; public Request(int type)&#123; this.type=type; &#125; /**类型*/ private int type;&#125; 组长处理类 1234567891011121314151617181920class GroupManagerHandler extends AbstractLeaveHandler &#123; public GroupManagerHandler(String handlerName)&#123; this.handlerName=handlerName; &#125; protected void handlerRequest(Request request)&#123; if(request.getType = this.MIN)&#123; System.out.println(&quot;组长处理结束&quot;); return; &#125; if(null != this.nextHandler)&#123; this.nextHandler.handlerRequest(request); &#125;else&#123; System.out.println(&quot;审批拒绝！&quot;); &#125; &#125; &#125; 部门经理处理类 1234567891011121314151617181920class DeptManagerHandler extends AbstractLeaveHandler &#123; public DeptManagerHandler(String handlerName)&#123; this.handlerName=handlerName; &#125; protected void handlerRequest(Request request)&#123; if(request.getType = this.MIDDLE)&#123; System.out.println(&quot;部门经理处理结束&quot;); return; &#125; if(null != this.nextHandler)&#123; this.nextHandler.handlerRequest(request); &#125;else&#123; System.out.println(&quot;审批拒绝！&quot;); &#125; &#125; &#125; CTO经理处理类 1234567891011121314151617181920class CtoManagerHandler extends AbstractLeaveHandler &#123; public CtoManagerHandler(String handlerName)&#123; this.handlerName=handlerName; &#125; protected void handlerRequest(Request request)&#123; if(request.getType = CTO.MAX)&#123; System.out.println(&quot;CTO处理结束&quot;); return; &#125; if(null != this.nextHandler)&#123; this.nextHandler.handlerRequest(request); &#125;else&#123; System.out.println(&quot;审批拒绝！&quot;); &#125; &#125; &#125; 客户端 123456789101112public class Client&#123; public static void main(String args[])&#123; GroupManagerHandler g = new GroupManagerHandler(&quot;组长处理类&quot;); DeptManagerHandler d = new DeptManagerHandler(&quot;部门经理处理类&quot;); CtoManagerHandler c = new CtoManagerHandler(&quot;CTO处理类&quot;); g.setNextHandler(d); d.setNextHandler(c); Request rq=new Request(30); g.handlerRequest(rq); &#125;&#125;","tags":[{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"处世","date":"2018-07-13T13:01:27.000Z","path":"2018/07/13/个人思考/处世/","text":"当我们做一件事情的时候，不要寐心，可能很多时候为了达成目的，我们会着急，焦虑，眼看时间一点点在消逝，不得已而为之，未考虑清楚匆忙决定一件事情，最终发现事与愿违。当然太过谨慎思虑太多也会错失很多机会，青春给了我们试错的资本，敢于尝试是听得比较多的道理。 对人对事，得与失之间，权衡利弊而后之。而立之年，太多的困惑会阻挡人的前进方向，选择的方向往往比努力重要，想成为什么样子，想达到什么目标，三思而后行。我们处在一个环境中往往会带有局限性，限制我们的视野与思维，当你慢慢接触更优秀的人与其共事交流，会开阔自身的思维与境界，很多时候我们更愿意处于一个舒适区，不想跳出来，害怕这份稳定与安宁被打破，宁愿在内做最优解，但是这样人就会不知不觉被环境所同化，带有其土壤所熏陶的气息，很难打破。如果我们选择的东西不是我们内心所想要的，必定有所困惑，怀疑自身的态度与原则，必要的调解都无法按捺内心那股冲突。我们处于世上，有着自身的底线，跨越这个底线，抛弃原则，可能最终自己都无法认清自己的模样，何苦呢？ 人必要忠于自己而后立生处事，对人对事亦然。","tags":[],"categories":[{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"}]},{"title":"表我与自我","date":"2018-07-09T13:01:34.000Z","path":"2018/07/09/个人思考/表我与自我/","text":"当我们认知一个人，最快速的方式是通过外表，穿着，走姿，来刻画一个人在我们心目中的印象，标签化是我们短期内记忆一个人最快的方法，反之亦然。 一个人所呈现的表象是他想让我们看到的样子，表我和内我是截然不同的，在外界环境中，起作用的是表我，这个姿态是我们根据社会规则，道德伦理，他人所要求的样子所刻画出来的。形成一个人的表我，其行为细节，三观，态度等，其实都可以关联性分析。一个人最原生的自我来自于其原生家庭，所处的阶层，父母的教养，童年的经历，青春期的成长，都是塑造一个人的基石。其三观与原生家庭的教养会在社交细节中体现出来，其行为动机则需要关联构成其复杂性格的环境与经历。我们知道一个人的行事总是遵循其固定不变的性格构成，受动机和能力的制约，一个正常的人在其范围内作出的行为都是有根据的，处事，对人亦然。要了解一个人的自我，需要时间去了解，通过对其日常的行为细节，观其言察其色，对待一件事情的反应，面对责任时是推卸抑或主动承担。这些细节是掩饰不了的，会在其行为中体现出来。情商达练之人懂得在人群中把握分寸，与人相处时保持一种舒适的状态，适度展现自我在环境中的存在，但也往往成为其弱点。人与人相处时，其一言一行都会进入他人的印象中，言语是其动机产生的结果，达到一个如何的程度，希望事情走向一个什么样的结果，其实已经刻画在一个人的大致计划中，是其本我在事物发展过程当中的本能调控。这类动机行为是难以看穿的，因为当你不完全了解一个人时，这个结果你是无法推敲出来的。有一类人，处于人群中并不处于起眼的，但发生某事情时，为了调控事情走向，达到自我目的，会通过各类细节去调控，虽然抽象，但是若果最终的结果如他个人所愿，则必定有其达练之处。聪明人与聪明人交谈时，思维方式是跳跃的，正常人的交流顺序是按照123456，但聪明人之间交流的逻辑顺序是136，遵从跳跃式顺序。很多时候聪明人识破一个人的动机的时候，不会去揭穿，鉴于正常的社交尊重，让对方能够下台面或者利用话题周旋，若这个动机也是能够接受的范围内，且是双赢的，则会顺应对方的所求，有所求必有所图，这类人难以交心，其有着天生的防备心态，表面上关系融洽，但一旦希望关系深入时，你必然能感受到与对方的距离。大智若愚非常适用于形容高阶的聪明人，看似平淡无常，其背后的动机暗流涌动，当你对其产生疑惑但又无法说出个所以然来，这时候，明显的对方已经高你一阶。","tags":[],"categories":[{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"}]},{"title":"光阴似箭日月如梭","date":"2018-07-07T13:01:50.000Z","path":"2018/07/07/个人思考/光阴似箭日月如梭/","text":"光阴似箭，日月如梭，曾几何时写作文惯用的起手式只是应付当时那800字的心态加之自身时常慨叹时光易逝，因此，这两个四字词不知出现在我的作文里多少次。再次用起，总有一番不同的感觉。很多电影，很多文章，很多诗词，很多字句，当人有了一定的阅历后重新回味总会有一番不同的感受，如周星驰的电影，宫崎骏的动漫，童年1元杯的珍珠奶茶，街边小贩的牛杂，初高中写的文章，这种五味杂陈的感觉或许就是自身心智在不断成熟，对过去自我一种审视的反馈。不知不觉时间已到了2018，偶然间被叫了声叔叔犹感突兀，但貌似在提醒我已长大成人，95后的我们已经奔向社会，成为承担社会责任的一代，起承转合间备感压力，爱情婚姻，事业家庭，属于这个阶段去追求的东西，人生没有多少个十年，一个阶段又一个阶段的成长造就现在的我们，不断变化的自我与环境间的不断磨合，年轮棱角在角逐中被磨平，因此能够保持初心的人犹应珍惜。那一个个头顶掉发的中年大叔当年何不是意气风发的青年，带着梦想与期待步入社会，在生活面前，他们收起了那份锐气取而代之的是对生活的妥协，这或许是一种成熟吧，我不知道，但是自我抗拒成为他们，因此必须储备资本，你才有条件对生活说不，这个条件需要你为之付出，付出才有所得，任何事情亦然，空有目标而无执行力只是头脑发热之人的一时冲动，落实到逐步的目标实施中，有具体的可行性，才有机会达到想要的效果。 勤奋的含义是今天的热血，而不是明天的决心，后天的保证。","tags":[],"categories":[{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"}]},{"title":"存在即是合理","date":"2018-07-04T13:02:00.000Z","path":"2018/07/04/个人思考/存在即是合理/","text":"存在即是合理，当环境变换时，周遭的一切都不是你知悉的一切，快速投入到工作中，你会发现周围的一切都那么模糊，快速的工作节奏，工作的deadline压力，抬头发现已经忘记时间，夜色已经降临，只是生活还是在继续。走出大楼，那各色的人匆匆茫茫到底在奔向何方，憧憬着什么。有时你会发现人最可怕的地方是不知道自己想要什么，任由生活摆布。但成年人的世界有时又无可奈何，责任在身，上级的压力，慢慢的就能够去接受，去承担这种变化，无事一身轻或许是最潇洒的状态，摆摆手或者就能让自己的生活轻松点，但是人要懂得居安思危，时间是很残酷的，不知不觉你的青春、你的时间就已然流逝。 生活要有点盼头，有点目标，你就会去期待，这个过程必须改变自我，坚持着一些事情，养成良好的习惯，保持自律，一点一点的积累，相信会在不久的将来收到回报。","tags":[],"categories":[{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"}]},{"title":"杂谈","date":"2018-06-29T13:02:05.000Z","path":"2018/06/29/个人思考/杂谈/","text":"成长，爱情，婚姻，可能是20多岁这个年龄段比较苦恼的三件事情，一方面我们步向社会，慢慢适应社会的节奏，从学生到社会一员这一角色的转变，带着金字塔尖那份骄傲走出来，发现这份骄傲带给你的只有一时的光环作用，社会更看重个人价值，能力贡献，说白了就是等价交换，不管是技能、资本、人脉抑或其他可利用的资源，都被他人当作你的价值所在，你身上会自带一个标签，大家会利用那个标签来评判你的利用价值，这些都在人际交往的细节中能体现出来，社交就是一种互利互惠的活动，标签化印象化是你能给与他人对你认知最快的方式。在社会中不再像学生阶段般，大家都是平等地接受教育，学习，考试，以成绩来定论一个人。不得承认好多在校成绩优秀的学生进入社会会有一份失落感，不再以成绩来定论一个人的价值，而是多方面的能力，这能力是个笼统的概念，也即是如上所说，不再是你个人产生的影响，涉及到各个层面的关系，利用好这各方面的资源，对于个人的发展有各种好处。 关于爱情，私以为触不可及，也不算，只不过在遇到适合的人之前都不愿随便发展一段感情，毕竟爱情需要成本，不管感情上、精力上抑或经济上，很多时候，上层建筑是需要下层建筑来支撑的，这一点在初中政治课上早有认知，爱情亦然，这个社会越来越不相信爱情，讲究门当户对，高中课上年过半百的数学老师直言道，但我们不以为然，我们相信着那没有面包的爱情，纯真动人，可以为了爱不顾一切。但随着成长，你会发觉这个世界很不公平，爱情是一件很奢侈的东西，见过一些人和事，发现爱情有时不堪一击，那般脆弱，因为我们身处这个大环境中，我们的观念，视角不再受那书中狭隘的爱情观所枷锁，欲望在膨胀，观念在刷新，影响着我们的选择，我们的考虑。但不管如何，谁都享有爱情的权利，既然两情相悦，惺惺相惜，那就去体验吧，至少不会成为人生的一大遗憾。 关于婚姻，常听说婚姻是爱情的坟墓，貌似爱情的终点就是婚姻，成为枷锁两个人一生的苦链，我无法评判先辈的经验之谈，未到那个年纪未有那般体会也不好说什么。但至少我是向往婚姻的，婚姻应该是两个人爱情的结晶，是对彼此相依为命，厮守终生的一种承诺，未来的事情我们不能预测与知晓，但我们在那一刻的选择就是我们那一刻所相信着的想法，既然相信着那就相信自己的选择，一起去面对生活的柴米油盐，面对生活的欢声笑语。生活不可能永远一帆风顺，婚姻也如此，任何一段成功的婚姻无不是两个人共同参与，共同构建的结果，这其中的酸甜苦辣也只有你们两个知道，正是一起走过，一起面对，齐步并进，婚姻才会幸福而美满，只向往美好而不考虑艰辛，只憧憬快乐而忽视痛苦，那是自私者的想法 ，爱与被爱都是相互的，好的婚姻应当是相互扶持，相互关爱，包容理解，所以见到一些老年后依然彼此关爱，互相尊重的夫妻，才会感叹好的婚姻的难能可贵，因为生活的重担很容易消耗感情，消耗彼此的耐心，一旦风雨来临，就能见证婚姻的坚固性。 杂谈629","tags":[],"categories":[{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"}]},{"title":"写","date":"2018-06-28T13:02:10.000Z","path":"2018/06/28/个人思考/写/","text":"写，是一种心情，是一种态度，是对生活的思考，庆幸我生而为人，庆幸我学会了读与写，庆幸我有了思想，只需要一支笔，一个大脑便能对抗全世界，对抗消极的一切。当你有了写的冲动，那抑制不住的倾诉欲，涌现的灵感，流露的情绪只需执笔下纸。那文字是你面对生活的武器，是你激荡的思考留下的结晶，是你迸发的心情，是你不屈的态度，想写就写，有想法就写，多么惬意舒适，自由自在。你升华着，成长着，什么都无法阻挡枷锁你自由的思想，任其倾泻吧，那是你生活源源不断的动力，是面对困难的武器，是面对消极的解药。 给我一支笔，一个自由的思想，我不再畏惧。","tags":[],"categories":[{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"}]},{"title":"平常心","date":"2018-06-27T13:02:14.000Z","path":"2018/06/27/个人思考/平常心/","text":"世上有一些东西，是你自己支配不了的，比如运气和机会、舆论和毁誉，那就不去管它们，顺气自然吧！ 世上有一些东西，是你自己可以支配的，比如兴趣和志向、处世和做人，那就在这些方面好好地努力，至于努力的结果是什么，也顺气自然吧！ 我们不妨去追求最好——最好的生活、最好的职业、最好的婚姻、最好的友谊，等等。但是，是否得到最好，取决于许多因素，不是光靠努力就能成功。因此，如果我们尽了力，结果得到的不是最好，而是次好、次次好，我们也应该坦然地接受。人生原本就是有缺憾的，在人生中需要妥协。不肯妥协，和自己过不去，其实是一种痴愚，是对人生的物质。 在青年时期，人有虚荣心和野心是很正常的。成熟的标志是自我认识，认清了自己的天赋方向，于是外在的虚荣心和野心被内在的目标取代。 野心倘若肯下降为平常心，同时也就上升成了慧心。","tags":[],"categories":[{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"}]},{"title":"困顿与觉悟","date":"2018-06-24T13:02:23.000Z","path":"2018/06/24/个人思考/困顿与觉悟/","text":"人生的困惑无非色与空，色代表情感的困惑，空代表生命意义的困惑。想来想去，到头仍是困惑。不过想的好处是，在困惑中有了方向，困惑中的寻求形成了人的精神生活。因为色的诱惑，男人走向女人，女人走向男人，走进彼此的心灵，有色入情，于是有了爱。因为空的疑惑，人类呼唤世界之本相，由空入悟，于是有了哲学和宗教。 不去想人生的大问题，不是会快乐点吗？不是因为思考所以痛苦，而是因为痛苦所以思考。想不想不是自己能选择的，由天生的禀赋决定。想这类问题的人多半生性敏感而认真，实在身不由己，欲罢不能。 喜欢想人生问题的人，所谓喜欢想，并不是刻意去想，而是问题自己找上来，躲也躲不掉。想这类问题当然痛苦，但痛苦在先，你不去思考，痛苦仍然在，成为隐痛。既然如此，不如去面对它，看一看那些有智慧的人是怎么想这类问题的，开阔自己的思路，把痛苦变成人生的积极力量。","tags":[],"categories":[{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"}]},{"title":"存在的意义","date":"2018-06-24T12:10:27.000Z","path":"2018/06/24/个人思考/存在的意义/","text":"每个人生于世上，都不免会对自己存在的意义产生疑惑。不知何时有了意识，对这个世界有了清晰的认知，当问起自己这个问题时，仿佛呱呱落地的我们就在昨天，但今日我们已成为这个世界整体的一部分，不可否认的存在着。对于世界来讲，人是客体，对于人来讲，这个世界的一切都是客体。人作为一种有思考能力的动物，在进化的过程中区别与其他生物，我不免有疑惑我们的思维方式是否受限于我们的物质构成，如果将整个世界，扩大至宇宙，我们也不过是时间长河的一瞬，空间上的一点尘埃。换个角度，人不是这个世上的主体，也不过如其他物质，生物那般只是这个有机世界的一部分，以世界作为主体的角度来看，人与其他一切客体都是等同的，无非就是分子在不断运动，产生，分化，死亡。无他，也就是物质的形态以一种方式产生凋零转化为另一种形态。 每个人终其一生的寿命十分短暂，但走过的轨迹都是唯一的，认识的人经历的事情，我们身处这个时代，也受制于这个时代，我们享受着21世纪的便利，也遵循着社会运行法则，在这个车轮不停滚动的社会中生存，作为一种有思想的生物，我们接受的教育一方面完善我们的认知，但不可否认，一方面抑制了我们的思维。我们的三观，父母、老师的教育这些潜移默化的观念在我们青年时期已然写入我们的生命中，认知了世界的运行法则，然后在此之上，在生存着抑或有着各式各样的梦想，在个体生命中不断追逐。我们按照这个世界的规律，受教育，成长，工作，结婚，生子，退休，死亡，千篇一律，可能是每个人的轨迹路线了。 其实，对于每个个体来讲，体验一遍生命我认为就是其存在的意义，不管如何，这个世界有你存在的痕迹，到过，经历过，了解过，何其不是一种幸运，不管出生前的你处于什么，死亡后的你处于什么，你在这个起点与终点之间走过了一段路，感受自我与周遭世界的一切，那便是对于个体来讲存在的最大意义，放平心态，去感受生命的美好，感受世界带给你的风景，是我们作为人来讲最幸运的一种能力了。","tags":[],"categories":[{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"}]},{"title":"我们对待自己的态度","date":"2018-06-24T11:57:32.000Z","path":"2018/06/24/个人思考/我们对待自己的态度/","text":"一个人的个性越独特、越具价值和意义，那么，他就越有必要不时地认清自己生命总体发展的大致脉络和自己的计划，为此必须要踏上认识自己的道路，清楚自己的首要和真正的意愿——这些对于他的幸福而言是至关重要的东西，然后对于何者排在第二和第三位置必须心中有数。同时他也应该大致明白自己应该从事何种职业、需要扮演何种角色以及自己与这个世界的关系。如果一个人具备非凡的个性，那么，对自己的生命计划有一个大致的了解，能够比任何一切都更有效地增强自己的勇气，振作、鼓足信心，激励自己行动起来，避免走弯路。 只有登上峰顶才能够回头总体，连贯的看到自己所走过的迂回曲折的道路，同样，只有当我们度过了生命中的一段时间，或者在我们整体生命终结的时候，我们才能把我们做的事、业绩真正联系起来，包括其中的因果关联，甚至才能了解到它们的价值。只要我们置身其中，那我们的行事就只能总是遵循我们那固定不变的性格构成，受着动机的左右和我们能力的制约。由此可见，我们的行事自始至终都有其必然性。我们在每一刻都做着我们在那一刻认为合理和适当的事情，只有事后的结果才让我们看清到底发生了什么事；对事情整体的惠顾才使我们明白事情的如何和为什么。 人生的智慧的重要一点就是在关注现在和计划将来这两者之间达致恰到好处的平衡，这样，现在与将来才不至于互相干扰。许多人太过沉迷现在，这些是无忧无虑、漫不经心的人；也有的人则更多地活在将来，他们则是谨小甚微、忧心忡忡的杞人。人们很少能够在处理现在和将来两者当中把握一个恰到好处的尺度。那些以希望和努力生活在将来的人眼睛盯着前面，不耐烦地等待将要发生的事情，仿佛将来的事情才会为他们带来真正的幸福。在这期间，他们却对现在不予理会、不加咀嚼，听任现时匆匆逝去。 我们应该愉快地迎接现时此刻，从而有意识地享受每一可忍受的、没有直接烦恼和痛苦的短暂时光，也就是说，不要由于在过去我们的希望落空现在就变得忧郁寡欢，或者为了将来操心伤神以致和败坏现时。 对已经发生的 无论事情多么悲痛，我们必须让过去的事情成为过去，或许我们难以做到这一点，但我们必须降伏我们的乖僻心情。 对将来的事情 在上帝的安排之中。 应该把每一天都视为一段特别的生活。 我们只能为那些肯定发生的灾祸忧心，对于不可肯定的，我们必须养成习惯，把并不肯定发生的灾祸视为永远不会发生。 我们的安宁越少受到担忧和害怕的打扰，那它就越会被我们的愿望、欲念和期待所刺激。只有当人挣脱了所有各种可能的期望，从而返回赤裸和冰冷的存在本身，人才能领会到精神上的安宁，而精神的安宁却是幸福的构成基础。如果人要享受现时，乃至整个一生，精神的安宁是必不可少的。我们应该永远记住今天只有一次，它不会再来。但在我们的想象中，今天又在明天重现。其实明天又是另外的一天，它也只来一次。在我们患病、困顿的时候，每当念及在这之前没有疾病和痛苦的时光，就陡然让人心生羡慕——那些美好的日子就犹如不曾得到我们珍惜的朋友，它们简直就是失去了的天堂。在健康、美好的日子里，这种情形应被我们牢记在心，这样我们就会倍加珍惜和享受此刻的好时光。 我们的视线、活动和接触的范围越狭窄，我们就越幸福；范围圈子越大，我们感受的焦虑或者担忧就越多。因为随着这一范围圈子的扩大，我们的愿望、恐惧、担忧也就相应增加。痛苦是肯定的，幸福是否定的。我们感受到欢乐还是痛苦，归根到底取决于我们意识的内涵。我们的一生中，我们关系和目标的范围总是不断伸展。在童年时期，我们的视野只局限于周围的环境和狭窄的关系。到了青年，视野明显扩大；进入成年期，我们的整个生命轨迹，甚至最遥远的联系、别的国家和民族都被纳入我们的视线之内；局限制约有助于增进我们的幸福，原因就在于意欲受到的刺激越少，我们的痛苦也就越少。我们的生活关系应尽可能的简单，越少感觉到生活，并因此更少地感觉到生活的重负，重负本来就是生活的本质。这样生活流淌就像一条波澜不惊、旋涡不起的小溪。","tags":[],"categories":[{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"}]},{"title":"外观模式","date":"2018-05-27T01:41:00.000Z","path":"2018/05/27/设计模式/design-pattern-外观模式/","text":"定义 外部与一个子系统的通信通过一个统一的外观对象进行，为一组接口提供一个统一的界面，外部与其只通过这个抽象的接口，隐藏背后的复杂性。 解决场景 一般业务包含一系列复杂的子逻辑，需要调用各个子服务的接口才能完成既定的业务需求，为了让调用方可以透明调用且无需了解其背后的逻辑链路，通过封装一个一致的门面对象，提供必要的接口参数即可。 如下单功能，我们需要保存用户的下单记录，发送物流，保存订单这系列操作，我们可以封装一个订单接口，对外提供下单的接口，剩下的逻辑放在其中去做。调用方无需了解。 代码 门面接口 123public interface OrderService&#123; void saveOrder();&#125; 门面实现 12345678public class OrderServiceImpl implements OrderService&#123; UserService userService; DistribuService distribuService; void saveOrder()&#123; userService.saveBuyRecord(); distribuService.distriPackage(); &#125;&#125; 客户端 123456public class Client&#123; public static void main(String args[])&#123; OrderService service = new OrderServiceImpl(); service.saveOrder(); &#125;&#125;","tags":[{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"kafka生产重复消费问题","date":"2018-04-11T04:20:07.000Z","path":"2018/04/11/中间件/kafka生产重复消费问题/","text":"生产环境中kafka出现消息积压的情况，消费者重复消费的情况 分析 业务代码中消费端主要做消息存储与消息推送，http推数据。定位消费端的日志逻辑，发现http连接超时，应该是厂家设的推送地址有问题，导致超时。用的kafka版本是0.10.0，查阅了超时配置在10s，思路就改动消费端的逻辑，改成用线程池去异步推，把自动提交改成手动提交，解决了我的问题。 0.10.0以后的版本与消费者相关的几个重要参数 enable.auto.commit 默认值true，表示消费者会周期性自动提交消费的offset auto.commit.interval.ms 在enable.auto.commit 为true的情况下， 自动提交的间隔，默认值5000ms max.poll.records 单次消费者拉取的最大数据条数，默认值 500 max.poll.interval.ms 默认值5分钟，表示若5分钟之内消费者没有消费完上一次poll的消息，那么consumer会主动发起离开group的请求 使用0.10.0后的版本，重要的特性是多了个poll线程，一个心跳线程维持心跳，另一个poll线程拉取数据，当消费了拉取的数据后，消费端会重新poll。当超过指定时间没有poll，也即consume*条数&gt;poll的间隔时间就会发生rebalance","tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://dogfun.top/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://dogfun.top/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"代理模式","date":"2018-03-24T03:19:26.000Z","path":"2018/03/24/设计模式/design-pattern-代理模式/","text":"一个类代表另一个类的功能，创建现有对象的对象，向外提供功能接口。增加了中间层，目标对象职责明确，不同的代理类能够按照场景去做不同的额外业务操作，不影响被代理类的业务。 银行接口 123public interface Bank&#123; void saveMoney();&#125; 银行业务处理类 12345public class RealBank implements Bank&#123; void saveMoney()&#123; log.info(&quot;存款&quot;); &#125;&#125; 银行代理类 1234567891011121314public class ProxyBank implements Bank&#123; private RealBank realBank; void riskCaculate()&#123; log.info(&quot;风险评估&quot;); &#125; void saveMoney()&#123; riskCaculate(); realBank.saveMoney(); &#125; &#125; 客户端 123456public class Client&#123; public static void main(String args[])&#123; Bank bank = new ProxyBank(); bank.saveMoney(); &#125;&#125;","tags":[{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"ssr & ignite 搭建","date":"2018-02-26T06:37:47.000Z","path":"2018/02/26/vps/ssr-ignite-搭建/","text":"shadowsocks安装123456789yum -y updateyum -y install wgetwget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.shchmod +x shadowsocks.sh./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log 编辑：vi /etc/shadowsocks.json 启动：/etc/init.d/shadowsocks start 停止：/etc/init.d/shadowsocks stop 重启：/etc/init.d/shadowsocks restart 状态：/etc/init.d/shadowsocks status 卸载：./shadowsocks-go.sh uninstall bbr安装123456789wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.shchmod +x bbr.sh./bbr.sh#确认bbr开启lsmod | grep bbr SSR安装1234567891011yum -y install git yum --enablerepo=extras install epel-releaseyum -y install python-pipgit clone https://github.com/hao35954514/shadowsocksR-b.gitcd shadowsocksR-b/ bash initcfg.shsed -i &quot;s/API_INTERFACE = &#x27;sspanelv2&#x27;/API_INTERFACE = &#x27;mudbjson&#x27;/&quot; userapiconfig.py 使用说明: python mujson_mgr.py -a|-d|-e|-c|-l [选项( -u|-p|-k|-m|-O|-o|-G|-g|-t|-f|-i|-s|-S )] 操作: -a ADD 添加 用户 -d DELETE 删除 用户 -e EDIT 编辑 用户 -c CLEAR 清零 上传/下载 已使用流量 -l LIST 显示用户信息 或 所有用户信息 选项: -u USER 用户名 -p PORT 服务器 端口 -k PASSWORD 服务器 密码 -m METHOD 服务器 加密方式，默认: aes-128-ctr -O PROTOCOL 服务器 协议插件，默认: auth_aes128_md5 -o OBFS 服务器 混淆插件，默认: tls1.2_ticket_auth_compatible -G PROTOCOL_PARAM 服务器 协议插件参数，可用于限制设备连接数，-G 5 代表限制5个 -g OBFS_PARAM 服务器 混淆插件参数，可省略 -t TRANSFER 限制总使用流量，单位: GB，默认:838868GB(即 8PB/8192TB 可理解为无限) -f FORBID 设置禁止访问使用的端口 ​ – 例如：禁止25,465,233~266这些端口，那么这样写: -f “25,465,233-266” -i MUID 设置子ID显示（仅适用与 -l 操作） -s value 当前用户(端口)单线程限速，单位: KB/s(speed_limit_per_con) -S value 当前用户(端口)端口总限速，单位: KB/s(speed_limit_per_user) 一般选项: -h, –help 显示此帮助消息并退出 多用户的本地JSON数据库文件位置：shadowsocksR-b/mudb.json #添加用户 python mujson_mgr.py -a -u fuck -p 8989 -k panzer1230 -m aes-256-cfb -O auth_aes128_md5 -G 10 -o tls1.2_ticket_auth -s 10000 -S 10000 -t 10 #编辑用户 python mujson_mgr.py -e -u lightime -t 100 #以用户修改 python mujson_mgr.py -e -p 3333 -t 100 #以端口修改 #删除用户 python mujson_mgr.py -d -u lightime #以用户为依据删除 python mujson_mgr.py -d -p 3333 #以端口为依据删除 #其他操作 python mujson_mgr.py -l #查看所有用户信息 python mujson_mgr.py -l -u lightime #查看单个用户信息(包括流量使用情况) python mujson_mgr.py -c -u lightime #用户使用流量清零 #服务端控制 ./run.sh #后台运行 但不记录日志 ./logrun.sh #后台运行 且 记录日志 ./tail.sh #查看日志./stop.sh #停止服务端 go-ignite go-ignite是一个基于Docker实现，由Golang开发的多账户SS(R)管理面板。对用户来说，SS(R)服务被隔离在单独的容器中，安全高效，一键创建服务，简单方便。对管理员，提供后台管理页面，能够快捷的管理用户服务，重置流量等。 用户面板：支持创建 SS 和 SSR，但是仅提供自定义加密方式，且只能在初始化激活账号的时候，创建之后无法更改；SS 支持 AEAD 系加密；SSR 密码由随机生成、协议默认 auth_aes128_md5、混淆默认 tls1.2_ticket_auth_compatible。 管理面板：无法更改用户端口、服务类型；用户使用的端口并非随机创建。 因为需要使用 Docker，所以请使用非 OpenVZ 构架的 VPS 进行。 123456curl -sSL https://get.daocloud.io/docker | shservice docker startcurl -L https://get.daocloud.io/docker/compose/releases/download/1.19.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-composeusermod -aG docker root 12cd /optvi docker-compose.yml 通过ip访问123456789101112131415161718192021222324252627282930313233343536373839version: &#x27;3&#x27;services: ignite: container_name: ignite image: goignite/ignite volumes: - &quot;./data:/root/ignite/data&quot; - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; environment: - HOST_ADDRESS=8.8.8.8 # 此处修改为VPS IP，是展示在用户界面上的 SS/R 的连接 IP - HOST_FROM=5001 # SS/R 容器的起始可用端口范围，默认 5001 - HOST_TO=6000 # SS/R 容器的截止可用端口范围，默认 6000 ports: - &quot;80:5000&quot; # 用户界面访问端口，默认 80 restart: always ignite-admin: container_name: ignite-admin image: goignite/ignite-admin volumes: - &quot;./data:/root/ignite/data&quot; - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; environment: - AUTH_USERNAME=admin # 管理员用户名 - AUTH_PASSWORD=admin_password # 管理员密码 - Auth_SECRET=ignite2017 # 生成 JWT Token 的密钥，随便修改 ports: - &quot;8080:8000&quot; # 管理界面访问端口，默认 8080 restart: always 通过域名访问（中文为了说明，使用时请删除）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849 version: &#x27;3&#x27;services: nginx-proxy: container_name: nginx-proxy image: jwilder/nginx-proxy ports: - &quot;80:80&quot; # 访问端口，可以无需修改 volumes: - /var/run/docker.sock:/tmp/docker.sock:ro restart: always ignite: container_name: ignite image: goignite/ignite volumes: - &quot;./data:/root/ignite/data&quot; - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; environment: - HOST_ADDRESS=8.8.8.8 # 此处修改为 VPS IP，是展示在用户界面上的 SS/R 的连接 IP - HOST_FROM=5001 # SS/R 容器的起始可用端口范围，默认 5001 - HOST_TO=6000 # SS/R 容器的截止可用端口范围，默认 6000 - VIRTUAL_PORT=5000 - VIRTUAL_HOST=domain.com # 用户面板的访问域名 restart: always ignite-admin: container_name: ignite-admin image: goignite/ignite-admin volumes: - &quot;./data:/root/ignite/data&quot; - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; environment: - AUTH_USERNAME=admin # 管理员用户名 - AUTH_PASSWORD=admin_password # 管理员密码 - Auth_SECRET=ignite2017 # 生成 JWT Token 的密钥，随便修改 - VIRTUAL_PORT=8000 - VIRTUAL_HOST=admin.domain.com # 管理面板的访问域名 restart: always 123456789cd /optdocker-compose up -ddocker-compose up -d# 运行docker-compose down# 停止docker-compose pull# 更新","tags":[{"name":"ssr","slug":"ssr","permalink":"https://dogfun.top/tags/ssr/"},{"name":"ignite","slug":"ignite","permalink":"https://dogfun.top/tags/ignite/"}],"categories":[{"name":"vps","slug":"vps","permalink":"https://dogfun.top/categories/vps/"}]},{"title":"mysql","date":"2018-02-17T01:46:08.000Z","path":"2018/02/17/数据库/mysql/","text":"事务的定义 事务是数据库管理系统执行过程的一个逻辑单位，通俗地讲，一件事要么一次做完，要么不做。 事务的特性（ACID） 原子性（Atomicity）：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。 一致性（Consistency）：事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。 隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行。 持久性（Durability）：已被提交的事务对数据库的修改应该永久保存在数据库中。 例子 比如去银行存款这个事务，分为几个操作，首先查询账户余额，修改余额，然后提交，这就是一个事务。 事务隔离级别 事务与事务会共同影响同一条数据，比如两个人同时操作一个账户就会引发各种问题，隔离级别决定了两个事务同时操作的作用范围。 读未提交 事务A 事务B Begin Begin 更新id=3的数据status=true 查询id=3的数据，读到数据status=true Commit Commit 读已提交 事务A 事务B Begin Begin 更新id=3的数据status=true 查询id=3的数据，读到数据status=false Commit 查询id=3的数据，读到数据status=true Commit 可重复读 事务A 事务B Begin Begin 更新id=3的数据status=true 查询id=3的数据，读到数据status=false Commit 查询id=3的数据，读到数据status=false Commit 串行 事务A 事务B Begin Begin 更新id=3的数据status=true 查询id=3的数据，阻塞 Commit 查询id=3的数据，读到数据status=true Commit 事务的传播行为 从代码的层面上讲，就是方法的嵌套调用过程中，方法A对其子方法B的调用过程中，对其事务的影响范围。 PROPAGATION_REQUIRED：支持当前事务，假设当前没有事务。就新建一个事务 方法A调用子方法B，A自动起一个事务，如果B没有起事务，自动加入到A事务中。 PROPAGATION_SUPPORTS：支持当前事务，假设当前没有事务，就以非事务方式运行 方法A调用子方法B，B会看当前有没有事务，有则加入，无则以非事务运行 PROPAGATION_MANDATORY：支持当前事务，假设当前没有事务，就抛出异常 方法A调用子方法B，B会看当前有没有事务，有则加入，无则抛异常 PROPAGATION_REQUIRES_NEW：新建事务，假设当前存在事务。把当前事务挂起 方法A调用子方法B，B会起一个新事务，B的事务提交后，A的事务才会继续运行，B的事务失败回滚，A事务还是有可能提交 PROPAGATION_NOT_SUPPORTED：以非事务方式运行操作。假设当前存在事务，就把当前事务挂起 方法A调用子方法B，A事务挂起，B以非事务运行 PROPAGATION_NEVER：以非事务方式运行，假设当前存在事务，则抛出异常 方法A调用子方法B，B发现在A的事务中，就抛出异常 PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。 索引序 索引是数据库中为了提高数据查询速度而使用的一种数据结构，以一种结构化的存储方式来索引相关数据，达到快速查询的目的。通俗的讲类似书的目录，通过目录来查询数据效率会有极大提升。 数据结构 索引常用的数据结构： 哈希表 有序数组 搜索树 哈希表 适用于等值查询的场景，key通过哈希函数得到一个确定的位置，上面放对应的value。使用链表解决哈希冲突。不适合范围查询，因为需要全表扫描，无法利用索引完成排序，不支持多列联合索引的最左匹配规则，如果有大量重复键值的情况会产生哈希碰撞问题。 有序数组 只适用于静态搜索引擎，索引列的数据按照规则排序，查找数据可以直接二分查找，时间复杂度是O(log(N))支持范围查询。缺点是更新数据比较麻烦，需要移动记录。 搜索树 大部分数据库引擎采用这种数据结构，读写的性能优点适配磁盘的访问模式。搜索树的特点是左儿子节点的数据小于父节点，父节点小于右儿子节点，每个节点的多个儿子从左到右递增，查询的时间复杂度是O(log(N))。 InnoDB的索引模型采用B+树，是一种多路平衡查询树 分类 主键索引，也叫聚簇索引，叶子节点存整行数据。 非主键索引，叶子节点存放的是主键的值。 覆盖索引，索引上已经覆盖了查询的需求，无需回表。 区别：通过非主键索引查找非主键列的话，需要再用主键去主键索引查找相应的数据，这个过程叫回表，也就是多扫描一次索引树。 索引维护 B+树需要维护索引的有序，因此插入新值时需要维护，如果所在的数据页满了，则要申请一个新的数据页，然后将部分数据迁移过去，这个过程称为页分裂，反过来则称为页合并。 采用自增主键插入数据时，由于主键是递增的，因此索引新增都是以追加的方式，不会引起页分裂，如果采用业务逻辑字段做主键，不容易保证有序插入，写数据成本会很高。 最左前缀原则 索引的搜索匹配按最左前缀匹配，不管是联合索引还是字符串索引的最左M个字符，在构造索引树时，已经按照索引的定义去进行了排序，比如联合索引(a,b)，在存储上也当成一个字节数组，排序也是按字节去比较排序。这也就是为什么会是最左前缀原则生效的原因。 12345678910联合索引（a,b）#可以覆盖到aselect * from test where a=&#x27;cc&#x27;;#覆盖到a，覆盖不到b，因为中间用了%通配符select * from test where a=&#x27;cc%&#x27; and b=&#x27;dd&#x27;;#覆盖到a和bselect * from test where a=&#x27;cc&#x27; and b=&#x27;dd&#x27;; 索引下推 Mysql5.6之后在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。比如联合索引(a,b)，根据a,b条件先筛选出符合条件的数据再进行回表。 索引失效模糊匹配、类型隐转、最左匹配 %导致没有命中 参数类型跟sql查询的类型不一致，使用了函数 比如说组合索引，由a、b、c组成，查询c没法命中 如何排查慢查询根据explain执行计划，主要关注两个指标，一个是type，是全表还是范围查询，看key是否有命中索引，看rows，返回的行数 工作例子：一个报表查询，数据量100w左右，sql用到了聚合函数，临时表，查询速度到了几秒，通过explain分析，统计部分临时表的数据量很大，实际最后的结果集数据rows仅少量，索引也没有命中，走的是全表扫描，原表的日期用的是char来存，sql语句采用to_date()函数与传入的日期参数比较，导致索引失效，去除函数，并且对聚合查询做提前的条件过滤 创建索引12345678910111.PRIMARY KEY（主键索引）mysql&gt;ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` ) 2.UNIQUE(唯一索引)mysql&gt;ALTER TABLE `table_name` ADD UNIQUE (`column` ) 3.INDEX(普通索引)mysql&gt;ALTER TABLE `table_name` ADD INDEX index_name ( `column` )4.FULLTEXT(全文索引)mysql&gt;ALTER TABLE `table_name` ADD FULLTEXT ( `column` )5.多列索引mysql&gt;ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` ) SQL常用123456789101112131415161718192021/*sql: 去除数据库表中 tab、空格、回车符等特殊字符的解决方法去除 tab、空格、回车符等使用 replace 语句按照 ASCII 码*/SELECT char(64)/*例如 64 对应 @，则 */select REPLACE(‘abc@qq.com’,char(64),’kk’)/*则结果为 abckkqq.com*//*依此类推，去掉其他特殊符号，参考 ASCII 码对照表，去掉 tab 符号为*/ select REPLACE(‘要替换的字符或列名’,char(9),’替换的目标字符’)/*去掉空格符号为*/ select REPLACE(‘要替换的字符或列名’,char(32),’替换的目标字符’)/*去掉换行符号为*/ select REPLACE(‘要替换的字符或列名’,char(10),’替换的目标字符’)*/ 获取近12个月123456789101112SELECT DATE_FORMAT(CURDATE(), &#x27;%Y-%m&#x27;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 1 MONTH), &#x27;%Y-%m&#x27;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 2 MONTH), &#x27;%Y-%m&#x27;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 3 MONTH), &#x27;%Y-%m&#x27;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 4 MONTH), &#x27;%Y-%m&#x27;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 5 MONTH), &#x27;%Y-%m&#x27;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 6 MONTH), &#x27;%Y-%m&#x27;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 7 MONTH), &#x27;%Y-%m&#x27;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 8 MONTH), &#x27;%Y-%m&#x27;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 9 MONTH), &#x27;%Y-%m&#x27;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 10 MONTH), &#x27;%Y-%m&#x27;) AS `month` UNION SELECT DATE_FORMAT((CURDATE() - INTERVAL 11 MONTH), &#x27;%Y-%m&#x27;) AS `month` concatlength()UUID()有时需要对表里的批量数据设置主键uuid，要求每条数据的uuid都不一样。 一、方法： UPDATE table SET id=UUID(); UPDATE table SET id=REPLACE(id, ‘-‘, ‘’); 批量修改表字段排序规则12345678910111213#改变字段数据SELECT TABLE_SCHEMA &#x27;数据库&#x27;, TABLE_NAME &#x27;表&#x27;, COLUMN_NAME &#x27;字段&#x27;, CHARACTER_SET_NAME &#x27;原字符集&#x27;, COLLATION_NAME &#x27;原排序规则&#x27;, CONCAT( &#x27;ALTER TABLE &#x27;, TABLE_SCHEMA, &#x27;.&#x27;, TABLE_NAME, &#x27; MODIFY COLUMN &#x27;, COLUMN_NAME, &#x27; &#x27;, COLUMN_TYPE, &#x27; CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;&#x27; ) &#x27;修正SQL&#x27; FROM information_schema.`COLUMNS` WHERE COLLATION_NAME RLIKE &#x27;utf8mb4_0900_ai_ci&#x27; 时间处理字符串转日期-STR_TO_DATE 1select install_time from rs_device where install_time &gt;= STR_TO_DATE(&#x27;2021-06-25 03:15:00&#x27;,&#x27;%Y-%m-%d %H:%i:%s&#x27;) 日期转字符串-DATE_FORMAT 1select * from rs_device where DATE_FORMAT(install_time,&#x27;%Y-%m-%d %H:%i:%s&#x27;) &gt;= DATE_FORMAT(CURRENT_DATE,&#x27;%Y-%m-%d %H:%i:%s&#x27;) count的用法count(*)、count(id)、count(1)、count(字段)的区别，针对MySQL count(id)，InnoDB会遍历整张表，把每行的id取出来，返回给server层，判断不为空，按行累计。 count(1)，InnoDB会遍历整张表，每行放数字1进去，返回给server层，判断不为空，按行累计。 count(字段) 如果字段定义为not null，一行行取出这个字段，判断不能为null，按行累加。 如果字段定位为null，那么取的时候需要判断一下，不为null才累加。 count(*)，不会取全部字段，因为肯定不是null，直接按行累加。 效率：count(字段)&lt;count(主键id)&lt;count(1)≈count(*)。尽量使用count(*) Navicat更新数据MySQL是默认提交事务的，所以写query时，如果写了条update是直接提交的，如果想回滚怎么办？只能找binlog非常麻烦。正确的姿势应该是在query页中，提前set autocommit=0，也就是关闭自动提交，但这仅在当前query页中生效，重启或者打开新标签页会失效，然后你的update语句需要显式commit才能提交，这样你能在commit前select一下查看当前执行结果，Innodb的隔离级别默认是可重复读的，所以能读到当前事务下的数据结果，如果不对就执行rollback。 分区 查看分区详情 12SELECT PARTITION_NAME,PARTITION_METHOD,PARTITION_EXPRESSION,PARTITION_DESCRIPTION,TABLE_ROWS,SUBPARTITION_NAME,SUBPARTITION_METHOD,SUBPARTITION_EXPRESSIONFROM information_schema.PARTITIONS WHERE TABLE_SCHEMA=SCHEMA() AND TABLE_NAME=&#x27;base_resident_vmcard&#x27;; SQL优化优化原则 不要超过5个表以上的表连接 使用临时表存放中间结果 减少使用子查询 表连接前提前过滤数据，避免使用select* IN与NOT IN操作符改操作符oracle会将其转换为多表连接，改为exists SELECT * FROM TBL_REBATE_DAY_COUNT WHERE ID IN (1, 2, 3, 4, 5); SELECT * FROM TBL_REBATE_DAY_COUNT a WHERE exists(SELECT * ​ FROM TBL_ALGO_RECORD b WHERE a.ID = b.ID); IS NULL或IS NOT NULL任何包含NULL值的列都不会包含在索引中。可以使用其他操作运算符替代，改为a&gt;0或a&gt;’’ &gt; 及 &lt; 操作符（大于或小于操作符）大于或小于操作符一般情况下是不用调整的，因为它有索引就会采用索引查找，但有的情况下可以对它进行优化，如一个表有100万记录，一个数值型字段A，30万记录的A=0，30万记录的A=1，39万记录的A=2，1万记录的A=3。那么执行A&gt;2与A&gt;=3的效果就有很大的区别了，因为A&gt;2时ORACLE会先找出为2的记录索引再进行比较，而A&gt;=3时ORACLE则直接找到=3的记录索引。 LIKE操作符前置匹配忽略 select * from dual where name like ‘c%’; UNION操作符UNION在进行表链接后会筛选掉重复的记录，所以在表链接后会对所产生的结果集进行排序运算，删除重复的记录再返回结果。 采用UNION ALL操作符替代UNION，因为UNION ALL操作只是简单的将两个结果合并后就返回。 联接列select * from employss where first_name||’’||last_name =’Beill Cliton’; where first_name =’Beill’ and last_name =’Cliton’; Order by语句ORDER BY语句决定了Oracle如何将返回的查询结果排序。Order by语句对要排序的列没有什么特别的限制，也可以将函数加入列中(象联接或者附加等)。任何在Order by语句的非索引项或者有计算表达式都将降低查询速度。 仔细检查order by语句以找出非索引项或者表达式，它们会降低性能。解决这个问题的办法就是重写order by语句以使用索引，也可以为所使用的列建立另外一个索引，同时应绝对避免在order by子句中使用表达式。 MyBatisPlus时间范围查询1.传入时间范围参数类型是字符串123456&lt;if test=&quot;startTime!=null and startTime.trim() neq &#x27;&#x27;&quot;&gt; and date_format(create_time,&#x27;%Y-%m-%d %H:%i:%s&#x27;) &amp;gt;= str_to_date(#&#123;startTime&#125;,&#x27;%Y-%m-%d %H:%i:%s&#x27;) &lt;/if&gt; &lt;if test=&quot;endTime!=null and endTime.trim() neq &#x27;&#x27;&quot;&gt; and date_format(create_time,&#x27;%Y-%m-%d %H:%i:%s&#x27;) &amp;lt;= str_to_date(#&#123;endTime&#125;,&#x27;%Y-%m-%d %H:%i:%s&#x27;) &lt;/if&gt; 2.传入时间范围参数类型是Date123456&lt;if test=&quot;startTime!=null and startTime.trim() neq &#x27;&#x27;&quot;&gt; and date_format(create_time,&#x27;%Y-%m-%d %H:%i:%s&#x27;) &amp;gt;= date_format(#&#123;startTime&#125;,&#x27;%Y-%m-%d %H:%i:%s&#x27;) &lt;/if&gt; &lt;if test=&quot;endTime!=null and endTime.trim() neq &#x27;&#x27;&quot;&gt; and date_format(create_time,&#x27;%Y-%m-%d %H:%i:%s&#x27;) &amp;lt;= date_format(#&#123;endTime&#125;,&#x27;%Y-%m-%d %H:%i:%s&#x27;) &lt;/if&gt; 3.Mybatis-Plus时间范围查询12345678Page&lt;Record&gt; page = new Page&lt;&gt;(page, limit);IPage&lt;Record&gt; result = iRecordService.page(page, new LambdaQueryWrapper&lt;Record&gt;() .apply(StrUtil.isNotBlank(start_date), &quot;date_format (optime,&#x27;%Y-%m-%d&#x27;) &gt;= date_format(&#x27;&quot; + start_date + &quot;&#x27;,&#x27;%Y-%m-%d&#x27;)&quot;) .apply(StrUtil.isNotBlank(end_date), &quot;date_format (optime,&#x27;%Y-%m-%d&#x27;) &lt;= date_format(&#x27;&quot; + end_date + &quot;&#x27;,&#x27;%Y-%m-%d&#x27;)&quot;) .orderByDesc(HmsFaceDetectLog::getOptime)); 缓存与数据先删除缓存再更新DB 出现脏数据的概率较大，假设系统存在两条线程，一条是查询，一条是更新，当更新时，先删除缓存，此时查询线程不能命中缓存，去查库，此时load的是旧数据，然后将旧数据缓存，更新线程此时才更新数据库。这样很大的概率缓存是脏数据。 先更新DB再删除缓存 产生脏数据的概率低，同样是上个例子两条线程，当更新DB时，查询线程查的是旧数据，此时删除缓存，下次查询则会去查库，保证新数据，不会影响后面的数据。这种情况产生脏数据的情形：查询线程命中不了缓存，去查库，此时更新操作删除缓存，尔后查询线程load旧数据进缓存，这才造成脏数据。出现的条件在于查库线程在更新操作之前，且在更新线程删除缓存之后load数据进缓存。条件比较苛刻，可以忽略。 Mysql主从复制搭建应用场景读写分离 主服务器执行写、更新操作，从服务器对外提供读功能，根据需要调整从服务器数量提高数据库性能 原理Mysql服务器之间的主从同步是基于二进制日志机制，主服务器使用二进制日志来记录数据库的变动情况，从服务器通过读取和执行该日志文件来保持和主服务器的数据一致。 在使用二进制日志时，主服务器的所有操作都会被记录下来，然后从服务器会接收到该日志的一个副本。从服务器可以指定执行该日志中的哪一类事件（譬如只插入数据或者只更新数据），默认会执行日志中的所有语句。 每一个从服务器会记录关于二进制日志的信息：文件名和已经处理过的语句，这样意味着不同的从服务器可以分别执行同一个二进制日志的不同部分，并且从服务器可以随时连接或者中断和服务器的连接。 主服务器和每一个从服务器都必须配置一个唯一的ID号（在my.cnf文件的[mysqld]模块下有一个server-id配置项），另外，每一个从服务器还需要通过CHANGE MASTER TO语句来配置它要连接的主服务器的ip地址，日志文件名称和该日志里面的位置（这些信息存储在主服务器的数据库里） 文件目录 docker-compose.yml master conf my.cnf db init init.sql slave conf my.cnf db init init.sql dock-compose.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849version: &quot;3&quot;services: db-master: container_name: mysql-master image: mysql:8.0 restart: always environment: MYSQL_ROOT_PASSWORD: &quot;12345678&quot; MYSQL_USER: &#x27;test&#x27; MYSQL_PASS: &#x27;12345678&#x27; ports: # &lt;Port exposed&gt; : &lt; MySQL Port running inside container&gt; - &#x27;3306:3306&#x27; # Where our data will be persisted volumes: - &quot;./master/db/:/var/lib/mysql&quot; - &quot;./master/conf/my.cnf:/etc/my.cnf&quot; - &quot;./master/init/:/docker-entrypoint-initdb.d/&quot; networks: - net-mysql db-slave: container_name: mysql-slave image: mysql:8.0 restart: always environment: MYSQL_ROOT_PASSWORD: &quot;12345678&quot; MYSQL_USER: &#x27;test&#x27; MYSQL_PASS: &#x27;12345678&#x27; ports: # &lt;Port exposed&gt; : &lt; MySQL Port running inside container&gt; - &#x27;3307:3306&#x27; # Where our data will be persisted volumes: - &quot;./slave/db/:/var/lib/mysql&quot; - &quot;./slave/conf/my.cnf:/etc/my.cnf&quot; - &quot;./slave/init/:/docker-entrypoint-initdb.d/&quot; networks: - net-mysql # Names our volumevolumes: my-db-master: my-db-slave: networks: net-mysql: driver: bridge master节点my.conf123456789101112[mysqld]log_bin = mysql-binserver_id = 10user=mysqldefault-storage-engine=INNODBcharacter-set-server=utf8mb4[client]default-character-set=utf8mb4[mysql]default-character-set=utf8mb4 slave节点my.conf12345678[mysqld]log_bin = mysql-binserver_id = 11relay_log = /var/lib/mysql/mysql-relay-binlog_slave_updates = 1read_only = 1character-set-server=utf8mb4 进入从节点 1234567891011121314151617docker-compose exec db-slave bashmysql -u root -p# 创建用户授权GRANT SELECT,INSERT ON *.* TO &#x27;testUser&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;testPwd&#x27; WITH GRANT OPTION;# 配置从节点CHANGE MASTER TO MASTER_HOST=&#x27;172.21.0.2&#x27;, MASTER_USER=&#x27;root&#x27;, MASTER_PASSWORD=&#x27;12345678&#x27;, MASTER_LOG_FILE=&#x27;mysql-bin.000001&#x27;, MASTER_LOG_POS=0;查看状态mysql&gt; show slave status\\G;","tags":[],"categories":[{"name":"数据库","slug":"数据库","permalink":"https://dogfun.top/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"kafka消息队列","date":"2018-02-11T03:10:34.000Z","path":"2018/02/11/中间件/kafka消息队列/","text":"前言 在项目中使用到了kafka中间件，作为消费队列，下文对该组件的一些概念和特性做一些概括性总结。 消息队列作用解耦：降低系统间的耦合度，方便日后扩展 削峰：通过异步处理消息，并且提供多消费端来消费消息，达到削峰的作用 冗余 可恢复 Kafka特点Kakfa是一个分布式流处理平台，特点是高性能、分布式、高吞吐，底层写消息是顺序写磁盘，因此写入和读取速度非常快。大部分用于大数据处理平台和日志处理，其出身的原因也是LinkIn公司为了处理海量日志 支持消息模型 队列模型 同一个消息会被多个消费者一个个处理，不会重复处理 发布订阅模型 同一个消息会被所有消费者消费，类似通知 组件概念Producer：消息生产者 Consumer：消息消费者 Broker：实例，一般可以理解为服务器，一台服务器部署一个broker Topic：主题，消息是通过主题作为载体发送到队列中的 Partition：分区，主题下的分区概念，分区是可以在多个broker中，消息是写到多个partition上，每个partition上的数据是有序的，但多个消息间是无序的，若要保证消息有序消费，则可以设置一个topic一个partition 消费模型topic下的多个partition可以分布在多个broker中，一般N个partition分布在N个broker上，或者N个partition分布在M个broker，尽量保证N&lt;M，并且消费者数量&lt;=N，多余的消费者是拿不到partition的 副本机制Kakfa提供副本机制来保证高可用，副本不用于消费，仅用来冗余数据。比如一个topic有N个partition，分布在N个broker上。一个partition可以有多个副本，副本间有一个leader和多个follower，读写都是在leader中，follower和leader会保持数据同步。假设topic有3个partition设置3个副本，则第一个partition的数据会复制到2、3上，最简单的策略就是2存储1的数据副本，3存储2的数据副本，当某个broker宕了，则保证另外的broker中有数据冗余，这就保证了消息能继续消费，保证高可用 存在情况 假设leader所在的broker挂了，其他的follower还来不及同步消息，导致数据丢失，这种情况可以设置acks=all，表示当所有follower都收到该消息才算发送成功。","tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"},{"name":"消息队列","slug":"消息队列","permalink":"https://dogfun.top/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"中间件","slug":"中间件","permalink":"https://dogfun.top/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"categories":[{"name":"中间件","slug":"中间件","permalink":"https://dogfun.top/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"工厂模式","date":"2017-08-13T02:14:08.000Z","path":"2017/08/13/设计模式/design-pattern-工厂模式/","text":"概述 对比简单工厂模式集中工厂类生产，工厂模式将对象的创建交给相应的子类工厂，延迟创建，降低扩展对工厂接口的影响。这里有个要求就是工厂创建对象的细节不依赖于客户端。 对象关系 组成 关系 作用 抽象产品 具体产品的父类 产品的公共接口 具体产品 抽象产品的子类 生产的具体产品 抽象工厂 工厂抽象类 定义工厂的生产行为 具体的工厂 工厂抽象类的具体实现 根据参数创建不同的具体产品 UML 思路 抽象对象保持不变，我们需要把工厂抽象化，让子类工厂去实现抽象工厂，提供对象返回，这么做下来，当我们需要哪个对象，就调用哪个子类工厂就行了。 产品抽象类 1234abstract class Product&#123; String name; void show();&#125; 具体产品类 1234567891011class ProductA extends Product&#123; public void show()&#123; //生产产品A； &#125;&#125;class ProductB extends Product&#123; public void show()&#123; //生产产品B； &#125;&#125; 工厂接口 123interface Factory &#123; public Product getProduct();&#125; A工厂 12345public FactoryA implements Factory &#123; public Product getProduct()&#123; return new ProductA(); &#125;&#125; B工厂 12345public FactoryB implements Factory &#123; public Product getProduct()&#123; return new ProductB(); &#125;&#125; 客户端 123456789public class Client&#123; public static void main(String args[])&#123; Factory fa = new FactoryA(); Product a = f.getProduct(); Factory fb = new FactoryB(); Product b = f.getProduct(); &#125;&#125; 优点：通过对应的工厂对象完成对象的创建，对比简单工厂模式将对象的创建从工厂类中解耦出来，易扩展。","tags":[{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"会话技术Cookie与Session","date":"2017-08-06T13:06:53.000Z","path":"2017/08/06/web/会话技术Cookie与Session/","text":"序 什么是会话？按照理解就是人与人之间建立的一次谈话称为会话，放到Web的语义下就是浏览器与服务端的一次数据交互。我们知道Http协议是无状态的，一次连接建立后，数据交互完就结束了，第二次请求如果浏览器的请求不带点标识，服务端是无从知道是哪个客户发消息来，这也就引出我们的主题，Web的会话跟踪技术—Cookie与Session。 Cookie Cookie意为饼干，是一种客户端技术，当浏览器访问服务端时，服务端可以向响应Cookie中写入想要的内容，客户端就会保留相应的Cookie内容，在其后的请求中都会带上相应的内容，也就可以带上我们的用户标识。 常见方法 public Cookie(String name,String value) setValue与getValue方法 setMaxAge与getMaxAge方法 setPath与getPath方法 setDomain与getDomain方法 getName方法 不可跨域名 Cookie是不能跨域名的，也就是a网站的Cookie是不能发到b网站去的。 有效时间 使用setMaxAge来设置过期时间，如果是整数，则表示在MaxAge秒前有效，会写入磁盘；如果是负数，则表明Cookie是临时的，在浏览器关闭前是有效的。 没有修改和删除功能 修改就是用新值去覆盖旧值。 域名 domain属性决定了Cookie的域名，规定为”.域名”。 Session 是一种服务端技术，服务端会记录当前用户的相关信息，返回一个sessionId给客户端，那么下个请求就以sessionId唯一关联当前用户身份信息。 常见方法 long getCreationTime();【获取Session被创建时间】 String getId();【获取Session的id】 long getLastAccessedTime();【返回Session最后活跃的时间】 ServletContext getServletContext();【获取ServletContext对象】 void setMaxInactiveInterval(int var1);【设置Session超时时间】 int getMaxInactiveInterval();【获取Session超时时间】 Object getAttribute(String var1);【获取Session属性】 Enumeration getAttributeNames();【获取Session所有的属性名】 void setAttribute(String var1, Object var2);【设置Session属性】 void removeAttribute(String var1);【移除Session属性】 void invalidate();【销毁该Session】 boolean isNew();【该Session是否为新的】 生命周期与有效期 用户首次访问服务端servlet则会创建session对象。只要用户持续访问，服务端都会更新session的最后访问时间，而为了防止内存溢出，会把长时间没有访问的session干掉。默认的超时时间是30min，可以修改。","tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"},{"name":"Web","slug":"Web","permalink":"https://dogfun.top/tags/Web/"}],"categories":[{"name":"web","slug":"web","permalink":"https://dogfun.top/categories/web/"}]},{"title":"抽象工厂模式","date":"2017-07-21T02:14:13.000Z","path":"2017/07/21/设计模式/design-pattern-抽象工厂模式/","text":"概述 相比工厂模式，抽象工厂可以生产多类产品。抽象出产品类，比如电视类、空调类两类别产品，具体的产品子类对应子品牌，如海尔的电视，三星的电视或海尔的空调，三星的空调。工厂具体类主要包含需要生产的产品的组合，需要组合时只需扩展一个新的工厂具体类。 UML 缺点：当添加新的产品时，需要修改抽象工厂的接口，其子类都需要修改。 思路 怎么在一个工厂里组合生产多种产品呢？首先将多种类型的产品抽象化，创建对应产品的实现，创建顶层工厂抽象定义多种产品类族的工厂的抽象方法，这样顶层就决定了多种类族产品的组合，具体的产品有具体的抽象工厂。最终的效果就是我们能通过对应工厂获得对应的各种产品类 抽象产品类别 1234567abstract class ProductCatoryA&#123; void show();&#125;abstract class ProductCatoryB&#123; void catch();&#125; 具体产品 1234567891011121314151617181920212223class ProductConcreteAa extends ProductCatoryA&#123; public void show()&#123; //生产类别A的具体产品品牌a； &#125;&#125;class ProductConcreteAb extends ProductCatoryA&#123; public void show()&#123; //生产类别A的具体产品品牌b； &#125;&#125;class ProductConcreteBa extends ProductCatoryA&#123; public void catch()&#123; //生产类别B的具体产品品牌b； &#125;&#125;class ProductConcreteBb extends ProductCatoryA&#123; public void catch()&#123; //生产类别B的具体产品品牌b； &#125;&#125; 抽象工厂 1234abstract Factory &#123; public ProductCatoryA makeCatoryA(); public ProductCatoryB makeCatoryB();&#125; A工厂 123456789public FactoryA implements Factory &#123; public ProductCatoryA makeCatoryA()&#123; return new ProductConcreteAa(); &#125; public ProductCatoryB makeCatoryB()&#123; return new ProductConcreteBa(); &#125;&#125; B工厂 123456789public FactoryB implements Factory &#123; public ProductCatoryA makeCatoryA()&#123; return new ProductConcreteAb(); &#125; public ProductCatoryB makeCatoryB()&#123; return new ProductConcreteBb(); &#125;&#125; 客户端 12345678910111213public class Client&#123; public static void main(String args[])&#123; Factory fa = new FactoryA(); ProductCatoryA a = fa.makeCatoryA(); ProductCatoryB b = fa.makeCatoryB(); Factory fb = new FactoryB(); ProductCatoryA aa = fb.makeCatoryA(); ProductCatoryB bb = fb.makeCatoryB(); &#125;&#125; 总结 可以看出来如果我们要加入新的产品族，我们就需要在顶层工厂加入新的工厂方法，那么每个具体的工厂需要去实现新的产品的工厂方法，如果遇到需求变化大的情况，扩展起来比较麻烦，所以抽象工厂模式适合少变的场景","tags":[{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"简单工厂模式","date":"2017-04-26T03:18:49.000Z","path":"2017/04/26/设计模式/design-pattern-简单工厂模式/","text":"概述 通过一个工厂类的静态方法根据需要生产需要的对象，客户端直接调用工厂类，而不需要知道创建的细节。 对象关系 组成 关系 作用 抽象产品 具体产品的父类 产品的公共接口 具体产品 抽象产品的子类 生产的具体产品 工厂 被客户端调用 根据参数创建不同的具体产品 UML 思路 该模式的思路，首先定义一个抽象对象，定义相关的抽象方法，子对象通过继承实现抽象方法，实现工厂类，在工厂类提供一个静态对外调用，定义创建对象对应的参数，然后根据参数条件创建对应对象。 产品抽象类 1234abstract class Product&#123; String name; void show();&#125; 具体产品类 1234567891011class ProductA extends Product&#123; public void show()&#123; //生产产品A； &#125;&#125;class ProductB extends Product&#123; public void show()&#123; //生产产品B； &#125;&#125; 工厂类 123456789101112class Factory &#123; public static Product make(String type)&#123; switch(type)&#123; case &quot;A&quot;: return new ProductA(); case &quot;B&quot;: return new ProductB(); default: return null; &#125; &#125;&#125; 客户端 1234567public class Client&#123; public static void main(String args[])&#123; Factory f = new Factory; f.make(&quot;A&quot;).show(); f.make(&quot;B&quot;).show(); &#125;&#125; 缺点：当需要添加或修改产品时，需要修改工厂类的逻辑，当类的数量多时，不容易维护。 总结 使用简单工厂模式创建对象，所有创建对象的逻辑都放在了工厂静态方法内，客户端传入对应的对象类型或者参数来让工厂输出对象，缺点就是所有的创建逻辑都在工厂方法内导致以后如果扩展新对象需要修改工厂方法，当对象增多之后，不容易维护。","tags":[{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"单例模式","date":"2017-02-16T02:13:50.000Z","path":"2017/02/16/设计模式/design-pattern-单例模式/","text":"只有一个实例，类只创建一个对象，这个类提供一种访问其唯一对象的方式。 懒汉式：只有实例用到的时候才会去加载，加载时判断是否生成实例，没有就立刻创建并返回，有则返回已有的唯一实例。 1234567891011121314public class LazySingleton&#123; private static LazySingleton instance; private LazySingleton(); public static LazySingleton getInstance()&#123; if(instance==null)&#123; instance = new LazySingleton(); &#125; return instance; &#125;&#125; 饿汉式：实例在需要使用之前已经加载好了，用空间换取时间。 1234567891011public class HungrySingleton&#123; private static HungrySingleton instance = new HungrySingleton(); private HungrySingleton(); public static HungrySingleton getInstance()&#123; return instance; &#125;&#125; 双重检锁：保证线程安全。 1234567891011121314151617181920212223242526public class DoubleLockSingleton&#123; private volatile static DoubleLockSingleton instance ; private DoubleLockSingleton(); public static DoubleLockSingleton getInstance()&#123; if(instance==null)&#123; //保证只有一条线程能创建 synchronized(DoubleLockSingleton.class)&#123; if(instance==null)&#123; instance=new DoubleLockSingleton(); //jvm字节码指令分3步 /* 1、创建引用 2、在堆上分配内存空间 3、创建实例，引用与实例进行关联 由于jvm的字节码执行时会根据需要进行优化，无法保证2和3的顺序，有可能引用返回的实例是空对象，因此加入volatile保证jvm字节码执行的有序性。 */ &#125; &#125; &#125; return instance; &#125;&#125; 静态内部类生成单例：当需要用到单例时，jvm会调用静态内部类的加载，并初始化该实例，jvm能保证只初始化一次，因此是线程安全的。 12345678910111213public class Singleton&#123; private Singleton()&#123;&#125; private static class SingletonHolder&#123; private static final Singleton INSTANCE = new Singleton(); &#125; public Singleton getInstance()&#123; retrun SingletonHolder.INSTANCE; &#125;&#125;","tags":[{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]}],"categories":[{"name":"算法","slug":"算法","permalink":"https://dogfun.top/categories/%E7%AE%97%E6%B3%95/"},{"name":"web","slug":"web","permalink":"https://dogfun.top/categories/web/"},{"name":"linux","slug":"linux","permalink":"https://dogfun.top/categories/linux/"},{"name":"中间件","slug":"中间件","permalink":"https://dogfun.top/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"随想","slug":"随想","permalink":"https://dogfun.top/categories/%E9%9A%8F%E6%83%B3/"},{"name":"效率","slug":"效率","permalink":"https://dogfun.top/categories/%E6%95%88%E7%8E%87/"},{"name":"java","slug":"java","permalink":"https://dogfun.top/categories/java/"},{"name":"vps","slug":"vps","permalink":"https://dogfun.top/categories/vps/"},{"name":"数据库","slug":"数据库","permalink":"https://dogfun.top/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"金融","slug":"金融","permalink":"https://dogfun.top/categories/%E9%87%91%E8%9E%8D/"},{"name":"个人思考","slug":"个人思考","permalink":"https://dogfun.top/categories/%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83/"},{"name":"设计模式","slug":"设计模式","permalink":"https://dogfun.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"git","slug":"git","permalink":"https://dogfun.top/categories/git/"},{"name":"docker","slug":"docker","permalink":"https://dogfun.top/categories/docker/"}],"tags":[{"name":"技术学习","slug":"技术学习","permalink":"https://dogfun.top/tags/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"},{"name":"数据源","slug":"数据源","permalink":"https://dogfun.top/tags/%E6%95%B0%E6%8D%AE%E6%BA%90/"},{"name":"Spring","slug":"Spring","permalink":"https://dogfun.top/tags/Spring/"},{"name":"从零开始写框架","slug":"从零开始写框架","permalink":"https://dogfun.top/tags/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%86%99%E6%A1%86%E6%9E%B6/"},{"name":"投资","slug":"投资","permalink":"https://dogfun.top/tags/%E6%8A%95%E8%B5%84/"},{"name":"股票","slug":"股票","permalink":"https://dogfun.top/tags/%E8%82%A1%E7%A5%A8/"},{"name":"编程技巧","slug":"编程技巧","permalink":"https://dogfun.top/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"},{"name":"基金","slug":"基金","permalink":"https://dogfun.top/tags/%E5%9F%BA%E9%87%91/"},{"name":"JWT","slug":"JWT","permalink":"https://dogfun.top/tags/JWT/"},{"name":"Linux","slug":"Linux","permalink":"https://dogfun.top/tags/Linux/"},{"name":"理哲","slug":"理哲","permalink":"https://dogfun.top/tags/%E7%90%86%E5%93%B2/"},{"name":"WebSocket","slug":"WebSocket","permalink":"https://dogfun.top/tags/WebSocket/"},{"name":"Java基础","slug":"Java基础","permalink":"https://dogfun.top/tags/Java%E5%9F%BA%E7%A1%80/"},{"name":"异常","slug":"异常","permalink":"https://dogfun.top/tags/%E5%BC%82%E5%B8%B8/"},{"name":"消息队列","slug":"消息队列","permalink":"https://dogfun.top/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"ssr","slug":"ssr","permalink":"https://dogfun.top/tags/ssr/"},{"name":"ignite","slug":"ignite","permalink":"https://dogfun.top/tags/ignite/"},{"name":"中间件","slug":"中间件","permalink":"https://dogfun.top/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Web","slug":"Web","permalink":"https://dogfun.top/tags/Web/"}]}